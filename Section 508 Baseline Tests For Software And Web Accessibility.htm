<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Section 508 Baseline Tests For Software And Web Accessibility</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<h1 id="table-of-contents">Table of Contents</h1>
<p><a href="#etc."><u>etc. c. Check that the Heading levels match the
visual structure. Test Instruction 3a:  Visually apparent headings are
not programmatically identified. Section 508 Failure o Fails 1194.31(a):
Use without vision. Conditions o Fails 1194.31(b): Use with low vision.
 Programmatically identified heading levels do not match the visual
outline level. o Fails 1194.31(a): Use without vision. o Fails
1194.31(b): Use with low vision. Baseline Tests for Software &amp; Web
Accessibility Test Instruction 3b:  Visually apparent headings are not
programmatically identified. WCAG2 Failure o Fails 1.3.1 Info and
Relationships Conditions  Programmatically identified heading levels do
not match the visual outline level. o Fails 1.3.1 Info and Relationships
Test Instruction 3c:  Any failure in 3a Baseline o Fails Baseline
Requirement #15 Requirement Test  Visually apparent headings are
programmatically identified AND Results heading levels match the visual
outline level. o Passes Baseline Requirement #1</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We"><u>Document status,
review comments, and feedback .......................................
1</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_3"><u>Introduction
.......................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_5"><u>How the baseline
tests are structured
............................................................
6</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_9"><u>Use of the baseline
tests by federal agencies and other groups ..................
10</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_10"><u>Agency issues
beyond the test process
....................................................... 11</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_12"><u>Developing a
streamlined test process from this baseline—a primer .........
13</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_13"><u>Test Process
requirements
..........................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_14"><u>Test tool
instructions
.............................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_15"><u>Reporting results
..................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_16"><u>The Baseline Tests
(#1 - #28) .....................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_79"><u>Attachment A -
Cross-Reference Tables
....................................................... 80</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_80"><u>Baseline tests
(cross-reference table)
..........................................................
81</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_83"><u>Section 508
(cross-reference table)
.............................................................
84</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_86"><u>WCAG 2.0
(cross-reference table)
...............................................................
87</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_89"><u>Attachment B -
Flashing content test advisory notes...................................
90</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_90"><u>Requirement, and
draft rationale
..................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_91"><u>Attachment C -
Baseline Test Report Checklists
.......................................... 92</u></a></p>
<p><a href="#Software_only_test__Include_this"><u>Software-only test
.................................................................................</u></a></p>
<p><a href="#Web_only_test__Include_this_chec"><u>Web-only test
......................................................................................</u></a></p>
<p><a href="#Web_Software_test_Include_this_c"><u>Web+Software test
..................................................................................</u></a></p>
<p><a href="#Summary_of_failures"><u>Summary of failures
................................................................................</u></a></p>
<p><a href="#Document_Content_Change_Log"><u>Document Content Change Log
.....................................................................
97</u></a></p>
<p><a href="#Location_____________Change"><u>Version 2.0.1, November
2016
....................................................................
98</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_17"><u>1. Keyboard
navigation
.......................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_20"><u>2. Focus (visible)
...........................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_22"><u>3. Focus (order)
.............................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_24"><u>4. Focus (Revealing
hidden content) ....................................................
25</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_26"><u>5. Repetitive
Content
........................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_28"><u>6. Multi-state
components
....................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_31"><u>7. Images
....................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_35"><u>8. Color (meaning)
...........................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_37"><u>9. Color (contrast)
..........................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_39"><u>10. Flashing
(reserved)
........................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_40"><u>11. Forms
(associated instructions)
........................................................ 41</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_44"><u>12. Page Titles
................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_45"><u>13. Data Tables
(headers)......................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_48"><u>14. Data Tables
(cell-header association) ..............................................
49</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_51"><u>15. Headings
...................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_53"><u>16. Links and User
controls
....................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_56"><u>17. Language
...................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_58"><u>18. Audio
(transcripts)
........................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_60"><u>19. Video
(descriptions)
.......................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_62"><u>20. Synchronized
media (captions)
........................................................ 63</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_64"><u>21. Synchronized
media (descriptions) ..................................................
65</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_66"><u>22. Style-sheet
non-dependence............................................................
67</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_68"><u>23. Frames
.....................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_69"><u>24. Alternate pages
............................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_71"><u>25. Time outs
..................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_73"><u>26. Image maps
.................................................................................</u></a></p>
<p><a href="#Baseline_Tests_for_Software___We_74"><u>27. Plug-in Links
..............................................................................</u></a></p>
<p>Harmonized</p>
<p>Processes for</p>
<p>Section 508</p>
<p>Testing:</p>
<p>Baseline Tests for</p>
<p>Software &amp; Web</p>
<p>Accessibility</p>
<p>March 2017 | Version 2.0.2</p>
<p><span id="Baseline_Tests_for_Software___We"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Document status, review comments, and feedback</p>
<p>The current version is 2.0.2 approved for distribution by the
Interagency Trusted Tester Program (ITTP) Technical Working Group.</p>
<p>For more information on the baseline tests and links to published
streamlined test processes, training and certification programs,
visit:</p>
<p><a
href="http://www.dhs.gov/compliance-test-processes">http://www.dhs.gov/compliance-test-processes</a></p>
<p>For questions or to provide feedback, contact the DHS Accessibility
Helpdesk at:</p>
<p>accessibility@dhs.gov <a href="http://accessibility.dhs.gov/">|
http://accessibility.dhs.gov</a></p>
<p>202-447-0440 (Voice)</p>
<p>202-447-5857 (TTY)</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Contents:</p>
<p><a href="#Baseline_Tests_for_Software___We">Document status, review
comments, and feedback ....................................... 1</a></p>
<p><a href="#Baseline_Tests_for_Software___We_3">Introduction
.......................................................................................................
4</a></p>
<p><a href="#Baseline_Tests_for_Software___We_3">Baseline tests
................................................................................................
4</a></p>
<p><a href="#Baseline_Tests_for_Software___We_3">Background
...................................................................................................
4</a></p>
<p><a href="#Baseline_Tests_for_Software___We_5">How the baseline tests
are structured
............................................................ 6</a></p>
<p><a href="#Baseline_Tests_for_Software___We_9">Use of the baseline
tests by federal agencies and other groups .................. 10</a></p>
<p><a href="#Baseline_Tests_for_Software___We_10">Agency issues beyond
the test process .......................................................
11</a></p>
<p><a href="#Baseline_Tests_for_Software___We_12">Developing a
streamlined test process from this baseline—a primer .........
13</a></p>
<p><a href="#Baseline_Tests_for_Software___We_12">Examine example test
processes first
.......................................................... 13</a></p>
<p><a href="#Baseline_Tests_for_Software___We_12">Examine the advisory
notes on each baseline test.......................................
13</a></p>
<p><a href="#Baseline_Tests_for_Software___We_12">Target audiences,
requirement and test instruction wording ........................
13</a></p>
<p><a href="#Baseline_Tests_for_Software___We_13">Test Process
requirements
..........................................................................
14</a></p>
<p><a href="#Baseline_Tests_for_Software___We_13">Modifications to the
baseline tests
...............................................................
14</a></p>
<p><a href="#Baseline_Tests_for_Software___We_14">Test tool instructions
....................................................................................
15</a></p>
<p><a href="#Baseline_Tests_for_Software___We_15">Reporting results
.........................................................................................
16</a></p>
<p><a href="#Baseline_Tests_for_Software___We_16"><em>The Baseline Tests
(#1 - #28)</em>
..........................................................................
17</a></p>
<p><a href="#Baseline_Tests_for_Software___We_79">Attachment A -
Cross-Reference Tables
....................................................... 80</a></p>
<p><a href="#Baseline_Tests_for_Software___We_80">Baseline tests
(cross-reference table)
.......................................................... 81</a></p>
<p><a href="#Baseline_Tests_for_Software___We_83">Section 508
(cross-reference table)
............................................................. 84</a></p>
<p><a href="#Baseline_Tests_for_Software___We_86">WCAG 2.0
(cross-reference table)
...............................................................
87</a></p>
<p><a href="#Baseline_Tests_for_Software___We_89">Attachment B -
Flashing content test advisory notes...................................
90</a></p>
<p><a href="#Baseline_Tests_for_Software___We_89">Why to include a
flashing content test in a test process ...............................
90</a></p>
<p><a href="#Baseline_Tests_for_Software___We_89">Why there is no
baseline test for flashing
..................................................... 90</a></p>
<p><a href="#Baseline_Tests_for_Software___We_90">Requirement, and draft
rationale
..................................................................
91</a></p>
<p><a href="#Baseline_Tests_for_Software___We_90">How to report on
flashing content
................................................................
91</a></p>
<p><a href="#Baseline_Tests_for_Software___We_91">Attachment C -
Baseline Test Report Checklists
.......................................... 92</a></p>
<p><a href="#Software_only_test__Include_this">Software-only test
........................................................................................
93</a></p>
<p><a href="#Web_only_test__Include_this_chec">Web-only test
...............................................................................................
94</a></p>
<p><a href="#Web_Software_test_Include_this_c">Web+Software test
......................................................................................
95</a></p>
<p><a href="#Summary_of_failures">Summary of failures
.....................................................................................
96</a></p>
<p><a href="#Document_Content_Change_Log">Document Content Change Log
.....................................................................
97</a></p>
<p><a href="#Document_Content_Change_Log">Version 1.0.6, March 2015
...........................................................................
97</a></p>
<p><a href="#Document_Content_Change_Log">Version 1.1, February 2016
.........................................................................
97</a></p>
<p><a href="#Document_Content_Change_Log">Version 2.0, October 2016
...........................................................................
97</a></p>
<p><a href="#Location_____________Change">Version 2.0.1, November 2016
....................................................................
98</a></p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Contents: The Baseline Tests (#1 - #28)</p>
<p><a href="#Baseline_Tests_for_Software___We_17">1. Keyboard navigation
........................................................................
18</a></p>
<p><a href="#Baseline_Tests_for_Software___We_20">2. Focus (visible)
..................................................................................
21</a></p>
<p><a href="#Baseline_Tests_for_Software___We_22">3. Focus (order)
...................................................................................
23</a></p>
<p><a href="#Baseline_Tests_for_Software___We_24">4. Focus (Revealing
hidden content) ....................................................
25</a></p>
<p><a href="#Baseline_Tests_for_Software___We_26">5. Repetitive Content
............................................................................
27</a></p>
<p><a href="#Baseline_Tests_for_Software___We_28">6. Multi-state
components
....................................................................
29</a></p>
<p><a href="#Baseline_Tests_for_Software___We_31">7. Images
.............................................................................................
32</a></p>
<p><a href="#Baseline_Tests_for_Software___We_35">8. Color (meaning)
...............................................................................
36</a></p>
<p><a href="#Baseline_Tests_for_Software___We_37">9. Color (contrast)
................................................................................
38</a></p>
<p><a href="#Baseline_Tests_for_Software___We_39"><em>10.</em>
<em>Flashing (reserved)</em>
..........................................................................
40</a></p>
<p><a href="#Baseline_Tests_for_Software___We_40">11. Forms (associated
instructions) ........................................................
41</a></p>
<p><a href="#Baseline_Tests_for_Software___We_44">12. Page Titles
.......................................................................................
45</a></p>
<p><a href="#Baseline_Tests_for_Software___We_45">13. Data Tables
(headers)......................................................................
46</a></p>
<p><a href="#Baseline_Tests_for_Software___We_48">14. Data Tables
(cell-header association) ..............................................
49</a></p>
<p><a href="#Baseline_Tests_for_Software___We_51">15. Headings
..........................................................................................
52</a></p>
<p><a href="#Baseline_Tests_for_Software___We_53">16. Links and User
controls
....................................................................
54</a></p>
<p><a href="#Baseline_Tests_for_Software___We_56">17. Language
.........................................................................................
57</a></p>
<p><a href="#Baseline_Tests_for_Software___We_58">18. Audio
(transcripts)
............................................................................
59</a></p>
<p><a href="#Baseline_Tests_for_Software___We_60">19. Video
(descriptions)
.........................................................................
61</a></p>
<p><a href="#Baseline_Tests_for_Software___We_62">20. Synchronized media
(captions) ........................................................
63</a></p>
<p><a href="#Baseline_Tests_for_Software___We_64">21. Synchronized media
(descriptions) ..................................................
65</a></p>
<p><a href="#Baseline_Tests_for_Software___We_66">22. Style-sheet
non-dependence............................................................
67</a></p>
<p><a href="#Baseline_Tests_for_Software___We_68">23. Frames
.............................................................................................
69</a></p>
<p><a href="#Baseline_Tests_for_Software___We_69">24. Alternate pages
................................................................................
70</a></p>
<p><a href="#Baseline_Tests_for_Software___We_71">25. Time outs
.........................................................................................
72</a></p>
<p><a href="#Baseline_Tests_for_Software___We_73">26. Image maps
.....................................................................................
74</a></p>
<p><a href="#Baseline_Tests_for_Software___We_74">27. Plug-in Links
....................................................................................
75</a></p>
<p><a href="#Baseline_Tests_for_Software___We_76">28. Built-in
accessibility features
............................................................ 77</a></p>
<p><span id="Baseline_Tests_for_Software___We_3"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Introduction</p>
<p>Baseline tests</p>
<p>This document contains accessibility design requirements and
validation tests for software and</p>
<p>Web accessibility. These tests are for measuring compliance with
Section 508 of the</p>
<p>Rehabilitation Act of 1973, as amended (29 U.S.C. 794d)1.</p>
<p>This publication contains <em>baseline</em> tests that have been
agreed upon and adopted by</p>
<p>representatives of federal agencies as part of an effort to harmonize
their testing processes for</p>
<p>Section 508.</p>
<p>These baseline tests establish the minimum steps required to
determine whether an application</p>
<p>passes or fails applicable Section 508 technical and functional
performance requirements.</p>
<p>Federal agencies are encouraged to adopt the baseline to establish a
consistent, shared,</p>
<p>government-wide test approach.</p>
<p>Federal agencies and other groups are at liberty to develop their own
test processes,</p>
<p>incorporating the baseline tests and any additional test criteria
specific to their needs. Although</p>
<p>agencies may add some unique tests in their processes, all agency
test processes will include</p>
<p>the <em>baseline</em> test elements. A unified approach for 508
testing will provide consistency across</p>
<p>government and confidence in test results shared between
agencies.</p>
<p>Background</p>
<p>When Section 508 came into effect in 2001, it was up to individual
federal agencies to develop</p>
<p>their own responses to the requirements (interpretations of
standards, development of test and</p>
<p>governance processes, etc.). Some agencies do not test as part of
their compliance efforts,</p>
<p>lacking resources and/or expertise. Instead, they may rely on vendor
claims of conformance</p>
<p>with the Section 508 standards. A number of agencies do test,
however, and have developed</p>
<p>their own processes for evaluating Commercial-Off-The-Shelf (COTS)
products, and internally</p>
<p>developed software applications and Web sites. Because each agency
developed its own test</p>
<p>processes independently, there are inevitable differences in testing
approaches and associated</p>
<p>compliance determinations. Such differences have resulted in
different testing outcomes for the</p>
<p>same products: agency "a" would test COTS product "x", finding it 508
compliant, then agency</p>
<p>"b" would find product "x" non-compliant. Without consistent testing,
vendors receive mixed or</p>
<p>conflicting messages from different federal agencies on the
compliance of their products and</p>
<p>services, and multiple agencies tend to test the same products due to
a lack of trust with one</p>
<p>another's test results.</p>
<p>In an effort to improve Section 508 testing across government, the
"Harmonized Testing</p>
<p>Process for Section 508 Compliance: Baseline Tests for Software and
Web Accessibility" was</p>
<p>developed as part of a collaborative project between accessibility
teams at the US Department</p>
<p>of Homeland Security (DHS) and the US Social Security Administration
(SSA).</p>
<p>Prior to this project, SSA and DHS evaluated software and Web
accessibility against Section</p>
<p>508 requirements using very different approaches. DHS evaluated
against the requirements</p>
<p>1 Section 508 is an act that requires all federal departments and
agencies to ensure that their electronic</p>
<p>information &amp; technology (EIT) is accessible to people with
disabilities. The specific standards for</p>
<p>compliance with Section 508 are published a<a
href="http://section508.gov/">t Section508.gov.</a></p>
<p><span id="Baseline_Tests_for_Software___We_4"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>using code inspection tools to examine source code without the use of
Assistive Technology (AT). SSA, on the other hand, used an AT-intensive
approach, testing Web sites with assistive technologies most commonly
used by SSA employees with disabilities. While the two approaches were
radically different, they both had one thing in common: each strived to
accurately evaluate software and Web accessibility for Section 508
compliance. Consolidating and harmonizing the two approaches was not
easy, but for many reasons DHS and SSA felt it was necessary.</p>
<p>The result of this project is an agreed upon, harmonized core or
<em>'baseline'</em> set of tests that agencies can use to develop their
own test processes. Test processes should incorporate the baseline as
the minimum, and agencies have the option to streamline/enhance their
testing</p>
<p>processes to include more than the baseline if needed <a
href="#Baseline_Tests_for_Software___We_4">(Figure 1).</a></p>
<p><img src="media/index-6_1.png"
style="width:3.18056in;height:6.02778in" alt="index-6_1.png" /></p>
<p>Figure 1 - Developing a streamlined test process</p>
<p>incorporating the baseline tests</p>
<p>The baseline tests in this document have been developed to cover
Section 508 technical requirements for Software, Web, and Functional
Performance Criteria (FPC) that apply to all</p>
<p><span id="Baseline_Tests_for_Software___We_5"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Electronic and Information Technology (E&amp;IT). 2 The government's
Section 508 standards are, at</p>
<p>the time of writing, under a revision process. While not definite, it
is likely that the revised</p>
<p>Section 508 standards will follow closely the World Wide Web
Consortium (W3C) Web Content</p>
<p>Accessibility Guidelines 2.0 (WCAG 2.0).3 It was therefore decided to
develop the 508 baseline</p>
<p>tests to include, or at least align with most of the WCAG 2.0 success
criteria, in preparation for</p>
<p>the upcoming Section 508 refresh.4 A cross reference to show how the
baseline tests map to</p>
<p>Section 508 and to WCAG 2.0 in Attachment A.</p>
<p>Given the trend for technologies to converge, WCAG 2.0 requirements
were developed to</p>
<p>accommodate inevitable future technology changes, and the language
used in those guidelines</p>
<p>is necessarily at a high level. The experiences testers at both SSA
and DHS had, following</p>
<p>WCAG 2.0 to the letter, were problematic. Some tests led to
inconclusive results, and some</p>
<p>were considered too subjective in nature. The development of the new
baseline tests is the</p>
<p>result of an attempt to reduce ambiguity, increase consistency of
results, and emphasize the</p>
<p>methods and techniques that can reliably meet the Section 508
requirements, given the current</p>
<p>state and compatibility of underlying technologies.5</p>
<p>The result of the collaboration between SSA and DHS is reflected in
the current document: a set</p>
<p>of baseline tests that cover the current Section 508 standards, that
align with applicable WCAG</p>
<p>2.0 Level AA success criteria, and that can be incorporated in
separate, practical, systematic</p>
<p>test processes for software application and Web accessibility. 6
Additional WCAG harmonization</p>
<p>may be explored in the future as the Section 508 refresh process
continues and testing tools</p>
<p>and techniques mature.</p>
<p>How the baseline tests are structured</p>
<p>The selection criteria for including requirements and baseline tests
against those requirements</p>
<p>was:</p>
<p> <strong>Standards based:</strong> The requirement must be firmly
rooted in standards (both current and</p>
<p>emerging), or is there to address specific, documented, high-risk
accessibility issue (complaints are documented in an area that the
standards did not anticipate).</p>
<p> <strong>Validated:</strong> Tests were validated by SSA and DHS,
and are known to produce reliable and</p>
<p>repeatable results. In future updates, validation tests must be
conducted by more than one agency.</p>
<p> <strong>Usable:</strong> Validated Baseline tests were adapted into
a practical formal test process that was</p>
<p>tested to verify usability.</p>
<p>The tests have been developed to contain sufficient information and
instruction to make a</p>
<p>consistent and unambiguous measurement of the accessibility of
interface components,</p>
<p>independently of the other tests. However, doing all of these tests
in sequence is not</p>
<p>2 E&amp;IT is more widely referred to as ICT (Information and
Communications Technologies).</p>
<p>3 Web Content Accessibility Guidelines (WCAG) 2.0, W3C Recommendation
11 December 2008.</p>
<p>Available: <a
href="http://www.w3.org/TR/WCAG20/">http://www.w3.org/TR/WCAG20/</a></p>
<p>4 Note that "aligns with" does not imply "conforms to". For
conformance with WCAG 2.0, a WCAG 2.0 test</p>
<p>process should be followed, rather than the Baseline.</p>
<p>5 For example, HTML (Hyper Text Markup Language), ARIA (Accessible
Rich Internet Applications),</p>
<p>platform APIs (Application Programming Interfaces), browsers, and
assistive technologies.</p>
<p>6 The baseline tests herein are aligned with the WCAG Level A and
Level AA success criteria. WCAG</p>
<p><em>comments on the more stringent AAA:</em> "It is not recommended
that Level AAA conformance be required as a general policy for entire
sites because it is not possible to satisfy all Level AAA Success
Criteria for</p>
<p><em>some content."</em> <a
href="http://www.w3.org/TR/WCAG20/#cc1">http://www.w3.org/TR/WCAG20/#cc1</a></p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>recommended. Instead, testers should follow a streamlined, practical
test process that</p>
<p>incorporates these baseline tests <a
href="#Baseline_Tests_for_Software___We_4">(Figure 1).</a></p>
<p>Platform, browser and tools</p>
<p>The baseline tests support the following browsers and operating
systems.</p>
<p> Microsoft Internet Explorer version 11</p>
<p> Chrome (version 49.0.2623.87).</p>
<p> Firefox (version 45.0.2)</p>
<p> Microsoft Windows versions 7, 8.1, and 10. (In Windows 8.1 and 10,
testing is</p>
<p>performed in Desktop mode.)</p>
<p>It is recognized that product updates may take place daily, weekly,
or monthly, and specific versions noted above may quickly become
outdated. If a version update creates critical issues with usage within
the baseline testing procedures, details will be provided and those
versions shall be prohibited.</p>
<p>Configure Chrome for testing:</p>
<p>1. Chrome accessibility mode: When testing in Chrome, ensure that
accessibility mode is</p>
<p>enabled by either:</p>
<p>a. navigating to chrome://accessibility and setting this globally or
per tab, or b. Starting Chrome with the --force-renderer-accessibility
flag. (See</p>
<p><a
href="https://www.chromium.org/for-testers/command-line-flags">https://www.chromium.org/for-testers/command-line-flags</a>
for how to start Chrome with command-line flags.)</p>
<p>The tools used in the baseline tests have been chosen based on
several factors including ease of use, ease of teaching, and accuracy of
results. They are also free to use. Installation</p>
<p>instructions for these tools are available at <a
href="https://section508testing.org/tools.">https://www.dhs.gov/dhs-section-508-compliance-</a></p>
<p><a href="https://section508testing.org/tools.">testing-tools.</a></p>
<p> <strong>“Inspect”</strong> from Microsoft Corporation. This tool
reveals the accessibility properties (Name,</p>
<p>Role, Value and State) of Windows software components.7</p>
<p> URL for Windows 7<a
href="http://www.microsoft.com/en-us/download/details.aspx?id=8279">:
http://www.microsoft.com/en-us/download/details.aspx?id=8279</a></p>
<p> URL for Windows 8.1: <a
href="https://msdn.microsoft.com/en-us/windows/desktop/bg162891.aspx">https://msdn.microsoft.com/en-</a></p>
<p><a
href="https://msdn.microsoft.com/en-us/windows/desktop/bg162891.aspx">us/windows/desktop/bg162891.aspx</a></p>
<p> URL for Windows 10: <a
href="https://developer.microsoft.com/en-US/windows/downloads/windows-10-sdk">https://developer.microsoft.com/en-</a></p>
<p><a
href="https://developer.microsoft.com/en-US/windows/downloads/windows-10-sdk">US/windows/downloads/windows-10-sdk</a></p>
<p> <strong>“Java Ferret”</strong> from Oracle Corporation. This tool
reveals the accessibility properties (Name,</p>
<p>Role, Value and State) of Java software components.8</p>
<p> UR<a
href="http://www.oracle.com/technetwork/java/javase/tech/index-jsp-136191.html">L:
http://www.oracle.com/technetwork/java/javase/tech/index-jsp-136191.html</a></p>
<p>7 Inspect is a component of the installation of Microsoft Windows SDK
for Windows 7 and .NET</p>
<p>Framework 4, Version 7.1, or Microsoft Windows SDK for Windows 8.1
and 10. The tool must be used in the User Interface Automation (UIA)
mode, which includes the Microsoft Accessibility Architecture (MSAA)
properties.</p>
<p>8 Java Ferret is a component of the installation of Java Access
Bridge 2.0.2.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><strong></strong> “Web Accessibility Toolbar (WAT)” versions 2012 or
2015 for IE <strong>from the Web</strong></p>
<p>Accessibility Tools Consortium. This adds a toolbar to Internet
Explorer to aid manual inspection of accessibility properties of
components on web pages. : This toolbar is <strong>Note</strong></p>
<p>only compatible with IE. To test with Firefox or Chrome, install WAF
instead (see below).</p>
<p> URL: <a
href="https://www.dhs.gov/dhs-section-508-compliance-testing-tools">https://www.dhs.gov/dhs-section-508-compliance-testing-tools</a></p>
<p> <strong>Bookmarklets/Favelets.</strong> These tools are JavaScript
testing functions that are activated in</p>
<p>the browser, and supplement WAT. ( : These favelets are not necessary
if using WAF.) <strong>Note</strong></p>
<p> UR<a
href="https://www.dhs.gov/dhs-section-508-compliance-testing-tools">L:
https://www.dhs.gov/dhs-section-508-compliance-testing-tools</a></p>
<p> <strong>“ARIA Markup Favelet”</strong> reveals ARIA attributes on
web pages.  <strong>“Named Anchors Bookmarklet”</strong> reveals anchor
tags on web pages  <strong>“Frames Favelet”</strong> reveals frame and
iframe properties on web pages</p>
<p> <strong>“Web Accessibility Favelets (WAF)”</strong>. These favelets
were developed as an alternative to</p>
<p>WAT. They can be installed in IE, Firefox, and Chrome. WAF duplicates
the functionality of WAT (except it includes the Bookmarklets/Favelets
but not the Colour Contrast Analyzer) as much as possible within the
limitations of the favelet security context. (See below for more details
on known differences.) The Skip Link favelet from Jim Thatcher’s site is
included.</p>
<p> UR<a
href="https://www.dhs.gov/dhs-section-508-compliance-testing-tools">L:
https://www.dhs.gov/dhs-section-508-compliance-testing-tools</a></p>
<p> <strong>“Colour Contrast Analyzer”</strong> from The Paciello
Group. This tool is included with WAT. It</p>
<p>can also be installed as a standalone executable (to supplement
WAF).</p>
<p> UR<a
href="https://www.dhs.gov/dhs-section-508-compliance-testing-tools">L:
https://www.dhs.gov/dhs-section-508-compliance-testing-tools</a></p>
<p>While there are other platforms, browsers and tools available, those
used herein have been</p>
<p>technically validated for accurate and repeatable test results.
Agencies that use other</p>
<p>technologies are encouraged to verify that their results align with
the results from the tools</p>
<p>identified in this baseline. Contact the authors (see contact details
at the front of this document)</p>
<p>to verify use of other technologies. Once the testing outcomes are
verified, agencies may</p>
<p>develop an equivalent baseline process for their specific test
environments. Agency-specific</p>
<p>software installation and use guides should be included in
streamlined test processes based on</p>
<p>these tests.</p>
<p>Browser Recommendation: Test in IE11</p>
<p>While this test process supports multiple browsers, it was found that
IE11 is the most accessible</p>
<p>test environment for Flash and embedded Java. Due to Chrome’s and
Firefox’s diminishing</p>
<p>levels of support for Flash and Java, these browsers may not fully
reveal the coded accessibility</p>
<p>properties for these content types. Testing may still be performed in
Chrome and Firefox to</p>
<p>determine results in that specific browser. However, to determine the
compliance of the coded</p>
<p>content, applications that contain Flash and Java components should
be tested entirely in IE11.</p>
<p>These caveats will be repeated in this document where relevant. If it
is unknown at the start of</p>
<p>testing whether an application contains Flash or Java, the general
recommendation is to test in</p>
<p>IE. Testing of applications that do not contain Flash or Java
components can be performed in</p>
<p>any of the approved test environments.</p>
<p>Notes on WAF</p>
<p>The baseline tests were originally developed using WAT, a browser
plugin which is only</p>
<p>compatible with IE. To include other browsers in the approved test
environment and minimize</p>
<p>changes to test instructions, WAF, a suite of JavaScript favelets,
was developed to replicate</p>
<p>WAT operation and functionality as closely as possible. Alternative
instructions are not provided</p>
<p>for WAF unless there is a significant difference from WAT in terms of
testing or interpreting</p>
<p>results.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>WAF is a set of favelets that can be easily installed on various
browsers. The functions of the WAF favelets were named according to
their corresponding functions in WAT, minus the menu hierarchy, and the
instructions for testing can be easily mapped between WAT and WAF. For
example, where the WAT instruction is</p>
<p><strong>Use the to examine …</strong> WAT (Doc Info - ShowTitles,
Images - Show Images)</p>
<p>If using WAF, interpret these instructions as</p>
<p><strong>Use the to examine …</strong> WAF (Show Titles, Show
Images)</p>
<p>Once installed, the tester can organize the favelets by any
preference (e.g. in alphabetical order, in subfolders, in testing order,
etc.).</p>
<p>WAF nuances:</p>
<p> Disabling CSS: Whereas <strong>WAT (IE - Toggle CSS)</strong>
disables or enables CSS until this</p>
<p>function is re-selected, only disables CSS for one page refresh.
<strong>WAF (Toggle CSS)</strong></p>
<p>Additionally, may not re-enable CSS completely, in which case you
<strong>WAF (Toggle CSS)</strong></p>
<p>a page refresh will be required.</p>
<p>These caveats will be repeated in this document where relevant.</p>
<p><span id="Baseline_Tests_for_Software___We_9"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Baseline Tests</p>
<p>There are 28 separate requirements with associated tests, covering
all relevant components for</p>
<p>software applications and Web sites. Each test contains the following
information:</p>
<p> <strong>Numbered Requirement:</strong> In plain English, how the
component(s) should function in order</p>
<p>to meet the related standards. Note that the numbers are arbitrary,
and do not infer a practical test sequence</p>
<p> <strong>Rationale:</strong> In plain English, an explanation of why
this test is important, and why the test</p>
<p>methods are appropriate, with particular regard to the type(s) of
disability-related problems being addressed.</p>
<p> <strong>Related Standards:</strong> Which of the Section 508
standards are addressed by this test. Also,</p>
<p>which of the relevant WCAG 2.0 success criteria this test aligns
with. A given 508 standard or WCAG criteria may be addressed by multiple
baseline tests.9</p>
<p> <strong>Tools Necessary:</strong> Testing technologies used in this
test.</p>
<p><strong></strong> Test Instruction 1 - Finding Applicable
Components: <strong>How a tester would find the</strong></p>
<p>components that need to be tested.</p>
<p><strong></strong> Test Instruction 2 - Inspecting/Using Components:
<strong>How a tester would determine</strong></p>
<p>whether the components found in Instruction 1 meet the requirement.
This is achieved using inspection tools, and using human judgment.</p>
<p> <strong>Test Instruction 3 - Failure conditions:</strong> A list of
possible outcomes from Instruction 2,</p>
<p>along with what to mark on a test report for this particular
test.</p>
<p> <strong>3a - Section 508 Failure Conditions:</strong> The technical
requirements and/or functional</p>
<p>performance criteria that should be marked as failures in test
results. Only failure conditions are given for Section 508.10</p>
<p> <strong>3b - WCAG2 Failure Conditions:</strong> The A or AA
criteria that should be marked as failures</p>
<p>in test results.</p>
<p> <strong>3c - Baseline Requirement Test Results:</strong> This
includes a complete list of conditions</p>
<p>that must be fulfilled in order to pass the baseline requirement, and
conditions under which the baseline requirement is not applicable. Note
that any failure in 3a means that the baseline requirement fails.11</p>
<p>Appended to each test are an advisory notes entitled " " <strong>Tips
for streamlined test processes.</strong></p>
<p>These tips provide additional information, specific to the current
test, that support the generic</p>
<p>information provided in the primer section of this document.</p>
<p>Use of the baseline tests by federal agencies and other groups</p>
<p>Federal agencies and other groups are encouraged to adopt these
baseline tests, and either</p>
<p>develop their own test processes, or follow a test process developed
by another agency.12</p>
<p>When developing test processes, and reporting results from such test
processes, agencies must</p>
<p>take note of the following:</p>
<p><strong> Test</strong> results for each baseline requirement must be
reported<strong>. As such, each baseline</strong></p>
<p>requirement must be incorporated into the test process to be
considered an acceptable test process.</p>
<p>9 Cross-reference tables are provided at the back of this
document.</p>
<p>10 Streamlined test processes may include statements of when to mark
Section 508 standards as</p>
<p>compliant, or as not applicable.</p>
<p>11 For sharing test results between agencies, the results of 3a and
3c must be reported.</p>
<p>12 The baseline tests should not be re-published without citation,
nor should they be modified from the</p>
<p>content herein, which has been agreed upon and adopted by several
government agencies.</p>
<p><span id="Baseline_Tests_for_Software___We_10"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p> Results of tests that <strong>incorporate the baseline
tests</strong> are considered repeatable. A</p>
<p>conclusion as the result of such a process can say that it is on the
agreed-upon baseline.</p>
<p> Test processes that <strong>do not include all baseline
requirements</strong> are not considered to be</p>
<p>following the baseline. Results of these test processes will not be
accepted by agencies that have adopted the baseline tests.</p>
<p> Results of tests that incorporate the baseline but also <strong>go
beyond the baseline</strong> with</p>
<p>additional test requirements (see also <a
href="#Baseline_Tests_for_Software___We_4">Figure 1)</a>, must clearly
separate out in the report the results that refer to the baseline, and
the results that refer to additional agency-specific tests.</p>
<p>Agency issues beyond the test process</p>
<p>It should be noted that use of a test process that incorporates the
baseline tests is affected by other contextual issues that accompany any
Section 508 program in a federal agency. Some examples of related issues
to consider are:</p>
<p> This document does not address the policies or organizational
disciplines necessary to</p>
<p>develop a Section 508 program or outline the processes needed for
acceptance of vendor deliverables.</p>
<p> Our goal is to clearly document the accessibility of the evaluated
content against the Section</p>
<p>508 technical and functional performance requirements that are
applicable to software and web. While the baseline provides a more
predictable and reliable way of evaluating content, the test results can
be regarded as one factor that goes into making a Section 508 compliance
determination (the choice of an agency to adopt an application or not).
Other factors to consider in making compliance determinations include,
but are not limited to legal issues related to acquisition13, technical
issues of compatibility with existing systems, and business needs. The
output of a test process incorporating the baseline test will provide
results that can assist in making compliance determinations and
acceptance decisions of contract deliverables. The results may also be
used to notify vendors and teams of defects, and plan for / prioritize
ongoing test and remediation tasks.</p>
<p> This document does not address how to handle coding mistakes.
Problems may be found</p>
<p>during testing that impact accessibility, but are simply coding
errors. Included here would be things like links that lead to the wrong
target website. A tester may be responsible for notifying a developer if
that is agency good practice, but these issues are usually not
considered Baseline test results.</p>
<p> The baseline test methodology does not include tests with assistive
technology. Agencies</p>
<p>must decide the role assistive technology will play in their internal
testing program and Section 508 compliance determinations. Compatibility
and usability of content with assistive technology plays an important
role in assuring people with disabilities have comparable access to
technology, information, and systems.14 Because AT testing can result in
false-positives and false-negatives, defects must always be confirmed
with the baseline methods herein. Additional testing with AT may reveal
conclusive insights, but caution is urged: experience shows that such
additional AT testing is proficient only with experienced, well-trained
testers.</p>
<p> Section 508 puts Federal Agencies and some entities that receive
federal funds at both</p>
<p>business and legal risk if they do not comply with the law. The
developers of the baseline (at DHS and SSA) recognize that a well
implemented Section 508 program manages risks and</p>
<p>13 Federal Acquisition Regulation (FAR 39.2) <a
href="https://www.acquisition.gov/far/html/Subpart%2039_2.html">https://www.acquisition.gov/far/html/Subpart%2039_2.html</a>
14 Some content (e.g. dynamically generated content such as use of AJAX
and ARIA) may produce</p>
<p>passes and fails, the impact of which cannot be determined without
testing with assistive technology.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>knowingly takes on some risks. For example, an agency may deem it
acceptable to use this baseline to document minor deficiencies and allow
content to be published and applications to be pushed to production.
However, when evaluating COTS products, the severity of the impact of a
given defect or set of defects should be up to the implementing agency
(and not another agency or vendor). If results are generated outside of
the implementing agency (e.g. another trusted agency or vendors), they
should ignore any severity levels. In summary, agencies should not
accept outside entities evaluating their exposure to risk.</p>
<p> The baseline test methodology does not include guidance on managing
a testing program.</p>
<p>Agencies must determine the rules and procedures that their testers
will follow in performing testing to ensure adequate testing of
applications. This includes when testing will be performed, at what
level of coverage, and in which test environment. As noted in the
Browser Differences section, the test environments may affect the test
results of some applications. Agencies should consider these factors in
determining standard operating procedures for their testing program.</p>
<p><span id="Baseline_Tests_for_Software___We_12"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Developing a streamlined test process from this</p>
<p>baseline—a primer</p>
<p>The baseline test tables in this document are not intended to be
followed in a linear fashion, and</p>
<p>should be enhanced to form streamlined test processes for given
audiences (see al<a href="#Baseline_Tests_for_Software___We_4">so Figure
1,</a></p>
<p>page <a href="#Baseline_Tests_for_Software___We_4">5)</a>. The
following notes give a primer on issues to consider while developing a
streamlined testing process.</p>
<p>Examine example test processes first</p>
<p>Other federal groups have developed streamlined test processes. The
work you are planning may already have been done. Agencies publishing
their test processes usually allow other agencies to adopt and use
them.15</p>
<p>Examine the advisory notes on each baseline test</p>
<p>Each baseline test table in this document has a row entitled
"Advisory: Tips for streamlined test processes". These are tips on how
tests may be combined, how tests might easily be enhanced, and so forth.
These notes should always be consulted when creating a test process,
although they are advisory in nature.</p>
<p>Target audiences, requirement and test instruction wording</p>
<p>The baseline tests have been produced with the assumption that
testers have training / skills in accessibility, and have a basic
understanding of HTML and the construction of Web pages. Testers must
also have knowledge of the content or application that they are testing,
or they must be able to follow an informed test plan.</p>
<p>It is also assumed that testers have necessary skills to evaluate
subjective information in context (e.g., the suitability of alternate
text for images). Any agency adopting the baseline tests and producing
their own streamlined process (or adopting a published process) must
ensure that testers are given proper documentation, test plans,
demonstrations, and access to developers for clarifications and
explanations, as appropriate. Any test process incorporating these
baseline tests must therefore be tailored to the specific needs of its
developers and/or testers.</p>
<p>The baseline tests could be written for an audience of developers, an
audience of testers, or an audience of both. The requirements in each of
the baseline tables have been presented in a neutral tone that is
component-specific (e.g., "Links and/or user controls must have
meaningful names"). It may be desirable to reword the requirements and
instructions targeting developers (e.g., "Provide meaningful names for
all links and/or user controls"). Alternatively, it may be that the
process will be used only by testers, and so the language might be
changed to reflect that (e.g., "Check that links and/or user controls
have meaningful names").</p>
<p>15 Note any copying or editing restrictions etc. given in each
published process.</p>
<p><span id="Baseline_Tests_for_Software___We_13"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Test Process requirements</p>
<p>The test process contains all instructions that a tester needs to
follow the process completely to</p>
<p>test a product and report on the product’s test results. Test
processes derived from the baseline</p>
<p>tests should include a mapping to each baseline test and each Section
508 requirement. Test</p>
<p>processes should include the following:</p>
<p>1. Testing Tools</p>
<p>a. Where to obtain testing tools</p>
<p>b. How to set up of tools to ensure consistent test results between
testers c. How to use the tools</p>
<p>d. Non-baseline tools must be identified and results from these tools
are not to be</p>
<p>used to determine baseline test results.</p>
<p>2. Testing instructions</p>
<p>a. All baseline tests must be included (including an agency method
for Test #10</p>
<p>Flashing)</p>
<p>b. Advisory tips for streamlined test processes may be incorporated.
c. Agency-specific, non-baseline tests must be identified and not affect
baseline test</p>
<p>results</p>
<p>d. Test instructions (methods and use of tools for testing) e. Define
failure conditions</p>
<p>f. Define the 508 standard(s) and Baseline Tests that are being
tested</p>
<p>Modifications to the baseline tests</p>
<p>Given the nature of the baseline tests, they are not intended to be
used for testing 'as-is'.</p>
<p>Creation of a streamlined test requires some amount of modification
to the baseline. The</p>
<p>following provides guidance on what to do, and what not to do when
modifying the baseline</p>
<p>content.</p>
<p>Test order</p>
<p>Baseline tests included in this document are not intended to be used
in a linear fashion. The</p>
<p>order with which tests are conducted may be changed from the order
herein (the numbers of</p>
<p>each baseline test are for reference only). Tests may be combined for
efficiency. For example,</p>
<p>keyboard and focus tests can usually be done at the same time.</p>
<p>Always include the baseline, enhance as needed</p>
<p>Agencies that adopt the baseline tests agree to always incorporate
each baseline test listed</p>
<p>herein in their streamlined test processes. "Modification" in this
sense does not allow for</p>
<p>dropping <em>any</em> of the baseline tests.</p>
<p>To adopt the baseline, the content in each of the following table
cells of the baseline must be</p>
<p>represented somewhere in the streamlined test process (as a
minimum):</p>
<p> Numbered Requirement</p>
<p> Rationale</p>
<p> Test Instruction 1 - Finding Applicable Components</p>
<p> Test Instruction 2 - Inspecting/Using Components</p>
<p> Test Instruction 3a - Section 508 Failure Conditions</p>
<p> Test instruction 3c - Baseline Requirement Test Results</p>
<p>Additional agency-specific tests (see below) must be identified as
agency-specific testing (for</p>
<p>example, by means of a cross-reference table appended to the test
process document).</p>
<p><span id="Baseline_Tests_for_Software___We_14"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Wording changes, yes; Meaning changes, no</p>
<p>It may be desirable to change wording from the baseline. For example,
it may be desirable to change passive voice to active voice. Wording
changes to create a smooth-flowing, easy to read document are
acceptable. However, care should be taken to ensure that the meaning
remains the same even though the words used are different. A reviewer of
any streamlined test should be able to compare the content to the
baseline and conclude that the meaning and results that would come from
a test remain the same. Any errors or suggested improvements to</p>
<p>the baseline should be submitted to the address on pag<a
href="#Baseline_Tests_for_Software___We">e 1</a> of this document.</p>
<p>Separating out seldom used information</p>
<p>Each baseline test contains a rationale and a list of the necessary
tools. Testers need to learn this sort of information once, and then
have it available for quick reference. It is perfectly acceptable to
separate such seldom-used information into a separate section, but this
information must stay with any published test process (or be available
to access from any online streamlined test tool incorporating these
baseline tests).</p>
<p>Additional agency tests beyond the baseline</p>
<p>Agencies have the option to enhance their test processes to include
more than the baseline if</p>
<p>needed (see al<a href="#Top_of_index_html">so Figure 1</a> on page <a
href="#Baseline_Tests_for_Software___We_4">5)</a>. For example, there is
a test in the baseline that headings, where used, are programmatically
marked up so that they are accessible to screen reader users. Any agency
may decide to create a policy that "reports and memos over 1500 words
long must include headings, to enhance readability and enhance
accessibility". In this case, the test becomes (a) whether headings
exist to break up text over 1500 words long, and (b) whether existing
headings programmatically marked. When it comes to creating such a
streamlined test, and when it comes to sharing the results of such a
test between agencies, the agency-specific test (a) should be omitted
(or at least clearly marked as a non-baseline test); and the baseline
test (b) should always be included in the same manner as for the other
baseline results.</p>
<p>An agency may also create a streamlined process that includes
guidance to their accessibility test teams and other personnel on when a
given baseline test failure does not result in an agency compliance
determination failure. As stated earlier (see <em>Agency issues beyond
the test process</em>), test results are only one factor in making
internal compliance determinations. An agency policy that accepts a
certain baseline failure is the decision of that agency only. While the
streamlined process may include such information and guidance for an
agency's own internal use, results from it should similarly be separated
out from reports when sharing baseline test results between agencies (in
other words, report against the baseline; not against the compliance
determination).</p>
<p>Test tool instructions</p>
<p>Each baseline test lists the tool(s) used in that test. The test
instructions provide the high-level instruction on which part of the
tool to use (normally a menu choice). Instructions on how to use each
testing tool are not included in this document, but should be provided
to testers, either as part of a streamlined test process, or its
accompanying documentation.</p>
<p>It may be useful to visually differentiate test results, HTML and
other code in the streamlined process. For example:</p>
<p><span id="Baseline_Tests_for_Software___We_15"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>In the Baseline:</p>
<p>Use WAT (Tables – Show Data Tables). Each row and column header must
have either a SCOPE="col/row"; or an ID="x". If ID is used, data cells
must refer to the associated header cell's ID in order for the header to
pass this test.</p>
<p>In a streamlined process:</p>
<p><strong>WAT</strong> &gt; Tables &gt; Show Data Tables.</p>
<p> Each row and column header must have either</p>
<p> SCOPE="col/row"; or</p>
<p> ID="x".</p>
<p> If ID is used, data cells must refer to the associated header
cell's ID in order for</p>
<p>the header to pass this test.</p>
<p>Reporting results</p>
<p>Each baseline test includes an instruction (#3) for test results.
Results are presented in terms of</p>
<p>a clause, followed by, (3a) failures of Section 508, (3b) Failures of
WCAG 2.0, and (3c) failures</p>
<p>or passes of the Baseline Requirements. The results of 3a and 3c must
be reported, and 3b</p>
<p>may optionally be reported.</p>
<p>The method used in the baseline is to give certain clauses and then
the standard, guideline or</p>
<p>requirement that is impacted by that clause. An agency developing a
streamlined test process</p>
<p>can present failures in a way that meets their testing needs. For
example, a clause and failure is</p>
<p>given in the baseline as:</p>
<p><strong>[Web only]</strong> The purpose and/or function of a
non-decorative image is not</p>
<p>properly conveyed in descriptive text (1194.22(a): Equivalent text
descriptions)</p>
<p>This could be written in a streamlined process as:</p>
<p><strong>[W]</strong> Purpose and/or function of non-decorative image
not properly conveyed</p>
<p>in descriptive text. Fail 22a</p>
<p>Failures must be explained in the report. Reports will generally
include things like the type of</p>
<p>failure, the location of the failure, and supporting screen captures
with test tool results. Reports</p>
<p>may also describe any peer review process used.</p>
<p>When sharing reports between agencies, a checklist should be
included. Checklists for</p>
<p>software-only, web-only, and software plus web combined, are included
at the back of this</p>
<p>document (Attachment C).</p>
<p>It is not required that the compliance determinations16 that follow
on from test results be</p>
<p>included in any test reports that are shared between agencies.
Including such information is not</p>
<p>discouraged, however.</p>
<p>16 Compliance determination may be based on the test results, as well
as many other applicable factors</p>
<p><em>(see advice i</em><a
href="#Baseline_Tests_for_Software___We_10"><em>n</em> Agency issues
beyond the test process</a><em><a href="#Top_of_index_html">, p</a>ag<a
href="#Baseline_Tests_for_Software___We_10">e 9).</a></em></p>
<p><span id="Baseline_Tests_for_Software___We_16"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>The Baseline Tests (#1 - #28)</p>
<p><span id="Baseline_Tests_for_Software___We_17"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>1. Keyboard navigation</p>
<p><em><strong>Requirement</strong></em> 1. Keyboard access and control
must be available for all interactive</p>
<p>interface components and frames that can be accessed or controlled
with a mouse. Where non-standard keyboard commands are employed, notify
users of the existence and use of Alternate keyboard commands through
the interface, application help, and/or documentation.</p>
<p><em><strong>Rationale</strong></em> Interactive interface components
include navigation controls (links, buttons</p>
<p>etc.), and editable content (selectable text, data input etc.).</p>
<p>Wherever users are expected to interact with components, it must be
possible for users to get to those components or perform those functions
using only the keyboard, because (i) using a mouse is not possible when
the user has no sight, and (ii) using a mouse is not possible when the
user does not have the physical capability / dexterity to effectively
control a pointing device.</p>
<p>Keyboard access is defined as use with physical keyboard that is
attached to the computer, either separately (desktop PC) or integrated
(laptop PC, kiosk).</p>
<p>Ideally, interfaces use standard keyboard commands (TAB, Space Bar,
Enter, Escape, etc.), making their use easy and efficient. On occasions,
an interface may be designed to expand on the basic set of standard
keyboard commands; and/or remap standard keys. In both of these cases,
users must learn the non-standard keys. In order to be aware of
non-standard key commands, users must be notified of their existence and
correct use.</p>
<p>Notes:</p>
<p> Access must be via a physical keyboard. Specifically excluded from
this</p>
<p>test is the use of an on-screen keyboard, or using the Mouse-Keys
feature in Windows.</p>
<p> At this time the baseline tests herein cover use of software and
Web</p>
<p>sites on PCs (i.e., desktops and laptops) that have a keyboard as a
primary input device. Tablet PCs and software running on other portable
devices are not addressed in the baseline tests.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(a): Keyboard
Accessibility</p>
<p>WCAG2: 2.1.1 Keyboard</p>
<p>WCAG2: 2.1.2 No Keyboard Trap</p>
<p>WCAG2: 1.3.1 Info and relationships</p>
<p><em><strong>Tools Necessary</strong></em> Physical system keyboard
and pointing device (e.g., mouse), WAT</p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find all visible and
hidden interactive interface components (links, form</p>
<p><em><strong>Finding Applicable</strong></em> fields, drop down menus,
show/hide content, tree views, pop ups/light</p>
<p><em><strong>Components</strong></em> boxes, frames, iframes, etc.)
using a mouse (hover and/or click).</p>
<p>b. Use WAT (Doc Info-Show Titles) to reveal information that will
be</p>
<p>revealed by mouseover through the TITLE attribute.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Use the standard
keyboard commands (Tab, [Shift+Tab], Space bar,</p>
<p><em><strong>Inspecting/Using</strong></em> ALT, arrow keys, Enter,
etc.) to navigate through each interactive
<em><strong>Components</strong></em> interface component (including form
drop-down lists and form fields),</p>
<p>reveal hidden content, and activate all interface components. b.
Inspect any help (contextual help, or application help) and</p>
<p>documentation for notification of available Alternate keyboard</p>
<p>commands (e.g., non-standard keyboard controls for all users, or</p>
<p>access keys, hotkeys). Where standard keyboard commands do not</p>
<p>work, there must be instructions for (i) extending standard
keyboard</p>
<p>command operations (e.g., getting out of a keyboard "trap"), and/or
(ii)</p>
<p>remapped/ alternate keys. Verify that non-standard keyboard</p>
<p>commands they can be used to address deficiencies found in step a. c.
Inspect the information provided through the TITLE attribute on all</p>
<p>interactive components (including images that are interactive). If
the</p>
<p>TITLE information in the TITLE attribute cannot be revealed by</p>
<p>keyboard, it must be conveyed through screen text or visual
context.</p>
<p>Notes:</p>
<p> If a "trap" disrupts keyboard navigation, note the failure and use
a</p>
<p>mouse to regain control beyond the trap to continue testing.  The
test of whether an interactive interface component cannot be</p>
<p>accessed and/or activated by the keyboard can be satisfied by
either</p>
<p>step a, or by step b.</p>
<p> Non-standard keyboard access methods or shortcut keys must be</p>
<p>documented in a help section or be apparent on the screen
(hotkeys</p>
<p>become visible when pressing the Alt key, underlined letter, etc.). 
<strong>[Web only]</strong> Skip link keyboard navigability is a part of
this test.  <strong>[Web only]</strong> If using the keyboard reveals
the TITLE attribute's</p>
<p>information (e.g., through scripts), then it is not necessary to have
that</p>
<p>information on the page.</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  An interactive
interface component or function cannot be accessed by
<em><strong>Section 508 Failure</strong></em> the keyboard.</p>
<p><em><strong>Conditions</strong></em> o Fails 1194.21(a): Keyboard
Accessibility.</p>
<p> An interactive interface component or function cannot be activated
by</p>
<p>the keyboard.</p>
<p>o Fails 1194.21(a): Keyboard Accessibility.</p>
<p> A "trap" disrupts keyboard navigation.</p>
<p>o Fails 1194.21(a): Keyboard Accessibility.</p>
<p> Information provided by the TITLE attribute is not revealed by
the</p>
<p>keyboard and is not permanently shown on screen</p>
<p>o Fails 1194.21(a): Keyboard Accessibility.</p>
<p> Interactive interface components and functions can be accessed</p>
<p>AND/OR activated by the keyboard BUT non-standard/Alternative</p>
<p>commands are undocumented.</p>
<p>o Fails 1194.21(a): Keyboard Accessibility.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 3b:</strong></em>  An interactive
interface component or function cannot be accessed by <em><strong>WCAG2
Failure</strong></em> the keyboard.</p>
<p><em><strong>Conditions</strong></em> o Fails 2.1.1 Keyboard</p>
<p> An interactive interface component or function cannot be activated
by</p>
<p>the keyboard.</p>
<p>o Fails 2.1.1 Keyboard</p>
<p> A "trap" disrupts keyboard navigation.</p>
<p>o Fails 2.1.2 No Keyboard Trap</p>
<p> Information provided by the TITLE attribute is not revealed by
the</p>
<p>keyboard and is not permanently shown on screen</p>
<p>o Fails 2.1.1 Keyboard</p>
<p> Interactive interface components and functions can be accessed</p>
<p>AND/OR activated by the keyboard BUT non-standard/Alternative
commands are undocumented.</p>
<p>o Fails 1.3.1 Info and relationships</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#1</p>
<p><em><strong>Requirement Test</strong></em>  All interactive
interface components and functions can be accessed</p>
<p><em><strong>Results</strong></em> AND activated by the keyboard, AND
any non-standard/ Alternative</p>
<p>commands are documented.</p>
<p>o Passes Baseline Requirement #1</p>
<p><em><strong>Advisory: Tips for</strong></em>  Keyboard access for
Title content is available in Internet Explorer 11 for
<em><strong>streamlined test</strong></em> Windows 8.1 and 10. It may be
useful to notify testers to pause while</p>
<p><em><strong>processes</strong></em> tabbing through interactive
content with a TITLE attribute to see if</p>
<p>TITLE content is revealed during Keyboard Navigation testing.</p>
<p> This test may be combined with tests for focus.</p>
<p> It may be useful to separate out a test for keyboard use, and then
have</p>
<p>a separate test for documentation of non-standard commands.</p>
<p> Tips and techniques for finding hidden content may be useful
for</p>
<p>testers.</p>
<p> It may be useful to provide a Windows keyboard reference guide
to</p>
<p>testers.</p>
<p><span id="Baseline_Tests_for_Software___We_20"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>2. Focus (visible)</p>
<p><em><strong>Requirement</strong></em> 2. There must be a visible
indication of the currently focused interactive</p>
<p>component.</p>
<p><em><strong>Rationale</strong></em> Some software applications, and
Web browsers by default, indicate focus,</p>
<p>but this can be disrupted by the application of custom programming,
styles, style sheets, and scripting. However, such programming can also
be used to enhance visual indications of focus to help users who have
low vision.</p>
<p>When controlling the interface with keyboard only, if there is no
visual differentiation between the current focused item and the rest of
the interface / content, then it is not possible to tell where in the
interface you are. Therefore, a visual indication of focus is
necessary.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(c): Visual
Focus</p>
<p>WCAG2: 2.4.7 Focus Visible</p>
<p><em><strong>Tools Necessary</strong></em> Physical system
keyboard</p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find all visible and
hidden interactive interface components (links, form</p>
<p><em><strong>Finding Applicable</strong></em> fields, drop down menus,
show/hide content, tree views, pop ups/light</p>
<p><em><strong>Components</strong></em> boxes, etc.) using a mouse
(hover and/or click).</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Using the keyboard,
navigate to each interactive component and look</p>
<p><em><strong>Inspecting/Using</strong></em> for a visible indication
of focus (usually an outline around the
<em><strong>Components</strong></em> component).</p>
<p>Notes:</p>
<p> The clarity of visible focus is subjective and the minimum level is
the</p>
<p>browser’s (or OS platform) default display setting for indicating
focus.  Some components that are not normally considered interactive
may</p>
<p>actually be in the tab order, and therefore interactive (e.g., screen
text</p>
<p>for form filling instructions). Such components should receive a
visible</p>
<p>indication of focus when tabbed to.</p>
<p> <strong>[Web only]</strong> Skip link visual focus is a part of
this test.</p>
<p> <strong>[Web only]</strong> Loss of focus should not occur while
manually shifting</p>
<p>focus through the page (using the TAB or arrow keys). However,
when</p>
<p>a function that moves the focus is executed (such as an internal
page</p>
<p>link or hidden content is revealed), it may be necessary to
manually</p>
<p>shift focus once with the keyboard before focus becomes visible
again.</p>
<p>This is not considered a failure.</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  An interface
component does not give a visible indication when it <em><strong>Section
508 Failure</strong></em> receives focus.</p>
<p><em><strong>Conditions</strong></em> o Fails 1194.21(c): Visual
Focus.</p>
<p> A visual indication of focus occurs somewhere other than on the</p>
<p>component that has focus</p>
<p>o Fails 1194.21(c): Visual Focus.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 3b:</strong></em>  An interface
component does not give a visible indication when it <em><strong>WCAG2
Failure</strong></em> receives focus.</p>
<p><em><strong>Conditions</strong></em> o Fails 2.4.7 Focus Visible.</p>
<p> A visual indication of focus occurs somewhere other than on the</p>
<p>component that has focus</p>
<p>o Fails 2.4.7 Focus Visible</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#2</p>
<p><em><strong>Requirement Test</strong></em>  All interface components
give a visible indication when they receive</p>
<p>Results <em><strong>focus.</strong></em></p>
<p>o Passes Baseline Requirement #2</p>
<p><em><strong>Advisory: Tips for</strong></em>  Explain how to
determine the browser's (or OS platform) default <em><strong>streamlined
test</strong></em> behavior for indicating focus.</p>
<p>processes</p>
<p><span id="Baseline_Tests_for_Software___We_22"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>3. Focus (order)</p>
<p><em><strong>Requirement</strong></em> 3. When the sequence of
interface components has meaning or requires an</p>
<p>order of operation, the focus/TAB order must logically flow with the
application/content.</p>
<p><em><strong>Rationale</strong></em> A logical order and groupings of
interface components is normally a given</p>
<p>in the design of software applications and Web content. Groupings and
order are usually visually apparent. Logical arrangements are used to
aid visual appeal and improve usability. However, when the focus/TAB
order does not follow the logical order, users can become confused, make
errors, and may not understand the contextual meaning of components.
This is especially true for people who have no vision, or who have low
vision, and are relying on AT.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.31(a): Use
without vision</p>
<p>508 1194.31(b): Use with low vision</p>
<p>WCAG2: 2.4.3 Focus Order</p>
<p>WCAG2: 3.2.3 Consistent Navigation</p>
<p><em><strong>Tools Necessary</strong></em> Physical system
keyboard</p>
<p><em><strong>Test Instruction 1:</strong></em> a. Examine the
interface to determine the groupings and logical order.</p>
<p><em><strong>Finding Applicable</strong></em> b. Find components that
repeat on multiple pages or software screens</p>
<p><em><strong>Components</strong></em> (e.g., navigation menus).</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Use the keyboard to
navigate through the components. Be careful to</p>
<p><em><strong>Inspecting/Using</strong></em> address any hidden
content. Note any instances where the order
<em><strong>Components</strong></em> deviates from logical groupings,
and logical order between individual</p>
<p>components.</p>
<p>b. Where components are repeated on multiple pages or software</p>
<p>screens, note any changes to the relative order of the repeated</p>
<p>components.</p>
<p>Note:</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  There are mismatches
between the TAB order and the logical order. <em><strong>Section 508
Failure</strong></em> o Fails 1194.31(a): Use without vision.
<em><strong>Conditions</strong></em> o Fails 1194.31(b): Use with low
vision.</p>
<p> The relative order of repeated components changes between pages
/</p>
<p>software screens.</p>
<p>o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  There are mismatches
between the TAB order and the logical order. <em><strong>WCAG2
Failure</strong></em> Fails 2.4.3 Focus Order o</p>
<p><em><strong>Conditions</strong></em>  The relative order of repeated
components changes between pages /</p>
<p>software screens.</p>
<p>o Fails 2.4.3 Focus Order</p>
<p>o Fails 3.2.3 Consistent Navigation</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#3</p>
<p><em><strong>Requirement Test</strong></em>  The TAB order matches
the logical order and the order of repeated</p>
<p><em><strong>Results</strong></em> components remains constant between
pages.</p>
<p>o Passes Baseline Requirement #3</p>
<p><em><strong>Advisory: Tips for</strong></em>  This test is for
interactive interface components, excluding forms which
<em><strong>streamlined test</strong></em> are covered by the forms
test.</p>
<p><em><strong>processes</strong></em>  To get to all components, it
may require more than simply TABbing</p>
<p>between items. For example, it may be necessary to tab to a set of
components then use the arrow keys to get focus on individual
components.</p>
<p> Tab order may be application specific—reflecting business logic—so
it</p>
<p>may be helpful to ask developers whether a seemingly non-logical
order was intentional. It may be useful to verify order discrepancies
using the Tab Index attribute, if it is present (Although a Tab Index is
not required). It is also possible to Tab through components to see if
there is a visual focus on static text.</p>
<p> For web content that is in layout tables, it is possible to produce
a</p>
<p>linearized representation that may be useful in determining whether a
logical order is used. To linearize table content, use WAT (Tables -
Linearize).</p>
<p><span id="Baseline_Tests_for_Software___We_24"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>4. Focus (Revealing hidden content)</p>
<p><em><strong>Requirement</strong></em> 4. Components that reveal
hidden content (dialog boxes, light boxes, pop-</p>
<p>ups, content accordions, drop-down menus etc.) must either (i) shift
focus to the content they reveal, or (ii) the component must describe
that a change to the content will occur if selected.</p>
<p><em><strong>Rationale</strong></em> Some components on web content
and software screens are intentionally</p>
<p>hidden to reduce visual clutter. Other components only appear as part
of a procedure, such as an error notification.</p>
<p>It is possible to reveal content with interface components in an
inaccessible manner, by requiring user vision and/or requiring the use
of a mouse.</p>
<p>Keyboard users need to be able to get to the information and controls
that are revealed, and users without vision, or with low vision, need to
know that new content has appeared.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(c): Visual
Focus</p>
<p>508 1194.31(a): Use without vision</p>
<p>508 1194.31(b): Use with low vision</p>
<p>WCAG2: 2.4.3 Focus Order</p>
<p>WCAG2: 3.2.2 On Input</p>
<p><em><strong>Tools Necessary</strong></em> Physical system keyboard,
WAT, Inspect, Java Ferret</p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find instances of
interface components that reveal hidden content,</p>
<p><em><strong>Finding Applicable</strong></em> such as dialog boxes,
light boxes, pop-ups, content accordions, drop-</p>
<p><em><strong>Components</strong></em> down menus.</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Move the focus to
the control that reveals hidden content, activate the</p>
<p><em><strong>Inspecting/Using</strong></em> control with the keyboard,
and then determine whether focus is in the</p>
<p><em><strong>Components</strong></em> revealed content. It may be
necessary to TAB once to find the focus.</p>
<p>Continue to move through the revealed content using the keyboard. b.
If focus does not shift to the revealed content, an accurate
description</p>
<p>of the content change event must be provided.</p>
<p>o <strong>[Web only]</strong> Use the WAT (Doc Info - Titles, Images
- Show</p>
<p>Images) to examine the control's name, title and any adjacent screen
text or ALT text.</p>
<p>o <strong>[SW only]</strong> Use Inspect/Java Ferret to examine the
control's Name</p>
<p>and description.</p>
<p>Notes:</p>
<p> Without exception, focus must shift to modal dialog boxes (must
meet</p>
<p>step a, above) and remain within the dialog box until the box is
closed</p>
<p>by the user.</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 3a:</strong></em>  A modal dialog box
does not receive focus when it is opened. <em><strong>Section 508
Failure</strong></em> o Fails 1194.21(c): Visual Focus.
<em><strong>Conditions</strong></em>  A modal dialog box allows focus
to move off the dialog box before the</p>
<p>box is closed by a user's actions.</p>
<p>o Fails 1194.21(c): Visual Focus.</p>
<p> Focus does not move to revealed content, and no description of
the</p>
<p>content change is provided.</p>
<p>o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  A modal dialog box
does not receive focus when it is opened. <em><strong>WCAG2
Failure</strong></em> o Fails 2.4.3 Focus Order</p>
<p><em><strong>Conditions</strong></em>  A modal dialog box allows
focus to move off the dialog box before the</p>
<p>box is closed by a user's actions.</p>
<p>o Fails 2.4.3 Focus Order</p>
<p> Focus does not move to revealed content, or instructions/status are
not</p>
<p>provided when focus does not move to revealed content.</p>
<p>o Fails 2.4.3 Focus Order</p>
<p>o Fails 3.2.2 On Input</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#4</p>
<p><em><strong>Requirement Test</strong></em>  Focus moves to the
revealed content, or instructions/status are</p>
<p><em><strong>Results</strong></em> provided when focus does not move
to hidden content.</p>
<p>o Passes Baseline Requirement #4</p>
<p> There is no hidden content.</p>
<p>o Not applicable (Baseline Requirement #4)</p>
<p><em><strong>Advisory: Tips for</strong></em>  It may be useful to
remind testers that keyboard access and visible <em><strong>streamlined
test</strong></em> focus should be tested also during this test.
<em><strong>processes</strong></em>  Instructions on what "modal dialog
boxes" are and how they should</p>
<p>behave should be included.</p>
<p> Instructions for the use of Inspect / Java Ferret for identifying
focusable</p>
<p>content should be included for testers.</p>
<p><span id="Baseline_Tests_for_Software___We_26"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>5. Repetitive Content</p>
<p><em><strong>Requirement</strong></em> 5. <strong>[Web only]</strong>
A method must be provided to skip blocks of repeated</p>
<p>content or links on pages, allowing a user to move directly to
page-specific content.</p>
<p><em><strong>Rationale</strong></em> Groups of navigation links are
usually provided along the top and/or left of</p>
<p>multiple pages to provide quick navigation to other areas of a Web
site. In addition, some groups of pages may repeat blocks of content
(other than navigational controls).</p>
<p>For users who can see and use a mouse, skipping over navigation links
and other blocks of content is simply a mouse movement followed by a
click. However, for users who cannot use a mouse, repetitive links can
be a serious impediment to productivity. If a site has forty repetitive
links, a keyboard user must complete forty keystrokes just to get to the
information they need to use on each and every page.</p>
<p>To enable equitable use by keyboard only users, there must be a
method to skip past repetitive content. Similarly, for screen reader
users, if they must read content that is repeated on each page and
cannot skip past it, their experience on the page can be very
frustrating. A common method used to bypass repetitive content is
internal (same page) links.</p>
<p>Note:</p>
<p> Like other controls, the skip-navigation link must be keyboard
navigable</p>
<p>and receive visible focus.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.22(o): Method to
Skip Repetitive Links</p>
<p>WCAG2: 2.4.1 Bypass Blocks</p>
<p>Tools Necessary <em><strong>WAT</strong></em></p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find repeated blocks
of content and/or repetitive navigation links <em><strong>Finding
Applicable</strong></em> (menus, for example).</p>
<p>Components</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 2:</strong></em> o Use the WAT (Doc Info
- Skip Link) to reveal instances of skip links
<em><strong>Inspecting/Using</strong></em> and their targets.</p>
<p><em><strong>Components</strong></em> o The skip target must be
located after the repetitive content.</p>
<p>o If no skip links are marked, another skip method may have been</p>
<p>used. TAB toward the repetitive blocks of content/navigation links to
find a skip function. The skip function may only reveal when it receives
keyboard focus.</p>
<p>b. Test the functionality of the Skip method:</p>
<p>o Activate the function by keyboard. TAB to the link, activate it
with</p>
<p>the ENTER key, TAB again.</p>
<p>o Determine if the focus was moved past the repeated content. The</p>
<p>visual focus should have shifted to an interactive element after the
repetitive content.</p>
<p>o If there is no interactive element after the repetitive content,
the</p>
<p>focus would shift to the browser. To determine the actual location of
the skip target, adjust the browser window height (smaller) to force a
visual shift of content within the browser window when the skip function
is activated.</p>
<p>Notes:</p>
<p> If Skip links are there but they are not working properly, this is
a failure.  If there is a need for multiple skip links on a page, each
skip link must</p>
<p>describe its purpose to comply with the links requirement (#16). For
example, a page with repetitive links should have a skip link to jump
past these links. If there is also repetitive content, this should have
a separate skip link.</p>
<p> Repeated content that is contained in its own separate frame is
not</p>
<p>included in this test.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  There is no method
to skip past repeated blocks of content or links. <em><strong>Section
508 Failure</strong></em> o Fails 1194.22(o): Method to Skip Repetitive
Links. <em><strong>Conditions</strong></em></p>
<p><em><strong>Test Instruction 3b:</strong></em>  There is no method
to skip past repeated blocks of content or links. <em><strong>WCAG2
Failure</strong></em> o Fails 2.4.1 Bypass Blocks</p>
<p>Conditions</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#5</p>
<p><em><strong>Requirement Test</strong></em>  There are repeated
blocks of content or links and there are skip-links.</p>
<p><em><strong>Results</strong></em> o Passes Baseline Requirement
#5</p>
<p> There are no repeated blocks of content or links.</p>
<p>o Not applicable (Baseline Requirement #5)</p>
<p><em><strong>Advisory: Tips for</strong></em>  If Skip-navigation
links are there but the keyboard cannot be used to
<em><strong>streamlined test</strong></em> shift the focus, this is a
failure of the Keyboard test (#1). <em><strong>processes</strong></em> 
If Skip-navigation links are there but they are not visible when
focused,</p>
<p>this is a failure of the Focus (visible) test (#2).</p>
<p><span id="Baseline_Tests_for_Software___We_28"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>6. Multi-state components</p>
<p><em><strong>Requirement</strong></em> 6. Components that can change
their state must reveal their current state</p>
<p>and function to Assistive Technology.</p>
<p><em><strong>Rationale</strong></em> Certain components in an
interface can change their state. States include</p>
<p>such things as closed/open, ascending-order/descending-order,
collapsed/expanded. Dynamic values can also be shown on components
(e.g., "34 characters remaining", "Alert Priority 5"). The current state
and function of interface components is usually visually apparent.
However, these characteristics of the component must be provided and
discoverable by assistive technology for users without vision or with
low vision (including without color perception).</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(d): Name,
Role, State.</p>
<p>508 1194.31(a): Use without vision</p>
<p>508 1194.31(b): Use with low vision</p>
<p>WCAG 1.3.1. Info and Relationships</p>
<p>WCAG2: 3.2.1 On Focus</p>
<p>WCAG2: 3.2.2 On Input</p>
<p>WCAG2: 4.1.2 Name, Role, Value</p>
<p><em><strong>Tools Necessary</strong></em> WAT, ARIA Markup Favelet,
Inspect/Java Ferret</p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find components that
indicate status or can change their state. <em><strong>Finding
Applicable</strong></em> Examples include images, tree navigation, data
table sort functions.</p>
<p>Components <em>Note:</em></p>
<p> It may be necessary to use the mouse to determine whether state</p>
<p>changes occur on hover, or on click.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Inspect components
to find associated information using the following</p>
<p><em><strong>Inspecting/Using</strong></em> methods (either in
combination or singularly): <em><strong>Components</strong></em> o Read
Screen Text on a component</p>
<p>o <strong>[Web only]</strong> Use WAT to reveal Titles (Doc Info -
Show Titles) o <strong>[Web only]</strong> Use WAT to reveal ALT
attributes (Images – Show</p>
<p>Images)</p>
<p>o <strong>[Web only]</strong> Use ARIA Markup Favelet to reveal ARIA
attributes.</p>
<p>The ARIA attribute may contain the text description or reference text
on the page.</p>
<p>o <strong>[SW only]</strong> Use Inspect/Java Ferret to examine the
Name, Role and</p>
<p>State of components</p>
<p>b. Determine whether the current State and function are correct.
Consider</p>
<p>the following test criteria:</p>
<p>o Sometimes information might be combined (e.g., Name and State</p>
<p>are provided together, such as "tree view expanded", or the function
and State are the same, such as "34 characters remaining")</p>
<p>o The component must unambiguously give its current state, rather</p>
<p>than what its state would be after a change is activated (e.g.,
"Submenu, closed" is unambiguous, whereas "Close Submenu" sounds like an
instruction). It may be necessary to change the state of components to
check that this is working properly.</p>
<p>o Complete status information is required. If a data table offers</p>
<p>multiple sort options (for example, sortable by date, last name, and
city), the data table’s current status must include which column is the
primary sort option and how that column is sorted. It is not required
that a single component provide the complete status for a component
(e.g., an asterisk can indicate the column that is the primary sort and
a down arrow can indicate that it is sorted alphabetically A to Z).</p>
<p>Note:</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  <strong>[SW
only]</strong> A multi-state component does not reveal its current
<em><strong>Section 508 Failure</strong></em> information (Name, Role,
and/or State). <em><strong>Conditions</strong></em> o Fails 1194.21(d):
Name, Role, State.</p>
<p> <strong>[Web only]</strong> A multi-state component does not reveal
its current</p>
<p>information (ALT, TITLE, ARIA attributes).</p>
<p>o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  A multi-state
component does not reveal its current information (Name,
<em><strong>WCAG2 Failure</strong></em> Role, and/or State).</p>
<p><em><strong>Conditions</strong></em> o Fails 1.3.1 Info and
Relationships</p>
<p>o Fails 3.2.1 On Focus</p>
<p>o Fails 3.2.2 On Input</p>
<p>o Fails 4.1.2 Name, Role, Value</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#6</p>
<p><em><strong>Requirement Test</strong></em>  Multi-state components
reveal their current information (Name, Role,</p>
<p><em><strong>Results</strong></em> and/or State).</p>
<p>o Passes Baseline Requirement #6</p>
<p> There are no components that can change their state.</p>
<p>o Not applicable (Baseline Requirement #6)</p>
<p><em><strong>Advisory: Tips for</strong></em>  Addressing content
that updates somewhere on the web page or <em><strong>streamlined
test</strong></em> software screen other than the current area of focus
(i.e., non-user-</p>
<p><em><strong>processes</strong></em> initiated state change) is not
addressed in the baseline tests. It may be</p>
<p>worth examining/addressing.</p>
<p> <strong>[Web only]</strong> For images, the preferred method is ALT
text (unless input</p>
<p>fields or links), but TITLE is allowed in this baseline test.</p>
<p> <strong>[Web only]</strong> A user guide for ARIA states may be
helpful. In some</p>
<p>cases, the state may flip when using the ARIA Markup Favelet.  If
multiple ARIA attributes are used on one element, additional user</p>
<p>testing may be needed to provide conclusive results.</p>
<p><span id="Baseline_Tests_for_Software___We_31"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>7. Images</p>
<p><em><strong>Requirement</strong></em> 7. All images must have
associated text describing the purpose and/or</p>
<p>function of the image. Decorative images do not require a
description.</p>
<p><em><strong>Rationale</strong></em> Screen reader software cannot
interpret images. The software will,</p>
<p>however, read text that has been associated with images. The
interpretation (meaning) of an image must therefore be conveyed
textually in the interface programming.</p>
<p>The meaning of visual information is inherently contextual. For
example, a picture of a person running on a page about athletics is
contextually different to the same picture of a person running on a page
about data connection speeds. Therefore, instead of just describing a
picture ("person running") a description is needed in context ("Come
join the athletics team" versus "With our network speeds, you'll be
ahead of the race").</p>
<p>Images of text are sometimes used instead of screen text to achieve
an artistic effect. When text is rendered as an image, the Alternate
text should be the same words verbatim.</p>
<p>If font-based graphics are used to provide information, equivalent
information must be provided in an accessible format.</p>
<p>Images that are used a number of times throughout an application
(e.g., icons on navigation controls) must have a consistent meaning and
text description throughout the application. For example, if an icon of
a blank piece of paper means "new document" on most screens, the same
icon cannot be used elsewhere to mean "reformat document". Consistency
aids users with cognitive disabilities.</p>
<p>Some images and animations are decorative and convey no information.
Decorative components do not need a description, but they do need a tag
to affirm to the user that there is no content in the image.</p>
<p>Note:</p>
<p> <strong>[Web only]</strong> The description is most often provided
as Alternate text</p>
<p>("ALT text") attribute on an image. It is also acceptable to use a
TITLE attribute for the description. If both ALT and TITLE are provided
for an image, the review of the ALT should take precedence.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(d): Name,
Role, State</p>
<p>508 1194.21(e): Bitmap images</p>
<p>508 1194.22(a): Equivalent text descriptions</p>
<p>WCAG2: 1.1.1 Non-text Content</p>
<p>WCAG2: 3.2.4 Consistent Identification</p>
<p><em><strong>Tools Necessary</strong></em> WAT, Inspect/Java
Ferret</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 1:</strong></em> a. Reveal where images
have been used: <em><strong>Finding Applicable</strong></em> o Look for
images that are rendered by using font-based graphics
<em><strong>Components</strong></em> (e.g. up-arrows to indicate sort
order, etc.).</p>
<p>o <strong>[Web only]</strong> Use the WAT (Select Images – Show
Images) and the</p>
<p>ARIA favelet on the page. Some components may not look like images,
but they will show up in the WAT output.</p>
<p>b. Look for components that appear to be images. Determine
<strong>[SW only]</strong></p>
<p>whether images are decorative. An image may be considered</p>
<p>decorative if it is purely artistic, or if it is redundant with the
text</p>
<p>information next to it (e.g., the caption includes the purpose and/or
the</p>
<p>function of the image).</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Reveal descriptive
text on images:</p>
<p><em><strong>Inspecting/Using</strong></em> o <strong>[Web
only]</strong> Use the WAT (Select Images – Show Images) to
<em><strong>Components</strong></em> reveal the ALT content and (Select
Doc Info – Show Titles) to</p>
<p>reveal descriptive title attributes. Execute the ARIA favelet to
determine if ARIA attributes are used to provide text descriptions of
images.</p>
<p>o <strong>[SW only]</strong> Use Inspect/Java Ferret Name property to
check for an</p>
<p>equivalent text description.</p>
<p>b. Examine the descriptive text to determine whether the purpose
and/or</p>
<p>function of the image has been conveyed for all non-decorative
images.</p>
<p>It may be necessary to check the surrounding text and other content
to</p>
<p>determine whether the descriptive text makes sense in context. c.
Examine the descriptive text on text rendered as an image to check</p>
<p>whether the texts match verbatim.</p>
<p>d. Examine the descriptive text on all decorative images:</p>
<p>o <strong>[Web only]</strong> There must be a null ALT on each
decorative image</p>
<p>(ALT="")</p>
<p>o <strong>[SW only]</strong> The Name should equal 'None' on each
decorative</p>
<p>image found with Inspect (decorative images not found with Inspect
may be safely ignored</p>
<p>e. If there are any CAPTCHA images, the descriptive text should
describe</p>
<p>the purpose of the image, not the text of the CAPTCHA.</p>
<p>f. Examine instances where the same image is used multiple times.</p>
<p>Check that the meaning of the image (conveyed through visual</p>
<p>appearance as well as descriptive text) is consistent throughout
the</p>
<p>application.</p>
<p>Notes:</p>
<p> If data charts contain a great deal of detail, the image may be</p>
<p>supported by a data table near the chart, or linked to the data
table.</p>
<p>The ALT on the chart can then be the name of the chart, the
pertinent</p>
<p>trends displayed in the chart (see also the surrounding text for
context),</p>
<p>or a combination of both.</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 3a:</strong></em>  CAPTCHA descriptive
text does not contain the purpose of the <em><strong>Section 508
Failure</strong></em> CAPTCHA.</p>
<p><em><strong>Conditions</strong></em> o Fails 1194.22(a): Equivalent
text descriptions.</p>
<p> Inconsistent meaning (visual appearance and/or descriptive text)
on</p>
<p>images used multiple times.</p>
<p>o Fails 1194.21(e): Bitmap images.</p>
<p> The descriptive text on text rendered as an image does not
match</p>
<p>verbatim</p>
<p>o Fails 1194.22(a): Equivalent text descriptions.</p>
<p> <strong>[Web only]</strong> The purpose and/or function of a
non-decorative image is</p>
<p>not properly conveyed in descriptive text.</p>
<p>o Fails 1194.22(a): Equivalent text descriptions.</p>
<p> <strong>[Web only]</strong> Missing an equivalent text description
on a non-decorative</p>
<p>image.</p>
<p>o Fails 1194.22(a): Equivalent text descriptions.</p>
<p> <strong>[Web only]</strong> Missing ALT="" (or similar
tag/attribute) on a decorative</p>
<p>image.</p>
<p>o Fails 1194.22(a): Equivalent text descriptions.</p>
<p> <strong>[Web only]</strong> ALT or similar tag/attribute containing
a description on a</p>
<p>decorative image.</p>
<p>o Fails 1194.22(a): Equivalent text descriptions.</p>
<p> <strong>[SW only]</strong> The purpose and/or function of a
non-decorative image is not</p>
<p>properly conveyed in the Name property</p>
<p>o Fails 1194.21(d): Name, Role, State.</p>
<p> <strong>[SW only]</strong> Decorative images found by Inspect do
not have a 'None'</p>
<p>Name property.</p>
<p>o Fails 1194.21(d): Name, Role, State.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  CAPTCHA descriptive
text does not contain the purpose of the <em><strong>WCAG2
Failure</strong></em> CAPTCHA.</p>
<p><em><strong>Conditions</strong></em> o Fails 1.1.1 Non-text
Content.</p>
<p> Inconsistent descriptive text on images used multiple times.</p>
<p>o Fails 3.2.4 Consistent Identification</p>
<p> The descriptive text on text rendered as an image does not
match</p>
<p>verbatim</p>
<p>o Fails 1.1.1 Non-text Content.</p>
<p> The purpose and/or function of a non-decorative image is not
properly</p>
<p>conveyed in descriptive text.</p>
<p>o Fails 1.1.1 Non-text Content.</p>
<p> Missing ALT text or TITLE on a non-decorative image.</p>
<p>o Fails 1.1.1 Non-text Content.</p>
<p> Missing ALT="" on a decorative image.</p>
<p>o Fails 1.1.1 Non-text Content.</p>
<p> ALT containing a description on a decorative image.</p>
<p>o Fails 1.1.1 Non-text Content.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#7</p>
<p><em><strong>Requirement Test</strong></em>  Images have an ALT-Text
or Title attribute AND the meaning, and/or</p>
<p><em><strong>Results</strong></em> purpose of the image is
sufficiently described, AND the meaning of</p>
<p>images used multiple times is consistent.</p>
<p>o Passes Baseline Requirement #7</p>
<p> There are no images.</p>
<p>o Not applicable (Baseline Requirement #7)</p>
<p><em><strong>Advisory: Tips for</strong></em>  Images are prime
candidates for providing extensive guidance and <em><strong>streamlined
test</strong></em> examples on how to provide alternate/descriptive
text. It is a subjective</p>
<p><em><strong>processes</strong></em> task, requiring consideration of
a number of factors. There are</p>
<p>numerous common mistakes to watch out for.</p>
<p> If the WAT (Select Images – Show Images) command does not mark</p>
<p>an image on a web page, it may be that the image is generated via</p>
<p>CSS, which would be covered under Baseline Test #22.</p>
<p> Advice on handling CAPTCHA images can cover the descriptive text
for</p>
<p>the CAPTCHA, and add that the function on the CAPTCHA should
still</p>
<p>be accessible (by following other Baseline tests as required).</p>
<p> <strong>[Web only]</strong> The description is more often provided
as Alternate text,</p>
<p>and is preferable to using the TITLE attribute (although the use of
either</p>
<p>or both is allowed).</p>
<p><span id="Baseline_Tests_for_Software___We_35"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>8. Color (meaning)</p>
<p><em><strong>Requirement</strong></em> 8. Color must not be the only
means of conveying information, indicating an</p>
<p>action, prompting a response, or indicating status. Information
conveyed through color must also be provided in text displayed on the
screen or by visual differentiation.</p>
<p><em><strong>Rationale</strong></em> Color dependence is defined as
using color as the sole means to convey</p>
<p>information. For example, a single indicator that is green for 'on',
orange for 'standby', and red for 'off' is color dependent.</p>
<p>When color is the only means to convey information, people who are
color blind, and people who cannot see, do not have access to the same
information that others have. The status or function that is being
conveyed by color also needs to be available in a textual format that
can be viewed by all, and can be read by screen reader software.</p>
<p>This requirement does not mean that color cannot be used; it means
that color cannot be the only means of conveying the information.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(i): No color
dependence to convey information</p>
<p>508 1194.22(c): No color dependence to convey information</p>
<p>WCAG2: 1.1.1 Non-text Content</p>
<p>WCAG2: 1.4.1 Use of Color</p>
<p>Tools Necessary <em><strong>WAT</strong></em></p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find where color
conveys meaning, indicates an action, or prompts a</p>
<p>Finding Applicable <em><strong>response.</strong></em></p>
<p>Components</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Where color is used
to convey meaning, determine if meaning is
<em><strong>Inspecting/Using</strong></em> present via:</p>
<p><em><strong>Components</strong></em> o Screen text, displayed when
the meaningful color is displayed,</p>
<p>describing the color (e.g. the word "ALERT" for a red indicator, or
an asterisk for a required field), or</p>
<p>o Visual differentiation (e.g., shape, position or size).</p>
<p>b. Use WAT (Colour - Greyscale) where content is suspect in
<strong>[</strong> <strong>Web only]</strong></p>
<p>terms of color dependency, to determine whether the meaning is clear
when color is not used.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  <strong>[SW
only]</strong> An instance of color being the sole means of conveying
<em><strong>Section 508 Failure</strong></em> meaning.</p>
<p><em><strong>Conditions</strong></em> o Fails 1194.21(i): No color
dependence to convey information.</p>
<p> <strong>[Web only]</strong> An instance of color being the sole
means of conveying</p>
<p>meaning.</p>
<p>o Fails 1194.22(c): No color dependence to convey information.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  An instance of color
being the sole means of conveying meaning. <em><strong>WCAG2
Failure</strong></em> o Fails 1.1.1 Non-text Content.</p>
<p><em><strong>Conditions</strong></em> o Fails 1.4.1 Use of Color.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#8</p>
<p><em><strong>Requirement Test</strong></em>  Color is used to convey
meaning AND the same information is provided</p>
<p><em><strong>Results</strong></em> via screen text or visual
differentiation.</p>
<p>o Passes Baseline Requirement #8</p>
<p> Color is not used to convey meaning.</p>
<p>o Not applicable (Baseline Requirement #8)</p>
<p><em><strong>Advisory: Tips for</strong></em>  When color is used to
communicate data sets (e.g., Geographic <em><strong>streamlined
test</strong></em> Information System application, or pie chart),
additional guidance may</p>
<p><em><strong>processes</strong></em> be necessary on testing for
equivalent facilitation. Related tests might</p>
<p>include multi-state components, images, links, and Alternate
pages.</p>
<p>Data tables related to the charts may also be suggested means of</p>
<p>augmenting the standard interface.</p>
<p> For Web testing, the WAT tool may sometimes return a page with</p>
<p>missing information, due to the program's limitations. In such
cases,</p>
<p>and with Software testing, it may be necessary to conduct a
manual</p>
<p>inspection such as printing a screen capture on a black and white</p>
<p>printer.</p>
<p> WAF’s Greyscale test works in more cases than WAT’s, although
there</p>
<p>may be some sites where both work only partially or not at all.</p>
<p><span id="Baseline_Tests_for_Software___We_37"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>9. Color (contrast)</p>
<p><em><strong>Requirement</strong></em> 9. There must be contrasting
colors/shades at a minimum ratio of 4.5:1 for</p>
<p>discerning between background and foreground content.</p>
<p><em><strong>Rationale</strong></em> The visual difference between the
background behind text, and the text</p>
<p>itself, may be perceivable by a given designer. However, beyond color
choice which is under control of the designer, many factors beyond the
designer's control affect peoples' ability to discern between
colors/shades, including age (contrast sensitivity reduces with
age),screen brightness, ambient light, color blindness and some types of
low vision. The use of color/shade choices that do not contrast well
with each other may be deliberate (i.e., artistic preference), or they
may be the result of programmatic features (e.g., a button's text is
black on white, but the text turns yellow in a certain mode, and the
background remains white).</p>
<p>In general, the higher the level of contrast used, the more people
will be able to see and use the content.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.31(b): Use with
low vision</p>
<p>WCAG2: 1.4.3 Contrast (Minimum)</p>
<p>Tools Necessary <em><strong>WAT</strong></em></p>
<p><em><strong>Test Instruction 1:</strong></em> a. Visually examine all
appearances of meaningful text and images of</p>
<p><em><strong>Finding Applicable</strong></em> meaningful text
displayed on the page for areas that may have low
<em><strong>Components</strong></em> background to foreground
contrast.</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Use WAT (Colour –
Contrast Analyser (application)) and use the colour</p>
<p><em><strong>Inspecting/Using</strong></em> picker tool to select
foreground and background colors from the screen.</p>
<p><em><strong>Components</strong></em> Select the Luminosity Algorithm.
WAT will display a luminosity contrast</p>
<p>ratio, which must be at least 4.5:1.</p>
<p>Notes:</p>
<p> The Contrast Analyser test is a rudimentary and does not address
all</p>
<p>users with reduced contrast sensitivity. In cases where certain
color/shade combinations are suspect, it may be necessary to utilize
additional tools.</p>
<p> <strong>[SW only]</strong> Text contained in Logos is exempt from
this requirement.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  An instance of
colors/shades for discerning between background and <em><strong>Section
508 Failure</strong></em> foreground content having contrast ratios of
less than 4.5:1 <em><strong>Conditions</strong></em> o Fails 1194.31(b):
Use with low vision.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  An instance of
colors/shades for discerning between background and <em><strong>WCAG2
Failure</strong></em> foreground content having contrast ratios of less
than 4.5:1 <em><strong>Conditions</strong></em> o Fails 1.4.3 Contrast
(Minimum).</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#9</p>
<p><em><strong>Requirement Test</strong></em>  Colors/shades for
discerning between background and foreground</p>
<p><em><strong>Results</strong></em> content have contrast ratios of
4.5:1 or better.</p>
<p>o Passes Baseline Requirement #9</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Advisory: Tips for</strong></em>  Text contained in
Logos rendered as images is exempt from this <em><strong>streamlined
test</strong></em> requirement, but there must be an ALT-text for the
logo. <em><strong>processes</strong></em>  The thresholds in the Colour
Contrast Analyser are based on the</p>
<p>WCAG 2 minimum contrast ratio of 4.5:1. WCAG 2.0 recommends a</p>
<p>lower threshold of 3:1 for 'large scale' text (18 point or 14 point
bold).</p>
<p>Although the Colour Contrast Analyser has a pass/fail indicator for
large</p>
<p>text, it does not determine the size of the text being tested. It
is</p>
<p>acceptable to allow a 3:1 ratio for larger text so long as the test
includes</p>
<p>a reliable mechanism for determining the font's point size.  The WAT
Colour Contrast Analyser is not specific to web content only.</p>
<p>The tool can be used for software inspection in any window.  If
using a dual-monitor setup, it is necessary to have both the tool
and</p>
<p>the window under test displayed on the primary monitor. 
Instructions for testing of text contrast changes due to mouse hover
and</p>
<p>status can be incorporated into streamlined tests.</p>
<p> Incidental text is exempt from this requirement. Text or images of
text</p>
<p>that are part of an inactive user interface component, that are
pure</p>
<p>decoration, that are not visible to anyone, or that are part of a
picture</p>
<p>that contains significant other visual content, have no contrast</p>
<p>requirement. An example of incidental text is disabled form field
labels.</p>
<p><span id="Baseline_Tests_for_Software___We_39"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>10. Flashing (reserved)</p>
<p>Requirement</p>
<p>10. Sections(s) of the screen should not flash at or above 3Hz.</p>
<p>Note:</p>
<p>Agencies must include an evaluation of flashing/blinking content in
their test processes. However, as of the publication of the current
version of baseline tests, there is no agreed-upon testing method.</p>
<p>For more information and advisory notes, see the attachment at the
end of this document.</p>
<p><span id="Baseline_Tests_for_Software___We_40"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>11. Forms (associated instructions)</p>
<p><em><strong>Requirement</strong></em> 11. Labels, instructions,
directions and cues necessary to complete a form</p>
<p>must be programmatically associated with their respective input
control.</p>
<p><em><strong>Rationale</strong></em> In order to correctly and
accurately complete a form, it is necessary to</p>
<p>follow instructions, directions and cues, as well as enter
information in the correct places. A given form component may be the
subject of instructions that are not positioned next to the component
(e.g., at the top of a form, the instruction is "If you are the home
owner, complete parts a, b, and f"). In such cases, form designers will
use visual layout and flow to direct the user. However, users without
vision, or with low vision, may not have access to the visual cues, and
hence will be unable to easily find the related instructions for the
current form component. For this reason, it is necessary to
programmatically associate all relevant instructions, directions and
cues with their respective components/controls.</p>
<p>Note:</p>
<p> Read-only (e.g. pre-filled) form fields are considered interactive,
in that</p>
<p>they need to receive keyboard focus and must be labeled.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(f): Input
text</p>
<p>508 1194.21(l): Forms</p>
<p>508 1194.22(n): Labels for forms</p>
<p>WCAG2: 1.3.1 Info and relationships</p>
<p>WCAG2: 3.3.2 Labels or instructions</p>
<p><em><strong>Tools Necessary</strong></em> WAT, ARIA Markup Favelet,
Inspect 32/Java Ferret</p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find all form input
components. Examples include buttons, text fields,</p>
<p><em><strong>Finding Applicable</strong></em> radio buttons,
checkboxes, multi-select lists (combo boxes).
<em><strong>Components</strong></em> b. Find all instructions and cues
(textual and graphical ) that are related to</p>
<p>form components/controls, including groupings, order of
completion,</p>
<p>special conditions or qualifiers, etc.</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Check the form
fields to see if all instructions and cues are <strong>[Web
only]</strong></p>
<p><em><strong>Inspecting/Using</strong></em> within label tags. Use WAT
(Structure – Fieldset/Labels, Doc Info -</p>
<p><em><strong>Components</strong></em> Show Titles):</p>
<p>o TITLE attributes can be used to duplicate the visual label,
which</p>
<p>can be rendered as screen text or as an image (duplicating the label
in the TITLE attribute can aid screen reader users, but is not
required).</p>
<p>o The TITLE attribute cannot be the sole means of providing</p>
<p>information.</p>
<p>b. Check that LABEL and ID are valid HTML: <strong>[Web
only]</strong></p>
<p>o Check that there is only one 'LABEL FOR' and only one 'ID'</p>
<p>assigned to each instruction / input component.</p>
<p>o Every ID on the page must be unique.</p>
<p>o The LABEL FOR and ID for the pair must be identical (case</p>
<p>sensitive).</p>
<p>o Determine whether the page is coded in HTML 4.01 or HTML5.</p>
<p>Press F12 or view source to inspect the DOCTYPE.</p>
<p> means the page is coded in HTML5.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p> means the page is coded in</p>
<p>HTML 4.01.</p>
<p>o In HTML 4.01:</p>
<p> IDs must start with a letter (starting with numbers is</p>
<p>prohibited).</p>
<p> After the first letter, any number of letters (a to z, A to Z),
digits</p>
<p>(0 to 9), hyphens (-), underscores (_), colons (:) and periods (.)
are allowed.</p>
<p>o In HTML5:</p>
<p> IDs can have any value as long as it is unique, not the empty</p>
<p>string, and does not contain spaces.</p>
<p>c. If all instructions and cues are present and related to the
<strong>[Web only]</strong></p>
<p>components, this completes this test. If this is not the case,
continue to step d.</p>
<p>d. Use the ARIA Markup Favelet. <strong>[Web only]</strong></p>
<p>o Determine whether ARIA form attributes exist on the page. o
<strong>[Web only]</strong> If ARIA is found, check that the ARIA
attribute(s) and</p>
<p>corresponding ID(s) are correctly identifying all necessary
instructions and cues for the form element. Note fields which have
‘required=true’.</p>
<p>e. Inspect the form to see if all instructions and cues are
<strong>[SW only]</strong></p>
<p>present within labels. Use Inspect/Java Ferret to examine the Name,
Role, State, and Value information for each component.</p>
<p>Notes:</p>
<p> There are many ways to indicate that a Web form field is
required.</p>
<p>Usually this is visually indicated by an asterisk (*) or other
symbol. The required information needs to be directly associated with
the input component via one of the above methods (adding a title
attribute, including the '*' in the label, or through ARIA
‘required=true’). For software, the required indicator should be
included in Name or other property of the form element and revealed with
Inspect.</p>
<p> All error handling and error suggestions should be considered
as</p>
<p>instructions and cues necessary to complete the form. This is
regardless of whether the errors are detected before or after a
submission/page reload or when errors are handled as the user enters
information (error handling can be addressed in many ways). If error
messages and alerts receive focus, then error instructions and cues do
not need to be programmatically associated with a form field.</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  <strong>[SW
only]</strong> The Name of a component does not match its visual label
<em><strong>Section 508 Failure</strong></em> o Fails 1194.21(l):
Forms.</p>
<p><em><strong>Conditions</strong></em>  <strong>[SW only]</strong> The
Role of a component does not accurately reflect its</p>
<p>function.</p>
<p>o Fails 1194.21(l): Forms.</p>
<p> <strong>[SW only]</strong> The State of components with focus is
not "focused,</p>
<p>focusable".</p>
<p>o Fails 1194.21(l): Forms.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p> <strong>[SW only]</strong> The State of checkboxes and radio
buttons does not show</p>
<p>that an item is selected correctly.</p>
<p>o Fails 1194.21(l): Forms.</p>
<p> <strong>[SW only]</strong> Instructions and cues (including whether
a field is considered</p>
<p>'required') are not related to their components.</p>
<p>o Fails 1194.21(l): Forms.</p>
<p> <strong>[SW only]</strong> The Value property is incorrect for text
input fields.</p>
<p>o Fails 1194.21(f): Input text</p>
<p> <strong>[Web only]</strong> LABEL FOR and ID are used, but not as
valid HTML</p>
<p>o Fails 1194.22(n): Labels for forms.</p>
<p> <strong>[Web only]</strong> For a form field, the TITLE attribute
is the sole means of</p>
<p>providing information (i.e., there is no additional screen text or
visual</p>
<p>context).</p>
<p>o Fails 1194.22(n): Labels for forms.</p>
<p> <strong>[Web only]</strong> Instructions and cues are not related
(through LABEL,</p>
<p>TITLE, or ARIA attribute) to their respective input components.</p>
<p>o Fails 1194.22(n): Labels for forms.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  The Name of a
component does not match it's visual label</p>
<p><em><strong>WCAG2 Failure</strong></em> o Fails 1.3.1 Info and
relationships.</p>
<p><em><strong>Conditions</strong></em> o Fails 3.3.2 Labels or
instructions.</p>
<p> The Role of a component does not accurately reflect its
function.</p>
<p>o Fails 1.3.1 Info and relationships</p>
<p>o Fails 3.3.2 Labels or instructions.</p>
<p> The State of checkboxes and radio buttons does not show that an
item</p>
<p>is selected correctly.</p>
<p>o Fails 1.3.1 Info and relationships</p>
<p> Instructions and cues are not related to their components.</p>
<p>o Fails 1.3.1 Info and relationships.</p>
<p>o Fails 3.3.2 Labels or instructions.</p>
<p> The Value property is incorrect for text input fields.</p>
<p>o Fails 1.3.1 Info and relationships</p>
<p> Label for and ID are used, but not as valid HTML</p>
<p>o Fails 1.3.1 Info and relationships.</p>
<p>o Fails 3.3.2 Labels or instructions.</p>
<p> For a form field, the TITLE attribute is the sole means of
providing</p>
<p>information (i.e., there is no additional screen text or visual
context).</p>
<p>o Fails 3.3.2 Labels or instructions.</p>
<p> Instructions and cues are not related (through label, title, or
ARIA</p>
<p>attribute) to their respective input components.</p>
<p>o Fails 1.3.1 Info and relationships</p>
<p>o Fails 3.3.2 Labels or instructions.</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#11</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Requirement Test</strong></em>  Labels, instructions,
directions and cues necessary to complete a form
<em><strong>Results</strong></em> are correctly associated with their
respective input components</p>
<p>programmatically.</p>
<p>o Passes Baseline Requirement #11</p>
<p> There are no form input components.</p>
<p>o Not applicable (Baseline Requirement #11)</p>
<p><em><strong>Advisory: Tips for</strong></em>  Keyboard access for
Title content is available in Internet Explorer 11 for
<em><strong>streamlined test</strong></em> Windows 8.1 and 10. It may be
useful to notify testers to pause while</p>
<p><em><strong>processes</strong></em> tabbing through interactive
content with a TITLE attribute to see if</p>
<p>TITLE content is revealed during Keyboard Navigation testing.</p>
<p> Forms still have to be covered by all other tests that are
applicable</p>
<p>(e.g., Keyboard, focus (visible), focus (order)).</p>
<p> Instructions for interpreting and assessing the 'Fieldset' tags
that are</p>
<p>revealed by WAT can be incorporated into streamlined tests.</p>
<p> If multiple ARIA attributes are used on one element, additional
user</p>
<p>testing may be needed to provide conclusive results. It should be
noted for testers that when using Inspect32, the properties are listed
in MSAA mode as "Role", "Name", etc.; but in UI Automation mode they are
listed a "LegacyIAccessible.Role", "LegacyIAccessible.Name", etc.</p>
<p> In testing form fields with Java Ferret, it may be necessary to
type into</p>
<p>the field, then TAB out of the field, then SHIFT+TAB back into the
field in order to reveal the Value property.</p>
<p> Examples of code and screenshots with testing tool results are
highly</p>
<p>recommended to help testers.</p>
<p><span id="Baseline_Tests_for_Software___We_44"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>12. Page Titles</p>
<p><em><strong>Requirement</strong></em> 12. Programmatically identify
Page Titles.</p>
<p><em><strong>Rationale</strong></em> Page titles appear in the title
bar of the browser or software window (and in</p>
<p>the tabs where multiple tabs in a single window are used). If there
is no programmatically defined page title, visually capable users can
assimilate the content quickly to know where they are. However,
non-visual users will have to navigate through the content to know what
page they are on, which can take an undue amount of time.</p>
<p>Screen reader technologies will announce the programmatically defined
page title when the user is browsing between tabs and between
windows.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.31(a): Use
without vision</p>
<p>508 1194.31(b): Use with low vision</p>
<p>WCAG2: 2.4.2 Page titled</p>
<p>Tools Necessary <em><strong>None</strong></em></p>
<p><em><strong>Test Instruction 1:</strong></em> a. Examine the title
bar and/or the tab of the current page or software</p>
<p>Finding Applicable <em><strong>window.</strong></em></p>
<p>Components</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Check that the page
title is a meaningful representation / indication of</p>
<p><em><strong>Inspecting/Using</strong></em> the content. The title
should be in plain language (rather than code).</p>
<p>Components <em>Note:</em></p>
<p> <strong>[SW only]</strong> Some software may not use the title bar.
It may be necessary</p>
<p>to use ALT-TAB to cycle through open applications, or look in the</p>
<p>Windows Taskbar.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  No page title in
plain language.</p>
<p><em><strong>Section 508 Failure</strong></em> o Fails 1194.31(a): Use
without vision. <em><strong>Conditions</strong></em> o Fails 1194.31(b):
Use with low vision.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  No page title in
plain language.</p>
<p><em><strong>WCAG2 Failure</strong></em> o Fails 2.4.2 Page titled</p>
<p>Conditions</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#12</p>
<p><em><strong>Requirement Test</strong></em>  There is a page title in
plain language.</p>
<p><em><strong>Results</strong></em> o Passes Baseline Requirement
#12</p>
<p><em><strong>Advisory: Tips for</strong></em>  Standard software
convention is to use OS platform components which
<em><strong>streamlined test</strong></em> include an application title
bar. Some applications may not use the title</p>
<p><em><strong>processes</strong></em> bar, but should still be required
to present their names to AT when</p>
<p>switching between applications.</p>
<p><span id="Baseline_Tests_for_Software___We_45"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>13. Data Tables (headers)</p>
<p><em><strong>Requirement</strong></em> 13. Column and row header cells
of data tables must be programmatically</p>
<p>identified.</p>
<p><em><strong>Rationale</strong></em> For users with vision, the
process of determining what headers go with a</p>
<p>data cell is usually straightforward, especially when formatting such
as bold letters and shading is applied to the headers. For users of
screen reading software, however, things like 'bold' and 'shaded' have
no useful meaning, so using styles and formatting to identify headers
does not work. Instead, row and column headers must have programmatic
markup to enable them to be identified by the screen reading
software.</p>
<p>On all data tables, column and row headers must be identified.</p>
<p>Notes:</p>
<p> Data tables are those tables where the information in a cell
requires a</p>
<p>row or column header to adequately describe the cell's contents. If a
table is used for placement of components on the page for visual
aesthetics, then it is a layout table. This test applies to data tables
only.</p>
<p> Complex data tables are defined as those that have two or more
levels</p>
<p>of headers, and/or include split or merged cells.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(d): Name,
Role, State</p>
<p>508 1194.22(g): Identify row and column headers</p>
<p>WCAG2: 1.3.1 Info and Relationships</p>
<p>Tools Necessary <em><strong>WAT, Inspect</strong></em></p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find data
tables:</p>
<p><em><strong>Finding Applicable</strong></em>  <strong>[Web
only]</strong> Use WAT (Tables - Table Borders) to find where
<em><strong>Components</strong></em> table markup has been used.
Identify which tables are data</p>
<p>tables (to test) and which are layout tables (to ignore).</p>
<p> <em>[SW only]</em> Visually inspect the content to find data
tables.</p>
<p>Note:</p>
<p> <strong>[Web only]</strong> If color is used extensively on the
page, the table borders</p>
<p>may not be easily distinguishable using the above WAT test. If this
is the case, use WAT (Tables - Show Data Tables).</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Identify all of the
headers for each data cell (some cell headers may not</p>
<p><em><strong>Inspecting/Using</strong></em> be in the same row and/or
column as the data cell). <em><strong>Components</strong></em> b. Reveal
the markup assigned to row and column headers:</p>
<p> <strong>[Web only]</strong> Use WAT (Tables – Show Data Tables).
Each row</p>
<p>and column header must have either a SCOPE="row | col",
SCOPE="rowgroup | colgroup", or an ID="x". If ID is used, data cells
must refer to the associated header cell's ID in order for the header to
pass this test.</p>
<p> <strong>[SW only]</strong> Use Inspect to examine each header cell.
The Name</p>
<p>must match the screen text. The Role must be accurate (table, column
header, or row header). Some software do not have a header property. It
is acceptable to include the header cell information in each appropriate
data cell. In this case, use Inspect to examine the data cells to
determine if header cells have been identified correctly.</p>
<p>c. Only data tables with one or two header levels may employ
<strong>[Web only]</strong></p>
<p>the SCOPE="row | col | rowgroup | colgroup" attributes if all
headers</p>
<p>are in the same row and/or column or group as the data cell. Data</p>
<p>tables with more than two header levels, or with headers that are not
in</p>
<p>the same row and/or column as the data cell, must use HEADER/ID.</p>
<p>(ID can be used on a table with any number of header levels, and</p>
<p>complex tables.)</p>
<p>d. An image of a data table, with its contents described in Alternate
text,</p>
<p>will fail this test. Data tables must be marked up programmatically.
e. For tables that use TD SCOPE, determine whether the <strong>[Web
only]</strong></p>
<p>page is coded in HTML 4.01 or HTML5. Press F12 or view source to</p>
<p>inspect the DOCTYPE.</p>
<p>a. means the page is coded in HTML5. b. means the page is coded
in</p>
<p>HTML 4.01.</p>
<p>c. In HTML5,TD SCOPE is not supported (only TH SCOPE is</p>
<p>supported).</p>
<p>Note:</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em><strong>Test Instruction 3a:</strong></em>  <strong>[Web
only]</strong> A data table does not have its row and/or column header
<em><strong>Section 508 Failure</strong></em> cells correctly marked
programmatically. <em><strong>Conditions</strong></em> o Fails
1194.22(g): Identify row and column headers.</p>
<p> <strong>[SW only]</strong> A data table does not have its row
and/or column header</p>
<p>cells correctly marked programmatically.</p>
<p>o Fails 1194.21(d): Name, Role, State.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  A data table does
not have its row and/or column header cells correctly <em><strong>WCAG2
Failure</strong></em> marked programmatically.</p>
<p><em><strong>Conditions</strong></em> o Fails 1.3.1 Info and
Relationships.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#13</p>
<p><em><strong>Requirement Test</strong></em>  Data tables have their
row and/or column header cells correctly marked
<em><strong>Results</strong></em> programmatically.</p>
<p>o Passes Baseline Requirement #13</p>
<p> There are no data tables.</p>
<p>o Not applicable (Baseline Requirement #13)</p>
<p><em><strong>Advisory: Tips for</strong></em>  Worked examples would
be a great help for testers. <em><strong>streamlined test</strong></em>
 Testing should include data table cell mappings (Baseline Test #14).
<em><strong>processes</strong></em>  In HTML 4.01, TH SCOPE is
preferred over TD SCOPE for headers.</p>
<p>However, TD is acceptable at this time.</p>
<p> A calendar / date picker that has headers (Sun, Mon, Tues etc.)
may</p>
<p>need to be treated as a data table. The visual information must be
provided programmatically for each element of the calendar (year, day,
month, blackout days, etc.).</p>
<p> Although not prohibited by this test, data table structural
elements such</p>
<p>as ‘TH’ should not appear in Layout tables, as it is an example of
bad coding. Adding ARIA ‘Role=presentation’ can solve this coding
problem. See also Note F46 under ‘Understanding WCAG 1.3.1’ on the WCAG
website</p>
<p><span id="Baseline_Tests_for_Software___We_48"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>14. Data Tables (cell-header association)</p>
<p><em><strong>Requirement</strong></em> 14. Data cells on complex
tables must include markup to associate the data</p>
<p>cell with the correct header.</p>
<p><em><strong>Rationale</strong></em> Complex data tables are defined
as those that have two or more levels of</p>
<p>headers, and/or include split or merged cells. On complex tables,
markup is needed to define which headers are associated with data cells,
so that screen reader users can determine where they are for any given
cell or set of cells.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.21(d): Name,
Role, State</p>
<p>508 1194.22(h): Associate Data with Headers</p>
<p>WCAG2: 1.3.1 Info and Relationships</p>
<p>Tools Necessary <em><strong>WAT, Inspect</strong></em></p>
<p><em><strong>Test Instruction 1:</strong></em> a. Find data
tables:</p>
<p><em><strong>Finding Applicable</strong></em>  <strong>[Web
only]</strong> Use WAT (Tables - Table Borders) to find where
<em><strong>Components</strong></em> table markup has been used.
Identify which tables are data</p>
<p>tables (to test) and which are layout tables (to ignore).</p>
<p> <strong>[SW only]</strong> Visually inspect the content to find
data tables.</p>
<p>Notes:</p>
<p> <strong>[Web only]</strong> If color is used extensively on the
page, the table borders</p>
<p>may not be easily distinguishable using the above WAT test. If this
is</p>
<p>the case, use WAT (Tables - Show Data Tables).</p>
<p> If a data cell’s header is not in its row or column, treat it as a
complex</p>
<p>table.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 2:</strong></em> a. Identify all of the
headers for each data cell (some cell headers may not</p>
<p><em><strong>Inspecting/Using</strong></em> be in the same row and/or
column as the data cell). <em><strong>Components</strong></em> b. Reveal
the markup assigned to data cells:</p>
<p> <strong>[Web only]</strong> Use WAT (Tables – Show Data
Tables).</p>
<p> <strong>[SW only]</strong> Use Inspect to examine each data cell.
The Name</p>
<p>must match the screen text and include column and row header
information. The Role must be accurate (cell</p>
<p>c. Where a data table has a maximum of 2 levels of headers,
<strong>[Web only]</strong></p>
<p>SCOPE (row/col/rowgroup/colgroup) is acceptable if all headers are in
the same row and/or column or group as the data cell.</p>
<p>d. Check any data table that should identify its column or row
<strong>[Web only]</strong></p>
<p>headers with ID or SCOPE:</p>
<p> Either:</p>
<p>o Each data cell must have a TD HEADERS="x y", where</p>
<p>"x y" refers to the correctly associated headers (TH</p>
<p>ID="x" on one header and ID="y" on the second header)</p>
<p> Or:</p>
<p>o Each data cell is correctly associated to all its relevant</p>
<p>headers by use of SCOPE="row | col | rowgroup |</p>
<p>colgroup".</p>
<p> Where cell headers are not in the same row and/or column as</p>
<p>the data cell, check that each ID / HEADER association is
correct.</p>
<p>e. In HTML5, TD SCOPE is not supported (only TH SCOPE is <strong>[Web
only]</strong></p>
<p>supported).</p>
<p> If TD SCOPE is used, determine whether the page is coded in</p>
<p>HTML 4.01 or HTML5. Press F12 or view source to inspect the
DOCTYPE.</p>
<p>o means the page is coded in</p>
<p>HTML5.</p>
<p>o means the page is</p>
<p>coded in HTML 4.01.</p>
<p> In HTML 4.01:</p>
<p>o IDs must start with a letter (starting with numbers is</p>
<p>prohibited).</p>
<p>o After the first letter, any number of letters (a to z, A to Z),</p>
<p>digits (0 to 9), hyphens (-), underscores (_), colons (:)</p>
<p>and periods (.) are allowed.</p>
<p> In HTML5:</p>
<p>o IDs can have any value as long as it is unique, not the</p>
<p>empty string, and does not contain spaces.</p>
<p>f. Where data cells are associated with multiple headers (e.g.,
Headers</p>
<p>are 'Sales... January... Pending', and data is '575'), each header
association must be explicitly made in each data cell.</p>
<p>Notes:</p>
<p> An image of a data table, with its contents described in Alternate
text,</p>
<p>will fail this test. Data tables must be marked up
programmatically.</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em><strong>Test Instruction 3a:</strong></em>  <strong>[Web
only]</strong> A complex data table has data cells that do not have
<em><strong>Section 508 Failure</strong></em> associations with header
cells correctly marked programmatically.
<em><strong>Conditions</strong></em> o Fails 1194.22(h): Associate Data
with Headers.</p>
<p> <strong>[SW only]</strong> A complex data table has data cells that
do not have</p>
<p>associations with header cells correctly marked programmatically.</p>
<p>o Fails 1194.21(d): Name, Role, State.</p>
<p><em><strong>Test Instruction 3b:</strong></em>  A complex data table
has data cells that do not have associations with <em><strong>WCAG2
Failure</strong></em> header cells correctly marked programmatically.
<em><strong>Conditions</strong></em> o Fails 1.3.1 Info and
Relationships.</p>
<p>Test Instruction 3c: <em><strong> Any failure in
3a</strong></em></p>
<p><em><strong>Baseline</strong></em> o Fails Baseline Requirement
#14</p>
<p><em><strong>Requirement Test</strong></em>  Data cells of complex
tables have their associations with header cells
<em><strong>Results</strong></em> correctly marked programmatically.</p>
<p>o Passes Baseline Requirement #14</p>
<p> There are no data tables.</p>
<p>o Not applicable (Baseline Requirement #14)</p>
<p><em><strong>Advisory: Tips for</strong></em>  Worked examples would
be a great help for testers. <em><strong>streamlined test</strong></em>
 Testing should include data table headers.
<em><strong>processes</strong></em></p>
<p><span id="Baseline_Tests_for_Software___We_51"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>15. Headings</p>
<p><em><strong>Requirement</strong></em> 15. <strong>[Web only]</strong>
Headings must be programmatically identified and must</p>
<p>match the visual outline level.</p>
<p><em><strong>Rationale</strong></em> Headings are used to visually and
semantically break up content to make it</p>
<p>easier to read, easier to find and understand relevant information,
and so on. Headings can be visually marked using text formatting such as
bold, underline, or combinations (e.g., bold, underlined, and large font
means a major heading).</p>
<p>Screen reader technologies cannot automatically infer meaning from
formatting changes. A given piece of text may be in italics because it
is emphasizing a point, or because it is a heading. Because there is no
way to infer meaning, headings can use visual formatting, but they must
also be programmatically identified for identification with AT.</p>
<p>Notes:</p>
<p> The requirement should not be construed to require headings in
place</p>
<p>of headers in data tables.</p>
<p> This requirement does not mean that headings be added; it means
that</p>
<p>where headings are identifiable through visual formatting, they must
be programmatically identified.</p>
<p> Any visual representations of heading level (e.g., major
section,</p>
<p>section, subsection) must be matched by the programmatic heading
level (i.e., major section = level 1, section = level 2, sub-section =
level 3). Matching the programmatic level with the visual level is
essential for proper comprehension of the content for non-visual
users.</p>
<p><em><strong>Related Standards</strong></em> 508 1194.31(a): Use
without vision</p>
<p>508 1194.31(b): Use with low vision</p>
<p>WCAG2: 1.3.1 Info and Relationships</p>
<p>Tools Necessary <em><strong>WAT</strong></em></p>
<p><em><strong>Test Instruction 1:</strong></em> a. Visually identify
where headings are used on the page, through <em><strong>Finding
Applicable</strong></em> formatting or use of white space, boxes or
other visual separators. <em><strong>Components</strong></em></p>
<p><em><strong>Test Instruction 2:</strong></em> a. Use the WAT
(Structure - Headings, Structure - Heading Structure) to</p>
<p><em><strong>Inspecting/Using</strong></em> reveal headings and the
hierarchy used. <em><strong>Components</strong></em> b. Check that any
visual headings are also marked as headings,</p>
<h1 id="section">, </h1>
<h2 id="etc.">etc. </h2>
<p>c. Check that the Heading levels match the visual structure.</p>
<p><em>Test Instruction 3a:</em>  Visually apparent headings are not
programmatically identified.</p>
<p><em>Section 508 Failure</em> o Fails 1194.31(a): Use without vision.
<em>Conditions</em> o Fails 1194.31(b): Use with low vision.</p>
<p> Programmatically identified heading levels do not match the
visual</p>
<p>outline level.</p>
<p>o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3b:</em>  Visually apparent headings are not
programmatically identified.</p>
<p><em>WCAG2 Failure</em> o Fails 1.3.1 Info and Relationships</p>
<p><em>Conditions</em>  Programmatically identified heading levels do
not match the visual</p>
<p>outline level.</p>
<p>o Fails 1.3.1 Info and Relationships</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #15</p>
<p><em>Requirement Test</em>  Visually apparent headings are
programmatically identified AND <em>Results</em> heading levels match
the visual outline level.</p>
<p>o Passes Baseline Requirement #15</p>
<p> There are no visually apparent headings.</p>
<p>o Not applicable (Baseline Requirement #15)</p>
<p><em>Advisory: Tips for</em>  If a page appears to have logical
separable sections, but there are no <em>streamlined test</em> headings,
it might be worth pointing out to the authors that identifying</p>
<p><em>processes</em> such sections through headings might be useful for
all users.</p>
<p> HTML section headings are used to provide structure on a web
page,</p>
<p>facilitating faster comprehension. However, some designers may
use</p>
<p>heading tags for non-heading purposes, such as text styling to
call</p>
<p>visual attention to content. Such uses deviate from the primary
purpose</p>
<p>of headings, which is to provide information on how the content on
the</p>
<p>page is structured. It might be worth pointing out to the designers
that</p>
<p>using heading tags for non-headings can cause confusion for non-</p>
<p>visual users.</p>
<p> Examples would be helpful to illustrate headings that do and do
not</p>
<p>match their visual structure.</p>
<p><span id="Baseline_Tests_for_Software___We_53"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>16. Links and User controls</p>
<p><em>Requirement</em> 16. Links and/or user controls must have
meaningful names that describe</p>
<p>the unique destination, function, and/or purpose of the control for
assistive technology.</p>
<p><em>Rationale</em> To aid navigation with screen reading AT software,
users can call up a list</p>
<p>of links on a web page or software screen. Users can read through
content and decide which of the links in the content they wish to follow
(i.e., they do not have to navigate back to the link itself).</p>
<p>In order to provide links to end users, there are a number of common
methods in practice that render a list of links unhelpful. Say each item
for sale has a 'click here' link next to it, and the user calls up the
list of links. The list will have multiple 'click here' links that are
not distinguishable. Another common problem occurs when the links only
contain URLs, and the purpose of each link may not be apparent.</p>
<p>It is therefore required to use meaningful and unique names for links
and user controls, to aid navigation and use by AT.</p>
<p>Note:</p>
<p> Links and user controls in image maps are defined by coordinates,
and</p>
<p>their name and purpose are conveyed through title attribute, or
ALT-text attribute.</p>
<p><em>Related Standards</em> 508 1194.21(d): Name, Role, State</p>
<p>508 1194.22(l): Functional Text for Scripts</p>
<p>508 1194.31(a): Use without vision</p>
<p>508 1194.31(b): Use with low vision</p>
<p>WCAG2: 2.4.4 Link Purpose (In Context)</p>
<p><em>Tools Necessary</em> WAT, Inspect/Java Ferret</p>
<p>Test Instruction 1: <em>a. Find all links:</em></p>
<p><em>Finding Applicable</em>  [Web only] Use WAT ( Doc Info – List
Links) <em>Components</em>  [SW only] Scan the content to find links
and other user controls.</p>
<p>Notes:</p>
<p> Some links may contain images.</p>
<p> Some links may be contained in image maps.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 2: <em>a.</em> Examine each link / user control:</p>
<p><em>Inspecting/Using</em>  [Web only] Use WAT (Doc Info - List
Links) to show on a <em>Components</em> separate page all link URLs,
name and title attribute (if any).</p>
<p> [SW only] Use Inspect/Java Ferret to examine the Name, Role</p>
<p>and State of each link / user control.</p>
<p>b. Check that each link / user control on the page has a unique
screen</p>
<p>text name, or has a non-unique name augmented by a unique title</p>
<p>attribute.</p>
<p>c. Use WAT (Doc Info – JavaScript/New Window Links) to [Web only]</p>
<p>check for script scripted elements on the page. Check that the
elements</p>
<p>have a descriptive name in the links list.</p>
<p>d. The method in step a, showing a list of links, helps in [ Web
only]</p>
<p>checking that link names and titles (if any) are meaningful and
unique</p>
<p>when spoken in isolation. If there is any doubt that a link is
meaningful</p>
<p>in the context of surrounding information, other WAT checks can
be</p>
<p>used to show links and pertinent attributes on the screen,
including</p>
<p>WAT (Structure - Show Other Elements - "a"), (Doc Info - Show
Titles),</p>
<p>(Images - Show Images).</p>
<p>Notes:</p>
<p> [Web only] The list of links will include all client-side image
map</p>
<p>hotspots. The hotspots are links which must be checked in this test.
 Step d is to help identify whether a link is meaningful to a user of
the</p>
<p>application; not whether it is meaningful to the tester. For example,
a</p>
<p>link named "X17-88.docx" may not make sense to a tester, but in</p>
<p>reviewing the rest of the page it may be clear that it would make
sense</p>
<p>to a typical user of the application. Links that are
ambiguous/repetitive</p>
<p>("Click here, Click here, Click here") are covered separately in step
b.  Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em>Test Instruction 3a:</em>  A scripted element does not have a
descriptive name.</p>
<p><em>Section 508 Failure</em> o Fails 1194.22(l): Functional Text for
Scripts. <em>Conditions</em> o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p> [SW only] Software controls do not have a descriptive, unique
Name</p>
<p>property</p>
<p>o Fails 1194.21(d): Name, Role, State.</p>
<p> [SW only] Software controls have incorrect Role and/or State</p>
<p>o Fails 1194.21(d): Name, Role State.</p>
<p> The destination, function, and/or purpose of a link / control is
not</p>
<p>contained in the screen text, name, title attribute, or ALT-text
attribute</p>
<p>o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p> Each link / control is not uniquely identified.</p>
<p>o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3b:</em>  A scripted element does not have a
descriptive name.</p>
<p><em>WCAG2 Failure</em> o Fails 2.4.4 Link Purpose (In Context)</p>
<p><em>Conditions</em>  Controls do not have a descriptive, unique Name
property</p>
<p>o Fails 2.4.4 Link Purpose (In Context)</p>
<p> The destination, function, and/or purpose of a link / control is
not</p>
<p>contained in the screen text, name, title attribute, or ALT-text
attribute</p>
<p>o Fails 2.4.4 Link Purpose (In Context)</p>
<p> Each link / control is not uniquely identified.</p>
<p>o Fails 2.4.4 Link Purpose (In Context)</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #16</p>
<p><em>Requirement Test</em>  The destination, function, and/or purpose
of the link is contained in the <em>Results</em> screen text, title
attribute, or ALT-text attribute AND each link is</p>
<p>uniquely identified.</p>
<p>o Passes Baseline Requirement #16</p>
<p> There are no links or user controls.</p>
<p>o Not applicable (Baseline Requirement #16)</p>
<p><em>Advisory: Tips for</em>  This test incorporates the link
elements within client side image maps. <em>streamlined test</em> There
is a separate test for the existence of server side image maps</p>
<p>processes <em>(#27).</em></p>
<p> The List of Links provided by the WAT tool may also include a
"close</p>
<p>window" link which is a WAT function, not a part of the code of the
page. This link can be safely ignored in the test.</p>
<p> For Multi-state controls in software, follow the test for
multi-state</p>
<p>controls.</p>
<p><span id="Baseline_Tests_for_Software___We_56"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>17. Language</p>
<p><em>Requirement</em> 17. [Web only] A default language must be
programmatically identified for</p>
<p>each page, and for passages that use a language other than the
default. Exceptions: proper names, technical terms, or foreign words
that have become part of the vernacular.</p>
<p><em>Rationale</em> When a site is in one language but has certain
pages that are in a different</p>
<p>language, or sections within a page that use a different language, it
is necessary to programmatically identify both the default language and
the change of language. Screen reader technologies can switch their
language pronunciation, but only if there is code to identify the proper
language. If language changes are not identified, for a screen reader
user, the speech will sound awkward at best, or unintelligible at
worst.</p>
<p>Note:</p>
<p> Interface components that are part of the browser and/or
operating</p>
<p>system, such as dialog boxes, browser status bar, browser title
bar,</p>
<p>browser menus, are not included in this test (they are outside of
the</p>
<p>control of the Web page and its language settings).</p>
<p><em>Related Standards</em> 508 1194.31(a): Use without vision</p>
<p>508 1194.31(b): Use with low vision</p>
<p>WCAG2: 3.1.1 Language of Page</p>
<p>WCAG2: 3.1.2 Language of Parts</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Identify the default language of the
page, and any passages that differ</p>
<p><em>Finding Applicable</em> to the default language.</p>
<p>Components</p>
<p><em>Test Instruction 2:</em> a. Use the WAT (Doc Info - Show Lang
Attributes) to reveal the language</p>
<p><em>Inspecting/Using</em> settings applied to the page and to
sections of the page. <em>Components</em> b. Check that there is an
accurate default language attribute set for the</p>
<p>page.</p>
<p>c. Check that there is an accurate language attribute set for each
passage</p>
<p>that is different from the page's default language.</p>
<p>d. Check that the language attributes match the actual language
used.</p>
<p>Exceptions: proper names, technical terms, or foreign words that
have</p>
<p>become part of the vernacular.</p>
<p><em>Test Instruction 3a:</em>  The language for the page is not
programmatically set.</p>
<p><em>Section 508 Failure</em> o Fails 1194.31(a): Use without vision.
<em>Conditions</em> o Fails 1194.31(b): Use with low vision.</p>
<p> A passage (content, image descriptions, form labels etc.) that
differs</p>
<p>from the default language of the page is not programmatically
identified.</p>
<p>o Fails 1194.31(a): Use without vision.</p>
<p>o Fails 1194.31(b): Use with low vision.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3b:</em>  The language for the page is not
programmatically set.</p>
<p><em>WCAG2 Failure</em> o Fails 3.1.2 Language of Parts</p>
<p><em>Conditions</em>  A passage (content, image descriptions, form
labels etc.) that differs</p>
<p>from the default language of the page is not programmatically
identified.</p>
<p>o Fails 3.1.2 Language of Parts</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #17</p>
<p><em>Requirement Test</em>  The language for the page is
programmatically set, AND any passages <em>Results</em> that differ to
the default language of the page are programmatically</p>
<p>identified.</p>
<p>o Passes Baseline Requirement #17</p>
<p><em>Advisory: Tips for</em>  This test is Web only, because in
software, language is controlled at the <em>streamlined test</em> OS
platform level.</p>
<p>processes</p>
<p><span id="Baseline_Tests_for_Software___We_58"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>18. Audio (transcripts)</p>
<p><em>Requirement</em> 18. Audio-only content must be accompanied by
transcripts.</p>
<p><em>Rationale</em> Audio-only content includes speeches, and other
meaningful audio. Some</p>
<p>users will not be able to hear the audio. Therefore, there needs to
be a text only version of what is being said, and/or a description of
the relevant sounds.</p>
<p>Notes:</p>
<p> Audio-only content may be delivered as a file, as streamed file, or
other</p>
<p>means.</p>
<p> Other short sounds such as confirmation beeps and error
notifications</p>
<p>are not included in this requirement.</p>
<p><em>Related Standards</em> 508 1194.22(a): Equivalent text
descriptions</p>
<p>WCAG2: 1.1.1 Non-text Content</p>
<p>WCAG2: 1.2.1 Audio-only and Video-only (Prerecorded)</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Find interface components that play
audio-only content when activated.</p>
<p><em>Finding Applicable</em> b. [Web only] Use the WAT (Doc Info -
List of Multimedia files) to identify <em>Components</em> audio-only
files.</p>
<p>c. Find other audio content that plays automatically or upon
activation of a</p>
<p>control.</p>
<p>Notes:</p>
<p> An audio-only file may be stored in a synchronized media format.
For</p>
<p>example, a speech is stored in a file where the video is simply a
static</p>
<p>graphic of the speaker's name and location. If the video component
is</p>
<p>static, and the information displayed in the video is also available
as</p>
<p>screen text, then treat the file as audio-only.</p>
<p> [Web only] Sometimes the WAT list of files will not work correctly.
This</p>
<p>can be due to scripted links. If the WAT list does not work, a
manual</p>
<p>inspection may be required to determine relevant files for
testing.</p>
<p><em>Test Instruction 2:</em> a. Check that the transcript is
accessible screen text (i.e., an image of a</p>
<p><em>Inspecting/Using</em> transcript with no ALT-text would not be
sufficient to pass this test).</p>
<p><em>Components</em> b. Open the transcript and play the audio-only
content.</p>
<p>c. Check that the information in the transcript is an accurate and
complete</p>
<p>representation of the audio-only content. Note the inclusion or
absence</p>
<p>of relevant items in addition to dialogue, such as doors banging,
sirens</p>
<p>wailing and so forth.</p>
<p><em>Test Instruction 3a:</em>  Audio-only content is not accompanied
by a transcript.</p>
<p><em>Section 508 Failure</em> o Fails 1194.22(a): Equivalent text
descriptions.</p>
<p><em>Conditions</em>  Audio-only content is accompanied by a
transcript that is not accurate</p>
<p>or complete.</p>
<p>o Fails 1194.22(a): Equivalent text descriptions.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3b:</em>  Audio-only content is not accompanied
by a transcript.</p>
<p><em>WCAG2 Failure</em> o Fails: 1.1.1 Non-text Content</p>
<p><em>Conditions</em> o Fails 1.2.1 Audio-only and Video-only
(Prerecorded)</p>
<p> Audio-only content is accompanied by a transcript that is not
accurate</p>
<p>or complete.</p>
<p>o Fails: 1.1.1 Non-text Content</p>
<p>o Fails 1.2.1 Audio-only and Video-only (Prerecorded)</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #18</p>
<p><em>Requirement Test</em>  Audio-only content has a transcript
supplied AND the transcript is an <em>Results</em> accurate and complete
representation of the audio-only content.</p>
<p>o Passes Baseline Requirement #18</p>
<p> There are no audio-only files.</p>
<p>o Not applicable (Baseline Requirement #18)</p>
<p><em>Advisory: Tips for</em>  If audio is synchronized with video,
slides, animations, or other time-<em>streamlined test</em> based visual
media, then use the synchronization test instead. <em>processes</em> 
The proximity of the audio content to any control to reveal the
transcript</p>
<p>is covered by the focus (order) test (i.e., whether there is a
logical order for content).</p>
<p><span id="Baseline_Tests_for_Software___We_60"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>19. Video (descriptions)</p>
<p><em>Requirement</em> 19. Video-only content must be accompanied by
descriptions.</p>
<p><em>Rationale</em> For video-only content (e.g., animations of
processes), some users will not</p>
<p>be able to see the content (delivered as a video-only file, or other
animation). Therefore, there needs to be an alternative delivery method
for the information. The alternative description can be text, or an
audio file describing what is being shown.</p>
<p>Notes:</p>
<p> [Web only] If no description is supplied (either in text or in an
audio</p>
<p>file), the Section 508 failure defaults to a missing text
description.  Other short animation effects such as button activation
highlights and</p>
<p>file shrink/disappear on closure are not included in this
requirement.</p>
<p><em>Related Standards</em> 508 1194.21(h): Animation</p>
<p>508 1194.22(a): Equivalent text descriptions</p>
<p>508 1194.24(d): Video descriptions</p>
<p>WCAG2: 1.1.1 Non-text Content</p>
<p>WCAG2: 1.2.1 Audio-only and Video-only (Prerecorded)</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Find interface components that play
video-only content when activated.</p>
<p><em>Finding Applicable</em> b. [Web only] Use the WAT (Doc Info -
List of Multimedia files) to identify <em>Components</em> video-only
files.</p>
<p>Notes:</p>
<p> A video-only file may be stored in a synchronized media format.
For</p>
<p>example, an animation is stored in a file where the audio is absent
or</p>
<p>can be considered incidental (e.g., background music that does
not</p>
<p>influence the comprehension of the animation). If the audio
component</p>
<p>is absent or incidental, then treat the file as video-only.</p>
<p> [Web only] Sometimes the WAT list of files will not work correctly.
This</p>
<p>can be due to scripted links. If the WAT list does not work, a
manual</p>
<p>inspection may be required to determine relevant files for
testing.</p>
<p><em>Test Instruction 2:</em> a. Check that the description is
available: <em>Inspecting/Using</em>  as accessible screen text (i.e.,
an image of a description with no <em>Components</em> ALT-text would not
be sufficient to pass this test), or</p>
<p> as an audio file.</p>
<p>b. Open the description and play the video-only content. c. Check
that the information in the description is an accurate and</p>
<p>complete representation of the video-only content.</p>
<p>Note:</p>
<p> When accompanying a video-only file with an audio description file,
the</p>
<p>files do not have to be synchronized.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3a:</em>  [Web only] A video-only file does not
have a description. <em>Section 508 Failure</em> o Fails 1194.22(a):
Equivalent text descriptions.</p>
<p><em>Conditions</em>  [Web only] A video-only file has text
descriptions that are not accurate</p>
<p>or complete.</p>
<p>o Fails 1194.22(a): Equivalent text descriptions.</p>
<p> [Web only] A video-only file has audio descriptions that are
not</p>
<p>accurate or complete.</p>
<p>o Fails 1194.24(d): Video descriptions.</p>
<p> [SW only] An animation in SW does not have descriptions (text
or</p>
<p>audio).</p>
<p>o Fails 1194.21(h): Animation.</p>
<p> [SW only] An animation has descriptions (text or audio) that are
not</p>
<p>accurate or complete.</p>
<p>o Fails 1194.21(h): Animation.</p>
<p><em>Test Instruction 3b:</em>  Video-only content does not have a
description.</p>
<p><em>WCAG2 Failure</em> o Fails: 1.1.1 Non-text Content</p>
<p><em>Conditions</em> o Fails 1.2.1 Audio-only and Video-only
(Prerecorded)</p>
<p> Video-only content has text descriptions that are not accurate
or</p>
<p>complete OR audio descriptions that are not accurate or complete.</p>
<p>o Fails: 1.1.1 Non-text Content</p>
<p>o Fails 1.2.1 Audio-only and Video-only (Prerecorded)</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #19</p>
<p><em>Requirement Test</em>  Video-only content has descriptions
supplied AND the descriptions are <em>Results</em> an accurate and
complete representation of the video-only content.</p>
<p>o Passes Baseline Requirement #19</p>
<p> There is no video-only (/animation) content.</p>
<p>o Not applicable (Baseline Requirement #19)</p>
<p><em>Advisory: Tips for</em>  If video is synchronized with audio,
meaningful sounds, narration, or <em>streamlined test</em> other time
based visual media, then use the synchronization test <em>processes</em>
instead.</p>
<p> The proximity of the video content to any control to reveal the</p>
<p>description is covered by the focus (order) test (i.e., whether there
is a logical order for content).</p>
<p><span id="Baseline_Tests_for_Software___We_62"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>20. Synchronized media (captions)</p>
<p><em>Requirement</em> 20. Synchronized media must have captions that
are time-synchronized</p>
<p>with the dialog and relevant sounds.</p>
<p><em>Rationale</em> Synchronized media is a presentation consisting of
time-synchronized</p>
<p>video and audio. Synchronized media includes public information
films, Web casts, press conferences, and online training
presentations.</p>
<p>A prime consideration for synchronized media is that some users will
not be able to hear the content well or hear it at all. Therefore there
needs to be another mode to provide the audio information. This usually
means captions (text showing what is being said, and other relevant
sounds). Captions need to be available, but do not necessarily need to
be turned on by default. For example, users who need captions can switch
them on with a control (usually a 'CC' button for Closed Captions). If
there is no means of switching modes, then the default mode must be
accessible (i.e., Open Captions).</p>
<p>Because captions must be time-synchronized, separate transcripts will
not meet this requirement on their own.</p>
<p><em>Related Standards</em> 508 1194.22(b): Synchronized
Alternatives</p>
<p>508 1194.24(c): Captions</p>
<p>WCAG2: 1.2.2 Captions (Prerecorded)</p>
<p>WCAG2: 1.2.4 Captions (Live)</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Find interface components that play
synchronized media when <em>Finding Applicable</em> activated. This
includes streaming media, and streaming live events.</p>
<p><em>Components</em> b. Use the WAT (Doc Info - List of Multimedia
files) to find [Web only]</p>
<p>synchronized media files.</p>
<p>Notes:</p>
<p> A synchronized media file may be used to store non-synchronized</p>
<p>media format. For example, a speech is stored in a synchronized
media</p>
<p>file where the video is simply a static image of the speaker's face
with a</p>
<p>caption. If the video component is static, and the information
displayed</p>
<p>in the video is also available as screen text, then treat the file as
audio-</p>
<p>only rather than synchronized media.</p>
<p> [Web only] Sometimes the WAT list of files will not work correctly.
This</p>
<p>can be due to scripted links. If the WAT list does not work, a
manual</p>
<p>inspection may be required to determine relevant files for
testing.</p>
<p><em>Test Instruction 2:</em> a. Enable the captioning for the
synchronized media. <em>Inspecting/Using</em> b. Play the synchronized
media content. <em>Components</em> c. Check that the information in the
captions is an accurate, synchronized</p>
<p>and complete representation of the dialogue and other relevant
sounds</p>
<p>in the synchronized media.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3a:</em>  Synchronized media does not have
captions.</p>
<p><em>Section 508 Failure</em> o Fails 1194.24(c): Captions.</p>
<p><em>Conditions</em>  Synchronized media has captions that are not
accurate or complete.</p>
<p>o Fails 1194.24(c): Captions.</p>
<p> Synchronized media has captions that are not synchronized with
dialog</p>
<p>and relevant sounds.</p>
<p>o Fails 1194.22(b): Synchronized Alternatives.</p>
<p><em>Test Instruction 3b:</em>  Synchronized media does not have
captions.</p>
<p><em>WCAG2 Failure</em> o Fails 1.2.2 Captions (Prerecorded)</p>
<p><em>Conditions</em>  Synchronized media has captions that are not
accurate or complete.</p>
<p>o Fails 1.2.2 Captions (Prerecorded)</p>
<p> Synchronized media has captions that are not synchronized with
dialog</p>
<p>and relevant sounds.</p>
<p>o Fails 1.2.2 Captions (Prerecorded)</p>
<p> Captions are not provided for streaming of live media events.</p>
<p>o Fails 1.2.4 Captions (Live)</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #20</p>
<p><em>Requirement Test</em>  Synchronized media has captions AND the
captions are an accurate, <em>Results</em> synchronized and complete
representation of the audio contained in the</p>
<p>synchronized media.</p>
<p>o Passes Baseline Requirement #20</p>
<p> There is no synchronized media.</p>
<p>o Not applicable (Baseline Requirement #20)</p>
<p><em>Advisory: Tips for</em>  Testing synchronized media is different
to testing audio-only content <em>streamlined test</em> (test #18).</p>
<p><em>processes</em>  Testing synchronized captions AND synchronized
descriptions at the</p>
<p>same time may be more time effective, so long as both are given equal
weight.</p>
<p> It is preferable to have the media on the main page for all
users</p>
<p>captioned and audio described, as current technology permits this. It
is acceptable to have separate files for captioned and/or audio
described versions.</p>
<p> Testing of synchronized media players is usually a software test of
the</p>
<p>plug-in.</p>
<p><span id="Baseline_Tests_for_Software___We_64"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>21. Synchronized media (descriptions)</p>
<p><em>Requirement</em> 21. Synchronized media must have audio
descriptions that are time-</p>
<p>synchronized with the video.</p>
<p><em>Rationale</em> Synchronized media is a presentation consisting of
time-synchronized</p>
<p>video and audio. Synchronized media includes public information
films, Web casts, press conferences, and online training
presentations.</p>
<p>A prime consideration for synchronized media is that some users will
not be able to see the content well or see it at all. Therefore there
needs to be another mode to provide descriptions of the visual
information. In synchronized media, this usually means additional
narration inserted during breaks in the dialog, describing visual events
and cues.</p>
<p>Audio descriptions need to be available, but are not required to be
turned on by default. For example, users who need descriptions can
switch them on with a control. If there is no means of switching modes,
then the audio descriptions must be enabled by default.</p>
<p>The Alternative presentation of information must allow understanding
of the relevant information. For example, descriptions might include the
looks on people's faces, people handing items to each other, or who has
entered the room.</p>
<p>Synchronization is required for the Alternative presentation modes.
Because descriptions must be synchronized, a text transcript will not
meet this requirement. Synchronized media content cannot be played and
then followed by a summary of the visual events. Instead, the visual
events must be described as they are happening, usually during breaks in
dialogue.</p>
<p><em>Related Standards</em> 508 1194.22(b): Synchronized
Alternatives</p>
<p>508 1194.24(d): Descriptions</p>
<p>WCAG2: 1.2.3 Audio Description or Media Alternative (Prerecorded)</p>
<p>WCAG2: 1.2.5 Audio Description (Prerecorded)</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Find interface components that play
synchronized media when <em>Finding Applicable</em> activated.</p>
<p><em>Components</em> b. Use the WAT (Doc Info - List of Multimedia
files) to find [Web only]</p>
<p>synchronized media files.</p>
<p>Notes:</p>
<p> A synchronized media file may be used to store non-synchronized</p>
<p>media format. For example, an animation is stored in a
synchronized</p>
<p>media file where the audio is absent or can be considered
incidental</p>
<p>(e.g., background music that does not influence the comprehension
of</p>
<p>the animation). If the audio component is absent or incidental,
then</p>
<p>treat the file as video-only.</p>
<p> [Web only] Sometimes the WAT list of files will not work correctly.
This</p>
<p>can be due to scripted links. If the WAT list does not work, a
manual</p>
<p>inspection may be required to determine relevant files for
testing.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 2:</em> a. Enable the audio descriptions for the
synchronized media. <em>Inspecting/Using</em> b. Play the synchronized
media content. <em>Components</em> c. Check that the audible description
is an accurate, synchronized and</p>
<p>complete representation of the relevant visual events in the
synchronized media.</p>
<p><em>Test Instruction 3a:</em>  Synchronized media is not audio
described.</p>
<p><em>Section 508 Failure</em> o Fails 1194.24(d): Descriptions.</p>
<p><em>Conditions</em>  Synchronized media is audio described, but the
descriptions are not</p>
<p>accurate or complete.</p>
<p>o Fails 1194.24(d): Descriptions.</p>
<p> Synchronized media is audio described, but the descriptions are
not</p>
<p>synchronized with video.</p>
<p>o Fails 1194.22(b): Synchronized Alternatives.</p>
<p><em>Test Instruction 3b:</em>  Synchronized media is not audio
described.</p>
<p><em>WCAG2 Failure</em> o Fails 1.2.3 Audio Description or Media
Alternative (Prerecorded) <em>Conditions</em> o Fails 1.2.5 Audio
Description (Prerecorded)</p>
<p> Synchronized media is audio described, but the descriptions are
not</p>
<p>accurate or complete.</p>
<p>o Fails 1.2.3 Audio Description or Media Alternative (Prerecorded) o
Fails 1.2.5 Audio Description (Prerecorded)</p>
<p> Synchronized media is audio described, but the descriptions are
not</p>
<p>synchronized with video.</p>
<p>o Fails 1.2.3 Audio Description or Media Alternative (Prerecorded) o
Fails 1.2.5 Audio Description (Prerecorded)</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #21</p>
<p><em>Requirement Test</em>  Synchronized media is audio described AND
the descriptions are an <em>Results</em> accurate, synchronized and
complete representation of the video</p>
<p>contained in the synchronized media.</p>
<p>o Passes Baseline Requirement #21</p>
<p> There is no synchronized media.</p>
<p>o Not applicable (Baseline Requirement #21)</p>
<p><em>Advisory: Tips for</em>  Testing synchronized media is different
from testing video-only content <em>streamlined test</em> (test
#19).</p>
<p><em>processes</em>  Testing synchronized captions AND synchronized
descriptions at the</p>
<p>same time may be more time effective, so long as both are given equal
weight.</p>
<p> It is preferable to have the media on the main page for all
users</p>
<p>captioned and audio described, as current technology permits this. It
is acceptable to have separate files for captioned and/or audio
described versions.</p>
<p> Testing of synchronized media players is usually a software test of
the</p>
<p>plug-in.</p>
<p><span id="Baseline_Tests_for_Software___We_66"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>22. Style-sheet non-dependence</p>
<p><em>Requirement</em> 22. [Web only] Web pages must be structured so
that their reading order is</p>
<p>consistent whether they are viewed with or without an associated
style sheet. Layout and appearance of the page may change visually, as
long as the logical reading order is maintained.</p>
<p><em>Rationale</em> Style sheets are a means to provide visual
formatting information to</p>
<p>complement a Web page's content.</p>
<p>The original intention behind style sheets was to separate
presentation from content. The text, images, links etc. comprise the
'content', and things such as font choice, background color, link
underlining etc. comprise the presentation 'style'.</p>
<p>A Web page should in theory always be readable and functional without
the developer’s style sheet, since content is separate from
presentation. However, it is possible for developers to inadvertently
deliver content through style. For example, a background image can be
applied with a style sheet, but if that background image also contains
important information, such as an organization's name, logo and contact
details, then content is no longer separate from presentation.</p>
<p>Because of their particular visual needs, some people with visual
impairments create their own style sheets (font color, background color,
etc.) to replace the provided style sheet. When content is not properly
separated from presentation, it becomes difficult or impossible to read
the information on the screen. Therefore, pages must be tested with
style sheet information removed, to ensure that all content is still
being delivered to the user.</p>
<p>For additional information/guidance, see also WCAG 2 glossary entry
"Accessibility Supported"</p>
<p><em>Related Standards</em> 508 1194.22(d): Readable without Style
Sheets</p>
<p>WCAG2: 1.1.1 Non-text content</p>
<p>WCAG2: 1.3.2 Meaningful Sequence</p>
<p>WCAG2: 1.3.3 Sensory Characteristics</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Look at the content on the original
page to determine the logical order.</p>
<p><em>Finding Applicable</em> b. Find hidden content for comparison
purposes. <em>Components</em></p>
<p><em>Test Instruction 2:</em> a. Use WAT (IE - Toggle CSS). Check for
the following: <em>Inspecting/Using</em>  Do any meaningful images
disappear (i.e., images that are set <em>Components</em> to show only
with the style sheet)</p>
<p> Does the order of the content change from the logical order to
a</p>
<p>non-logical order?</p>
<p> Does any content become illegible due to overlapping?  Is hidden
content from the original page still available?  Does any unintended
content get introduced (i.e., content that</p>
<p>never exists on the page but may be called up on other</p>
<p>pages.)?</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3a:</em>  When CSS is disabled, meaningful
images disappear</p>
<p><em>Section 508 Failure</em> o Fails 1194.22(d): Readable Style
Sheets.</p>
<p><em>Conditions</em>  When CSS is disabled, the content order is not
logical</p>
<p>o Fails 1194.22(d): Readable Style Sheets.</p>
<p> When CSS is disabled, content becomes illegible.</p>
<p>o Fails 1194.22(d): Readable Style Sheets.</p>
<p> When CSS is disabled, content becomes unavailable.</p>
<p>o Fails 1194.22(d): Readable Style Sheets.</p>
<p> When CSS is disabled, unintended content shows on the page.</p>
<p>o Fails 1194.22(d): Readable Style Sheets.</p>
<p><em>Test Instruction 3b:</em>  When CSS is disabled, meaningful
images disappear</p>
<p><em>WCAG2 Failure</em> o Fails 1.1.1 Non-text content.</p>
<p><em>Conditions</em>  When CSS is disabled, the content order is not
logical</p>
<p>o Fails 1.3.2 Meaningful Sequence</p>
<p>o Fails 1.3.3 Sensory Characteristics</p>
<p> When CSS is disabled, content becomes illegible.</p>
<p>o Fails 1.3.3 Sensory Characteristics</p>
<p> When CSS is disabled, content becomes unavailable.</p>
<p>o Fails 1.3.2 Meaningful Sequence</p>
<p> When CSS is disabled, unintended content shows on the page.</p>
<p>o Fails 1.3.2 Meaningful Sequence</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #22</p>
<p><em>Requirement Test</em>  When CSS is disabled, all meaningful
images stay AND the order <em>Results</em> remains logical AND content
remains legible AND content remains</p>
<p>available AND unintended content does not show on the page.</p>
<p>o Passes Baseline Requirement #22</p>
<p> Style sheets are not used.</p>
<p>o Not applicable (Baseline Requirement #22)</p>
<p><em>Advisory: Tips for</em>  It may be necessary to refresh the page
(F5) a number of times to <em>streamlined test</em> ensure that all
pertinent CSS images are found. <em>processes</em>  A tester may find
it easiest to toggle the style sheet view while testing</p>
<p>or use two browser windows.</p>
<p> For content on the original page that is in layout tables, it is
possible to</p>
<p>produce a linearized representation that may be useful in determining
whether a logical order is used. To linearize table content, use WAT
(Tables - Linearize). This can be used to supplement the test, but is
not part of the main test.</p>
<p><span id="Baseline_Tests_for_Software___We_68"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>23. Frames</p>
<p><em>Requirement</em> 23. [Web only] Frames and iframes must have a
meaningful description</p>
<p>using the title or name attribute.</p>
<p><em>Rationale</em> Frames are a means of separating out sections of a
Web page into</p>
<p>different navigable regions.</p>
<p>To mouse users, the separation of a Web page into sections means that
they can scroll the information in one frame without affecting another
frame. Keyboard only users who are able to see can navigate between
frames (F6 key is the browser default for this function).</p>
<p>Non-visual users can also use the keyboard to navigate between
frames, but if there is no programmatic name for the frames, the user
has to read through the content of each frame in an attempt to discern
where the information they need might be. This can take a long time, and
can lead nonvisual users to make errors. For this reason, it is
necessary for each frame to include a descriptive name. The name should
make sense when spoken in isolation as the user navigates between
frames.</p>
<p><em>Related Standards</em> 508 1194.22(i): Descriptive Frame
Titles</p>
<p>WCAG2: 1.1.1 Non-text Content</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Use WAT (Select Frames – Frame Name /
Title) to determine whether</p>
<p>Finding Applicable <em>there are frames.</em></p>
<p>Components</p>
<p><em>Test Instruction 2:</em> a. Use WAT (Select Frames – Frame Name /
Title) to check each frame</p>
<p><em>Inspecting/Using</em> and iframe for a meaningful and unique
content description in the Name</p>
<p><em>Components</em> or TITLE attribute.</p>
<p><em>Test Instruction 3a:</em>  A frame or iframe does not have a
meaningful and unique title or Name.</p>
<p><em>Section 508 Failure</em> o Fails 1194.22(i): Descriptive Frame
Titles. <em>Conditions</em></p>
<p><em>Test Instruction 3b:</em>  A frame or iframe does not have a
meaningful and unique title or name.</p>
<p><em>WCAG2 Failure</em> o Fails 1.1.1 Non-text Content</p>
<p>Conditions</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #23</p>
<p><em>Requirement Test</em>  Each frame or iframe has a meaningful and
unique title or name. <em>Results</em></p>
<p>o Passes Baseline Requirement #23</p>
<p> There are no frames or iframes</p>
<p>o Not applicable (Baseline Requirement #23)</p>
<p><em>Advisory: Tips for</em>  This test may be related to Page Titles
(#12). <em>streamlined test</em></p>
<p>processes</p>
<p><span id="Baseline_Tests_for_Software___We_69"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>24. Alternate pages</p>
<p><em>Requirement</em> 24. [Web only] When the primary page/site cannot
be made accessible, an</p>
<p>Alternative page/site must contain equivalent and up-to-date
content.</p>
<p><em>Rationale</em> An ' Alternate Page' is an accessible version
containing the same</p>
<p>information as the primary page. Alternate pages will usually contain
text in place of the inaccessible content from the primary page. For
example, a complex organizational chart may be written in prose. The
text must be equivalent, and it must be kept up-to-date.</p>
<p>An ' Alternate Page' should only be provided for accessibility when
the primary page cannot be made accessible. The accessible version must
contain the same information as the primary page.</p>
<p>Note:</p>
<p> The information should be 'equivalent', but by definition this is
not going</p>
<p>to be 'exactly the same'. The main points, themes, concepts etc. that
the authors are trying to get across in the primary content should also
come across in the alternate page. For example, if a complex chart on
the primary page shows a year with a small increases in earnings in Q2
and a large decrease in Q2, and the text discusses why these trends seem
to be occurring, the Alternate page should convey the trends, and the
high and low data points of interest. An alternate page that just gave
all the data points in linear form, with no highlighting of the trends
under consideration, would not be considered equivalent.</p>
<p><em>Related Standards</em> 508 1194.22(k): Text only or Alternative
versions</p>
<p>WCAG2: Conformance requirement #1: Conforming alternate version</p>
<p>Tools Necessary <em>None</em></p>
<p><em>Test Instruction 1:</em> a. Determine whether there are any
Alternate pages/sites by examining</p>
<p><em>Finding Applicable</em> the content (pay particular attention to
content containing maps, <em>Components</em> directions, complex charts
etc.).</p>
<p><em>Test Instruction 2:</em> a. Compare the content of the primary
page/site and the Alternate <em>Inspecting/Using</em> page/site, noting
any information differences and/or out-of-date <em>Components</em>
material.</p>
<p><em>Test Instruction 3a:</em>  An Alternate page/site is provided,
but the information is not equivalent <em>Section 508 Failure</em> to
and up to date with the primary page/site. <em>Conditions</em> o Fails
1194.22(k): Text only or Alternative versions.</p>
<p><em>Test Instruction 3b:</em>  An Alternate page/site is provided,
but the information is not equivalent <em>WCAG2 Failure</em> to and up
to date with the primary page/site. <em>Conditions</em> o Fails
Conformance requirement #1: Conforming alternate</p>
<p>version</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #24</p>
<p><em>Requirement Test</em>  An alternate page/site contains
equivalent, up-to-date information <em>Results</em> compared with the
primary page/site.</p>
<p>o Passes Baseline Requirement #24</p>
<p> There are no alternate pages/sites.</p>
<p>o Not applicable (Baseline Requirement #24)</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Advisory: Tips for</em>  This is a test of equivalency of the
information on an Alternate <em>streamlined test</em> page/site.</p>
<p><em>processes</em>  The Alternate page must pass all relevant tests
for accessibility.</p>
<p> The decision of whether to actually provide an Alternate page/site
or</p>
<p>not will rest with individual agencies and their policies.</p>
<p> Agencies may need to make policies on their definition of
'up-to-date'</p>
<p>(i.e., immediately with any changes, within an hour, within a day
etc.).  Historically, text-only versions of a Web page were employed
because</p>
<p>plug-ins and synchronized media were not accessible. Over time,
the</p>
<p>accessibility of plug-ins and the content they contain (e.g.,
electronic</p>
<p>documents, forms, training courses in flash) has improved to the
point</p>
<p>where it is very rare that the primary page cannot be made
accessible.</p>
<p>However, maps and directions, and very complex diagrams and
charts</p>
<p>remain difficult to make accessible without Alternate pages.</p>
<p><span id="Baseline_Tests_for_Software___We_71"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>25. Time outs</p>
<p><em>Requirement</em> 25. Users of assistive technology must be
alerted about a pending time out,</p>
<p>and users must be able to request more time to complete their
task.</p>
<p><em>Rationale</em> Messages and/or instructions to the user
requesting their response within a</p>
<p>given time are typically associated with sites that require a secure
login. This includes both server time outs and client side security time
outs.</p>
<p>People who use AT such as screen reader software or voice input
software may require more time than other users to assimilate the
information and execute the controls on a Web page or software
application. Because AT users may need more time, applications that have
a time out must provide (a) prior notification/warning that a time out
is about to occur, and (b) a means for the user to request more
time.</p>
<p>For additional information/guidance, see also WCAG 2 Understanding
Guideline 2.2</p>
<p><em>Related Standards</em> 508 1194.22(p): Time out notification</p>
<p>WCAG2: 2.2.1 Timing Adjustable</p>
<p>Tools Necessary <em>Stopwatch.</em></p>
<p><em>Test Instruction 1:</em> a. Determine if there is a timeout
function from the application's <em>Finding Applicable</em>
documentation, or by leaving the session inactive for a period.
<em>Components</em></p>
<p><em>Test Instruction 2:</em> a. Check that an alert for a timeout is
displayed, rather than the <em>Inspecting/Using</em> application exiting
without warning.</p>
<p><em>Components</em> b. Check that the user is offered the option to
continue their task (i.e.,</p>
<p>request more time), or exit.</p>
<p>c. Check that the alert message is displayed for at least 20
seconds</p>
<p>before the page actually times out.</p>
<p>Notes:</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p><em>Test Instruction 3a:</em>  A time-out occurs, and users are not
alerted.</p>
<p><em>Section 508 Failure</em> o Fails 1194.22(p): Time out
notification.</p>
<p><em>Conditions</em>  A time-out occurs, and users cannot request
more time.</p>
<p>o Fails 1194.22(p): Time out notification.</p>
<p> A time-out occurs, and is displayed for less than 20 seconds.</p>
<p>o Fails 1194.22(p): Time out notification.</p>
<p><em>Test Instruction 3b:</em>  A time-out occurs, and users are not
alerted.</p>
<p><em>WCAG2 Failure</em> o Fails 2.2.1 Timing Adjustable</p>
<p><em>Conditions</em>  A time-out occurs, and users cannot request
more time.</p>
<p>o Fails 2.2.1 Timing Adjustable</p>
<p> A time-out occurs, and is displayed for less than 20 seconds.</p>
<p>o Fails 2.2.1 Timing Adjustable</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #25</p>
<p><em>Requirement Test</em>  A time-out occurs, users are alerted, AND
users can request more time, <em>Results</em> AND the length of time
that the alert is displayed is 20 seconds or</p>
<p>more.</p>
<p>o Passes Baseline Requirement #25</p>
<p> There is no time out function.</p>
<p>o Not applicable (Baseline Requirement #25)</p>
<p><em>Advisory: Tips for</em>  Remind testers that when the time-out
occurs, visible focus should shift <em>streamlined test</em> to the
time-out alert.</p>
<p><em>processes</em>  In some cases, it may be necessary to contact
the application authors</p>
<p>to clarify the conditions under which time-outs occur.</p>
<p> Security policies at a given agency may require certain systems to
time-</p>
<p>out less than 20 seconds after the alert is first displayed. If
security</p>
<p>policies do override this requirement (via 'undue burden' tests,
for</p>
<p>example), the time should still be reasonable enough for the AT to
user</p>
<p>to read through and navigate to their choice (e.g., 'continue' or
'exit').</p>
<p>Additional testing with AT (screen readers, speech recognition
etc.)</p>
<p>may be needed to determine whether the time is considered</p>
<p>reasonable.</p>
<p><span id="Baseline_Tests_for_Software___We_73"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>26. Image maps</p>
<p><em>Requirement</em> 26. [Web only] Server-side image maps may not be
used. Client-side</p>
<p>image-maps must be used instead.</p>
<p><em>Rationale</em> Server-side image maps are not keyboard accessible
and incompatible</p>
<p>with assistive technologies used by people with disabilities. Any
server-side image maps must therefore be replaced by client-side
ones.</p>
<p><em>Related Standards</em> 508 1194.22(e) Redundant text links on
server-side image maps</p>
<p>508 1194.22(f) Client side not server side</p>
<p>WCAG 2: Conformance requirement #4: Only accessibility ways</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Use WAT (Images - Show Image Maps) to
determine whether there are</p>
<p><em>Finding Applicable</em> image maps in use.</p>
<p>Components</p>
<p><em>Test Instruction 2:</em> a. Use WAT (Images - Show Image Maps) to
list the types of image map</p>
<p>Inspecting/Using <em>in use.</em></p>
<p>Components</p>
<p><em>Test Instruction 3a:</em>  A server-side image map is in
use.</p>
<p><em>Section 508 Failure</em> o Fails 1194.22(e) Redundant text links
on server-side image <em>Conditions</em> maps.</p>
<p>o Fails 1194.22(f) Client side not server side.</p>
<p>Note:</p>
<p> The presence of any server-side image is technically a failure
of</p>
<p>1194.22(f). Because this standard has been interpreted to mean that
server-side image maps must be replaced by client-side image maps,
1194.22(e) becomes an automatic failure when server-side images are
present.</p>
<p><em>Test Instruction 3b:</em>  A server-side image map is in
use.</p>
<p><em>WCAG2 Failure</em> o Fails Conformance requirement #4: Only
accessibility ways <em>Conditions</em></p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #26</p>
<p><em>Requirement Test</em>  There are no server-side image maps (only
client-side image maps are <em>Results</em> used).</p>
<p>o Passes Baseline Requirement #26</p>
<p> There are no image maps.</p>
<p>o Not applicable (Baseline Requirement #26)</p>
<p><em>Advisory: Tips for</em>  This test is only for the type of image
maps used. Server-side images <em>streamlined test</em> are rare. All
other aspects of image maps (use with keyboard, link <em>processes</em>
names, ALT-text names etc.) are covered by other tests.</p>
<p><span id="Baseline_Tests_for_Software___We_74"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>27. Plug-in Links</p>
<p><em>Requirement</em> 27. [Web only] When public-facing pages utilize
content delivered via plug-</p>
<p>ins, or contain downloadable content that must be opened with a
separate application, a link to obtain the plug-in and/or application
must be provided.</p>
<p><em>Rationale</em> It may be necessary or desirable to deliver
content that must be displayed</p>
<p>in a separate application, or via a browser plug-in, such as PDF and
other electronic document files, and synchronized media.</p>
<p>For public facing Web pages, there must be a link provided either
directly (i.e., next to the content) or indirectly (i.e., a page
providing links to all plug-ins used on a site).</p>
<p>Notes:</p>
<p> Most interfaces will notify users that a plug-in is missing, and
will help</p>
<p>the user find and install the necessary plug-in. Some plug-ins do not
do</p>
<p>this, which is why this requirement remains in place.</p>
<p> Agencies usually restrict the software that can be installed on
users'</p>
<p>computers, and will also provide commonly used plug-ins as part
of</p>
<p>their enterprise architecture. For this reason, it is not required to
provide</p>
<p>a link to plug-ins for non-public facing (i.e., intranet) pages.</p>
<p><em>Related Standards</em> 508 1194.22(m): Plug-ins</p>
<p>Tools Necessary <em>WAT</em></p>
<p><em>Test Instruction 1:</em> a. Use WAT (Images - Show Images). If
non-HTML images are used,</p>
<p><em>Finding Applicable</em> WAT will not mark up the code (i.e.,
there will be no alerts given for a</p>
<p><em>Components</em> lack of ALT-text). Open the context menu (right
click) on the image to</p>
<p>determine the type of file in use.</p>
<p>b. Use the WAT (Doc Info - List of Downloadable files) to identify
files that</p>
<p>must be viewed with a separate application.</p>
<p>Notes:</p>
<p> Sometimes the WAT list of files will not work correctly. This can
be due</p>
<p>to scripted links. If the WAT list does not work, a manual
inspection</p>
<p>may be required to determine relevant files for testing.</p>
<p><em>Test Instruction 2:</em> a. Use WAT (Structure - Show Other
Elements - "a") to highlight all links</p>
<p><em>Inspecting/Using</em> on the page, or WAT (Doc Info - List
Links). Determine whether there</p>
<p><em>Components</em> are links to the required plug-ins.</p>
<p>Notes:</p>
<p> If the WAT command does not work or is unavailable, find all links
on a</p>
<p>page by TABbing through the page content.</p>
<p> Some images may contain links.</p>
<p><em>Test Instruction 3a:</em>  A link is not provided for required
plug-ins on public-facing pages.</p>
<p><em>Section 508 Failure</em> o Fails 1194.22(m): Plug-ins.</p>
<p>Conditions</p>
<p>Test Instruction 3b: <em> Not applicable.</em></p>
<p>WCAG2 Failure</p>
<p>Conditions</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #27</p>
<p><em>Requirement Test</em>  Links are provided for required plug-ins
on public-facing pages.</p>
<p><em>Results</em> o Passes Baseline Requirement #27</p>
<p> There are no required plug-ins OR this is not a public-facing
page.</p>
<p>o Not applicable (Baseline Requirement #27)</p>
<p><em>Advisory: Tips for</em>  This is a test of whether there is a
link to get the plug-in / application <em>streamlined test</em> from a
public-facing site.</p>
<p><em>processes</em>  The links to the plug-ins must pass the relevant
baseline test for links.</p>
<p> The plug-in baseline test is a web test for a link to player
software to</p>
<p>access the plug-in's content. However, if the plug-in's content is
software, the plug-in itself would need to be subjected to all relevant
tests for software.</p>
<p> Agencies may need to make policies on which plug-ins to allow
and</p>
<p>use, and whether to require links for plug-ins on internal (intranet)
sites.</p>
<p><span id="Baseline_Tests_for_Software___We_76"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>28. Built-in accessibility features</p>
<p><em>Requirement</em> 28. [SW only] Operating System (OS)
user-configurable accessibility</p>
<p>appearance settings and functions must not be disrupted or disabled
by the software application.</p>
<p><em>Rationale</em> It is possible to write software that controls
various aspects of the OS. The</p>
<p>control commands may inadvertently cause an OS accessibility feature
to deactivate. For example, Sticky Keys is a feature that enables users
to use one finger or pointer to use the control key, the alt key, and
the shift key sequentially (rather than the simultaneously, as they are
ordinarily used). If a developer wanted to reset the keyboard state
because they wanted to turn off the CAPS LOCK indicator, they must take
care not to reset accessibility features at the same time.</p>
<p>It is also possible to override OS accessibility appearance features.
For example, in High Contrast mode, the color settings of standard
windows components are modified throughout the OS. If a developer wanted
to make a special green and brown camouflaged theme for his or her
application, they would specify the exact colors that would be used in
the menus and other window control components. By specifying the exact
colors, rather than adopting system colors, they override the ability of
the user to employ the high contrast settings that they need to access
the application. In this example, an aesthetic preference results in
non-compliance with the requirement not to interfere with the user's
appearance settings.</p>
<p>The accessibility features of Windows 7, Windows 8.1, and 10 (the
platforms for which the baseline tests are written) contain the
following user-configurable accessibility features that should not be
disabled or disrupted by the software application:</p>
<p> All settings in the Ease of Access control panel</p>
<p> System color settings, including high contrast modes  System text
size settings</p>
<p>Note:</p>
<p> This requirement also applies to software that is embedded in a
page</p>
<p>displayed in a Web browser.</p>
<p><em>Related Standards</em> 508 1194.21(b) Built-in Accessibility
Features</p>
<p>508 1194.21(g): OS Individual display attributes</p>
<p>508 194.31(f): Use with physical limitations.</p>
<p>508 1194.31(c): Use without hearing.</p>
<p>WCAG2: 1.4.4 Resize text</p>
<p>WCAG 2: Conformance requirement #5: Non-interference</p>
<p>Tools Necessary <em>None</em></p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 1:</em> a. Close the software application under
test <em>Finding Applicable</em> b. Set the system text size to
200%:</p>
<p><em>Components</em> If the software is embedded in a Web page:</p>
<p> Set the browser zoom control to 200% of normal size.</p>
<p>If the software is running as a stand-alone application:</p>
<p>1. Open the Windows Ease of Access center in the control panel</p>
<p>(Windows Key + U)</p>
<p>2. Choose ‘Make the computer easier to see', then 'Change the</p>
<p>size of text and icons'.</p>
<p>3. Windows 7: 'Set custom text size (DPI)' and set to 200%. 4.
Windows 8.1/10: In the ‘Change only the text size’ section,</p>
<p>select Menu, then select a font size twice the current size. Do the
same for title bars, message boxes, icons, tooltips, and palette
titles.</p>
<p>5. Log out and back in when prompted.</p>
<p>c. Set the display to High Contrast Black: press Left Alt + Left
Shift + Print</p>
<p>Screen keys.</p>
<p>d. Set Sticky Keys to on: press the left shift key 5 times. An icon
will show</p>
<p>in the taskbar notification area to show that Sticky Keys is on.</p>
<p>e. Set Sound Sentry to on:</p>
<p>1. Open the Windows Ease of Access center in the control panel</p>
<p>(Windows Key + U).</p>
<p>2. Choose 'Use text or visual alternatives for sound', then 'Turn
on</p>
<p>visual notification for sounds (Sound Sentry).</p>
<p>f. Restart the software application under test.</p>
<p><em>Test Instruction 2:</em> a. Check that the application adopted
the high contrast appearance <em>Inspecting/Using</em> b. Check and that
the text size has been increased, and that information is</p>
<p><em>Components</em> not cut off because of the larger font size
(scrolling may be necessary,</p>
<p>and is acceptable).</p>
<p>c. Verify that Sticky Keys has not been disrupted in the OS (the icon
in the</p>
<p>taskbar notification area should be showing that Sticky Keys is still
on).</p>
<p>d. Verify that Sticky Keys has not been disrupted in the application.
Find</p>
<p>any text field in the application, and type a mix of upper and lower
case characters using one finger only.</p>
<p>e. Verify that Sound Sentry has not been disrupted in the OS.
Open</p>
<p>Notepad and type Ctrl+L. The Sound Sentry indicator should flash.</p>
<p>Notes:</p>
<p> After this test is complete, reset the OS Accessibility features
(and</p>
<p>browser settings, if applicable) to their default settings, and
restart the application.</p>
<p> Flash and embedded Java content should be tested in IE to
determine</p>
<p>the accessibility of the coded content.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p><em>Test Instruction 3a:</em>  User OS Color settings overridden by
the software application.</p>
<p><em>Section 508 Failure</em> o Fails 1194.21(g): OS Individual
display attributes.</p>
<p><em>Conditions</em>  Text of application did not enlarge, or became
illegible when enlarged.</p>
<p>o Fails 1194.21(g): OS Individual display attributes.</p>
<p> Sticky Keys functionality was disrupted in the application.</p>
<p>o Fails 1194.31(f) Use with physical limitations.</p>
<p> Sound Sentry functionality was disrupted by the application.</p>
<p>o Fails 1194.31(c) Use without hearing.</p>
<p> OS accessibility features (High Contrast, Sticky Keys, Sound
Sentry</p>
<p>and/or system text size (stand-alone software only)) were disrupted
by</p>
<p>the application.</p>
<p>o Fails 1194.21(b) Built-in Accessibility Features.</p>
<p><em>Test Instruction 3b:</em>  User OS Color settings overridden by
the software application.</p>
<p><em>WCAG2 Failure</em> o Fails Conformance requirement #5:
Non-interference</p>
<p><em>Conditions</em>  Text size settings disrupted by the software
application.</p>
<p>o Fails 1.4.4 Resize text</p>
<p>o Fails Conformance requirement #5: Non-interference</p>
<p> OS accessibility features disrupted by the software
application.</p>
<p>o Fails Conformance requirement #5: Non-interference</p>
<p> Sticky Keys functionality disrupted in the application.</p>
<p>o Fails Conformance requirement #5: Non-interference.</p>
<p>Test Instruction 3c: <em> Any failure in 3a</em></p>
<p><em>Baseline</em> o Fails Baseline Requirement #28</p>
<p><em>Requirement Test</em>  User OS color settings, OS text size, and
OS accessibility features are <em>Results</em> not overridden or
disrupted by the software application.</p>
<p>o Passes Baseline Requirement #28</p>
<p><em>Advisory: Tips for</em>  There are other accessibility features
in Windows that could be relevant <em>streamlined test</em> to test
depending on the content of the application. For example, for an</p>
<p><em>processes</em> application that uses sounds a great deal, Sound
Sentry may be worth</p>
<p>testing. A failure of any other Windows accessibility functions would
not</p>
<p>constitute a failure of the baseline test.</p>
<p><span id="Baseline_Tests_for_Software___We_79"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Attachment A - Cross-Reference Tables</p>
<p>Note:</p>
<p>The names for Section 508 tests are provided as short-hand for
reference in the tables that</p>
<p>follow. These are not the official names. For the text of the actual
standards see the original</p>
<p>document<a href="#Baseline_Tests_for_Software___We_3">.</a><a
href="#Top_of_index_html">1 (</a>pag<a
href="#Baseline_Tests_for_Software___We_3">e 4)</a></p>
<p><span id="Baseline_Tests_for_Software___We_80"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Baseline tests (cross-reference table)</p>
<p>No. Baseline test Scope Section 508 coverage WCAG 2 (reference only)
1. Keyboard Both 21 SW (a): Keyboard Accessibility 1.3.1 Info and
relationships</p>
<p>navigation 2.1.1 Keyboard</p>
<p>2.1.2 No Keyboard Trap</p>
<p>2. Focus (visible) Both 21 SW (c): Visual Focus 2.4.7 Focus Visible
3. Focus (order) Both 31 FPC (a): Use without vision 2.4.3 Focus
Order</p>
<p>31 FPC (b): Use with low vision 3.2.3 Consistent Navigation</p>
<p>4. Focus Both 31 FPC (a): Use without vision 2.4.3 Focus Order</p>
<p>(Revealing 31 FPC (b): Use with low vision 3.2.2 On Input</p>
<p>hidden content)</p>
<p>5. Skip-navigation 22 Web (o): Method to Skip 2.4.1 Bypass Blocks
Web</p>
<p>links Repetitive Links only</p>
<p>6. Multi-state Both 21 SW (d): Name, Role, State 1.3.1 Info and
Relationships</p>
<p>components 31 FPC (a): Use without vision 3.2.1 On Focus</p>
<p>31 FPC (b): Use with low vision 3.2.2 On Input</p>
<p>4.1.2 Name, Role, Value</p>
<p>7. Images Both 21 SW (d): Name, Role, State 1.1.1 Non-text
Content</p>
<p>21 SW (e): Bitmap images 3.2.4 Consistent Identification</p>
<p>22 Web (a): Equivalent text</p>
<p>descriptions</p>
<p>8. Color (meaning) Both 21 SW (i): No color dependence to 1.1.1
Non-text Content</p>
<p>convey information 1.4.1 Use of Color</p>
<p>22 Web (c): No color dependence to</p>
<p>convey information</p>
<p>9. Color (contrast) Both 31 FPC (b): Use with low vision 1.4.3
Contrast (Minimum) 10. Flashing Both 21 SW (k): Blinking objects 2.3.1
Three flashes or below</p>
<p>(reserved) threshold 22 Web (j): No flickering Interface</p>
<p>components.</p>
<p>11. Forms Both 21 SW (f): Input text 1.3.1 Info and Relationships</p>
<p>(associated 21 SW (l): Forms 3.3.2 Labels or Instructions</p>
<p>instructions)</p>
<p>22 Web (n): Labels for forms</p>
<p>12. Page Titles Both 31 FPC (a): Use without vision 2.4.2 Page
Titled</p>
<p>31 FPC (b): Use with low vision</p>
<p>13. Data Tables Both 21 SW (d): Name, Role, State 1.3.1 Info and
Relationships</p>
<p>(headers) 22 Web (g): Identify row and column</p>
<p>headers</p>
<p>14. Data Tables Both 21 SW (d): Name, Role, State 1.3.1 Info and
Relationships</p>
<p>(cell-header 22 Web (h): Associate Data with</p>
<p>mapping) Headers</p>
<p>15. Headings 31 FPC (a): Use without vision 1.3.1 Info and
Relationships Web</p>
<p>only 31 FPC (b): Use with low vision</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>No. Baseline test Scope Section 508 coverage WCAG 2 (reference only)
16. Links and user Both 21 SW (d): Name, Role, State 2.4.4 Link Purpose
(In Context):</p>
<p>controls 22 Web (l): Functional Text for</p>
<p>Scripts</p>
<p>31 FPC (a): Use without vision</p>
<p>31 FPC (b): Use with low vision</p>
<p>17. Language 31 FPC (a): Use without vision 3.1.1 Language of Page
Web</p>
<p>only 31 FPC (b): Use with low vision 3.1.2 Language of Parts</p>
<p>18. Audio Both 22 Web (a): Equivalent text 1.1.1 Non-text Content</p>
<p>(transcripts) descriptions 1.2.1 Audio-only and Video-only</p>
<p>(Prerecorded)</p>
<p>19. Video Both 22 Web (a): Equivalent text 1.1.1 Non-text Content</p>
<p>(descriptions) descriptions 1.2.1 Audio-only and Video-only</p>
<p>21 SW (h): Animation (Prerecorded)</p>
<p>24 Multimedia (d): Video</p>
<p>descriptions</p>
<p>20. Synchronized Both 22 Web (b): Synchronized 1.2.2 Captions
(Prerecorded)</p>
<p>media Alternatives 1.2.4 Captions (Live)</p>
<p>(captions) 24 Multimedia (c): Captions</p>
<p>21. Synchronized Both 22 Web (b): Synchronized 1.2.3 Audio
Description or Media</p>
<p>media Alternatives Alternative (Prerecorded)</p>
<p>(descriptions) 24 Multimedia (d): Descriptions 1.2.5 Audio
Description</p>
<p>(Prerecorded)</p>
<p>22. Style-sheet non- 22 Web (d): Readable Style Sheets 1.1.1 Non-text
Content Web</p>
<p>dependence 1.3.2 Meaningful Sequence only</p>
<p>1.3.3 Sensory Characteristics</p>
<p>23. Frames 22 Web (i): Descriptive Frame Titles 1.1.1 Non-text
Content Web</p>
<p>only</p>
<p>24. Alternate pages 22 Web (k): Text only or Alternative Conformance
requirement #1: Web</p>
<p>only versions conforming Alternate version</p>
<p>25. Time outs Both 22 Web (p): Time out notification 2.2.1 Timing
Adjustable</p>
<p>26. Image maps 22 Web (e) Redundant text links on Conformance
requirement #4: only Web</p>
<p>only 17 server-side image maps accessibility ways</p>
<p>22 Web (f) Client side not server</p>
<p>side</p>
<p>27. Plug-in Links 22 Web (m): Plug-ins Not Applicable. Web</p>
<p>only18</p>
<p>17 If Web (f) is a failure, Web (e) is an automatic failure. See test
notes for details.</p>
<p>18 The plug-in baseline test is a web test for a link to player
software to access the plug-in's content.</p>
<p>However, if the plug-in's content is software, the plug-in itself
would need to be subjected to all relevant tests for software.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>No. Baseline test Scope Section 508 coverage WCAG 2 (reference
only)</p>
<p>28. Built-in 21 SW (b) Built-in Accessibility 1.4.4 Resize text
SW</p>
<p>accessibility Features Conformance requirement #5: non-only</p>
<p>features 21 SW (g): OS Individual display interference</p>
<p>attributes</p>
<p>31 FPC (c): Use without hearing</p>
<p>31 FPC (f): Use with physical</p>
<p>limitations</p>
<p><span id="Baseline_Tests_for_Software___We_83"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Section 508 (cross-reference table)</p>
<p>Para. Name Baseline test Scope</p>
<p>21 SW (a) Keyboard Accessibility 1. Keyboard navigation Both</p>
<p>21 SW (b) Built-in Accessibility Features 28. Built-in accessibility
features SW</p>
<p>only</p>
<p>21 SW (c) Visual Focus 2. Focus (visible) Both</p>
<p>4. Focus (Revealing hidden content)</p>
<p>21 SW (d) Name, Role, State 6. Multi-state components Both</p>
<p>7. Images</p>
<p>13. Data Tables (headers)</p>
<p>14. Data Tables (cell-header mapping)</p>
<p>16. Links and user controls</p>
<p>21 SW (e) Bitmap images 7. Images Both</p>
<p>21 SW (f) Input text 11. Forms (associated instructions) Both</p>
<p>21 SW (g) OS Individual display attributes 28. Built-in accessibility
features SW</p>
<p>only</p>
<p>21 SW (h) Animation 19. Video (descriptions) Both</p>
<p>21 SW (i) No color dependence to convey 8. Color (meaning) Both</p>
<p>information</p>
<p>21 SW (j) Variety of color selections Not applicable <em>(see note
below)</em> <em>N/A</em> 21 SW (k) Blinking objects 10. Flashing
(reserved) Both</p>
<p>21 SW (l) Forms 11. Forms (associated instructions) Both</p>
<p>22 Web (a) Equivalent text descriptions 7. Images Both</p>
<p>18. Audio (transcripts)</p>
<p>19. Video (descriptions)</p>
<p>22 Web (b) Synchronized Alternatives 20. Synchronized media
(captions) Both</p>
<p>21. Synchronized media (descriptions)</p>
<p>22 Web (c) No color dependence to convey 8. Color (meaning) Both</p>
<p>information</p>
<p>22 Web (d) Readable Style Sheets 22. Style-sheet non-dependence
Web</p>
<p>only</p>
<p>22 Web (e) Redundant text links on server-side 26. Image maps Web</p>
<p>image maps only</p>
<p>22 Web (f) Client side not server side 26. Image maps Web</p>
<p>only</p>
<p>22 Web (g) Identify row and column headers 13. Data Tables (headers)
Both</p>
<p>22 Web (h) Associate Data with Headers 14. Data Tables (cell-header
mapping) Both</p>
<p>22 Web (i) Descriptive Frame Titles 23. Frames Web</p>
<p>only</p>
<p>22 Web (j) No flickering Interface components. 10. Flashing
(reserved) Both</p>
<p>22 Web (k) Text only or Alternative versions 24. Alternate pages
Web</p>
<p>only</p>
<p>22 Web (l) Functional Text for Scripts 16. Links and user controls
Both</p>
<p>22 Web (m) Plug-ins 27. Plug-in Links Web</p>
<p>only</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Para. Name Baseline test Scope</p>
<p>22 Web (n) Labels for forms 11. Forms (associated instructions)
Both</p>
<p>22 Web (o) Method to Skip Repetitive Links 5. Skip-navigation links
Web</p>
<p>only</p>
<p>22 Web (p) Time out notification 25. Time outs Both</p>
<p>24 Multimedia Captions 20. Synchronized media (captions) Both (c)</p>
<p>24 Multimedia Video descriptions 19. Video (descriptions) Both (d)
21. Synchronized media (descriptions)</p>
<p>31 FPC (a) Use without vision 4. Focus (Revealing hidden content)
Both</p>
<p>6. Multi-state components</p>
<p>12. Page Titles</p>
<p>15. Headings</p>
<p>16. Links and user controls</p>
<p>17. Language (Web only)</p>
<p>31 FPC (b) Use with low vision 4. Focus (Revealing hidden content)
Both</p>
<p>6. Multi-state components</p>
<p>9. Color (contrast)</p>
<p>12. Page Titles</p>
<p>15. Headings</p>
<p>16. Links and user controls</p>
<p>17. Language (Web only)</p>
<p>31 FPC Use without hearing 28. Built-in accessibility features SW</p>
<p>only</p>
<p>31 FPC (f) Use with physical limitations 28. Built-in accessibility
features SW</p>
<p>only</p>
<p>Section 508 standards not included in this baseline:</p>
<p>The Baseline tests include instructions and failure conditions for
all Section 508 standards except the following:</p>
<p>Subpart B - Technical Standards</p>
<p>1194.21 Software applications and operating systems</p>
<p>(j) Variety of color selections</p>
<p>Comment: SW (g) requires that applications do not override user
selected color and contrast selections. Passing SW (g) means that the
user-selectable ranges of colors in the OS (Microsoft Windows for this
baseline test) are available. Because the baseline has standardized on
Windows, SW (j) is automatically met through SW (g) in Baseline #28.
Agency-specific tests may be developed for SW(j) if applications do not
meet SW(g).</p>
<p>1194.22 <em>Web-based</em> intranet and internet information and
applications</p>
<p>(e) Redundant text links on server-side image maps</p>
<p>Comment: Web (f) has been interpreted to mean that server-side image
maps must be replaced by client-side image maps. In Baseline #26, Web
(e) becomes an automatic failure where server-side image maps exist.</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>1194.23 Telecommunications products (all)</p>
<p>Comment: Telecom products are converging with software and Web
browsing capabilities. However, at this time the baseline tests herein
cover use of software and Web sites on PCs (i.e., desktops and
laptops).</p>
<p>1194.24 Video and multimedia products19</p>
<p>(a) Television tuners and captioning</p>
<p>(b) Television tuners and secondary audio program</p>
<p>Comment: The baseline tests herein cover media displayed on PCs only.
<em>(e) User selection of Alternatives</em></p>
<p>Comment: This standard is already covered by the baseline tests.</p>
<p>1194.25 Self-contained, closed products (all)</p>
<p>Comment: The baseline tests cover software and Web sites running on
desktops and laptops, not on public kiosks and similar devices.</p>
<p>1194.26 Desktop and portable computers (all)</p>
<p>Comment: The baseline tests cover software and Web sites running on
desktops and laptops, but not the PC hardware itself.</p>
<p>Subpart C - Functional Performance Criteria</p>
<p>508 1194.31 (d) Use with limited hearing</p>
<p>Comment: The main requirements regarding hearing are already covered
by the Web and multimedia baseline tests. Short sounds such as
confirmation beeps and error notifications are not included in the
Baseline tests.</p>
<p>508 1194.31 (e) Use without speech</p>
<p>Comment: The main requirements regarding use without speech are
already covered by the software and Web baseline tests.</p>
<p>Subpart D - Information, Documentation, and Support (all)</p>
<p>Comment: Printed software documentation, if it is supplied with the
product, is subject to this standard. However, the baseline tests are
for the software itself.</p>
<p>19 The baseline includes the multimedia standards 1194.24(c)
Captions, and 1194.24(d): Descriptions. It</p>
<p>could be argued that these are already covered by the web standard
1124.22(b) which reads: <em>"Equivalent alternatives for any multimedia
presentation shall be synchronized with the presentation".</em> The
problem is that 22(b) does not clearly describe what the "equivalent
alternatives" are. 22(b) does, however, use the term "multimedia" (i.e.,
1194.24). Thus, the interpretation is that the intended "equivalent
alternatives" are captions and descriptions (i.e., 24(c) and 24(d)).</p>
<p><span id="Baseline_Tests_for_Software___We_86"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>WCAG 2.0 (cross-reference table)</p>
<p>Note:</p>
<p>The following table is for reference only. The baseline tests align
with, but do not necessarily cover WCAG 2.0 completely. Following the
baseline tests should not be considered equitable to</p>
<p>WCAG conformance. <a href="#Top_of_index_html">4 (</a>page <a
href="#Baseline_Tests_for_Software___We_5">6)</a></p>
<p>No. Name Baseline test Scope</p>
<p>1.1.1 Non-text Content 7. Images Both</p>
<p>8. Color (meaning)</p>
<p>19. Video (descriptions)</p>
<p>18. Audio (transcripts)</p>
<p>22. Style-sheet non-dependence</p>
<p>23. Frames</p>
<p>1.2.1 Audio-only and Video-only 18. Audio (transcripts)</p>
<p>(Prerecorded) 19. Video (descriptions)</p>
<p>1.2.2 Captions (Prerecorded) 20. Synchronized media (captions) Both
1.2.3 Audio Description or Media Alternative 21. Synchronized media
(descriptions) Both</p>
<p>(Prerecorded) 19. Video (descriptions)</p>
<p>1.2.4 Captions (Live) 20. Synchronized media (captions) Both</p>
<p>1.2.5 Audio Description (Prerecorded) 21. Synchronized media
(descriptions) Both 1.3.1 Info and Relationships 1. Keyboard navigation
Both</p>
<p>6. Multi-state components</p>
<p>11. Forms (associated instructions)</p>
<p>13. Data Tables (headers)</p>
<p>14. Data Tables (cell-header mapping)</p>
<p>15. Headings</p>
<p>1.3.2 Meaningful Sequence 22. Style-sheet non-dependence Web</p>
<p>only</p>
<p>1.3.3 Sensory Characteristics 22. Style-sheet non-dependence Web</p>
<p>only</p>
<p>1.4.1 Use of Color 8. Color (meaning) Both</p>
<p>1.4.3 Contrast (Minimum) 9. Color (contrast) Both</p>
<p>1.4.4 Resize text 28. Built-in accessibility features Both</p>
<p>2.1.1 Keyboard 1. Keyboard navigation Both</p>
<p>2.1.2 No Keyboard Trap 1. Keyboard navigation Both</p>
<p>2.2.1 Timing Adjustable 25. Time outs Both</p>
<p>2.3.1 Three flashes or below threshold 10. Flashing (reserved)
Both</p>
<p>2.4.1 Bypass Blocks 5. Skip-navigation links Web</p>
<p>only</p>
<p>2.4.2 Page Titled 12. Page Titles Both</p>
<p>2.4.3 Focus Order 3. Focus (order) Both</p>
<p>4. Focus (Revealing hidden content)</p>
<p>2.4.4 Link Purpose (In Context): 16. Links Both</p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>No. Name Baseline test Scope</p>
<p>2.4.7 Focus Visible 2. Focus (visible) Both</p>
<p>3.1.1 Language of Page 17. Language Web</p>
<p>only</p>
<p>3.1.2 Language of Parts 17. Language Web</p>
<p>only</p>
<p>3.2.1 On Focus 6. Multi-state components Both</p>
<p>3.2.2 On Input 4. Focus (Revealing hidden content) Both</p>
<p>6. Multi-state components</p>
<p>3.2.3 Consistent Navigation 3. Focus (order) Both</p>
<p>3.3.2 Labels or Instructions 11. Forms (associated instructions) Both
3.2.4 Consistent Identification 7. Images Both</p>
<p>4.1.2 Name, Role, Value 6. Multi-state components Both</p>
<p><em>N/A</em> Conformance requirement #1: 24. Alternate pages Web</p>
<p>conforming Alternate version only</p>
<p><em>N/A</em> Conformance requirement #4: only 26. Image maps Web</p>
<p>accessibility ways only</p>
<p><em>N/A</em> Conformance requirement #5: non- 28. Built-in
accessibility features SW</p>
<p>interference only</p>
<p>WCAG 2.0 Success Criteria Not covered in Baseline Tests</p>
<p>AAA Success criteria (all)</p>
<p>Comment: The baseline tests herein are aligned with the WCAG Level A
and Level AA success criteria. WCAG comments on the more stringent
AAA:</p>
<p>"It is not recommended that Level AAA conformance be required as a
general policy for entire sites because it is not possible to satisfy
all Level AAA Success</p>
<p>Criteria for some content.<a
href="#Baseline_Tests_for_Software___We_5">"</a> <em><a
href="#Top_of_index_html">3 (</a>pag<a
href="#Baseline_Tests_for_Software___We_5">e 6)</a></em></p>
<p>1.4.2 Audio Control</p>
<p>2.2.2 Pause, Stop, Hide</p>
<p>2.4.5 Multiple Ways</p>
<p>2.4.6 Headings and Labels</p>
<p>3.3.1 Error Identification</p>
<p>3.3.4 Error Prevention (Legal, Financial, Data)</p>
<p>4.1.1 Parsing</p>
<p>Comment: The above success criteria do not map to any current Section
508 standard.</p>
<p>3.3.3 Error Suggestion</p>
<p>Comment: Errors are already covered by baseline tests for keyboard
access, focus, labels etc.</p>
<p>1.4.5. Images of Text</p>
<p>Comment: The mapping of the coverage of this success criteria to 508
21a (Equivalent test descriptions) was better served by WCAG 1.1.1
(Non-text Content).</p>
<p>Conformance Requirement #2: F <em>ull Pages</em></p>
<p>Baseline Tests for Software &amp; Web Accessibility</p>
<p>Conformance Requirement #3: Complete Process</p>
<p>Comment: The above requirements are considered a given in Section 508
tests (i.e., the complete Web site must be compliant).</p>
<p>Baseline tests not mapped to WCAG 2.0</p>
<p>28. Plug-in Links</p>
<p>Comment: The above tests is required for Section 508 compliance, but
has no equivalent in WCAG 2.0 AA success criteria or conformance
requirements.</p>
<p><span id="Baseline_Tests_for_Software___We_89"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Attachment B - Flashing content test advisory notes</p>
<p>Agencies must include an evaluation of flashing/blinking content in
their test processes.</p>
<p>However, as of the publication of the current version of baseline
tests, there is no agreed-upon</p>
<p>testing method. The test number 10 is reserved for a future version
of this document when an</p>
<p>agreed-upon test process will be included. The following are advisory
notes relating to tests of</p>
<p>flashing content.</p>
<p>Why to include a flashing content test in a test process</p>
<p>Even though there is no baseline, there are two primary reasons to
include a test: the Section</p>
<p>508 law, and the risk of injury to users.</p>
<p>The Section 508 standards require:</p>
<p>§ 1194.21Software applications and operating systems (k) Software
shall not use flashing or blinking text, objects, or other components
having a flash or blink frequency greater than 2 Hz and lower than 55
Hz.</p>
<p>§ 1194.22Web-based intranet and internet information and
applications. (j) Pages shall be designed to avoid causing the screen to
flicker with a frequency greater than 2 Hz and lower than 55 Hz.</p>
<p>The standards are in place as an attempt to reduce the likelihood of
causing a seizure in a user</p>
<p>with photosensitive epilepsy. It is therefore incumbent on agencies
to apply due diligence to try</p>
<p>to lower the likelihood of causing injury.</p>
<p>Note:</p>
<p>WCAG 2.0 also includes two related success criteria:</p>
<p>2.2.2 Pause, Stop, Hide</p>
<p>2.3.1 Three Flashes or Below Threshold</p>
<p>The WCAG 2.0 Web site contains advice, commentary, and links to
further information relating</p>
<p>to the above success criteria that may be useful to consult when
developing a streamlined test</p>
<p>process<a href="#Baseline_Tests_for_Software___We_5">.</a><a
href="#Top_of_index_html">3 (</a>page <a
href="#Baseline_Tests_for_Software___We_5">6)</a></p>
<p>Why there is no baseline test for flashing</p>
<p>Despite exhaustive analysis efforts of DHS and SSA staff, a reliable,
repeatable method to</p>
<p>determine the number of flashes or blinks per second could not be
found or established at the</p>
<p>time of publication. There are many candidate methods to try, and it
may be possible to create a</p>
<p>software tool that can be accepted in the future. Candidate methods
that were studied included:</p>
<p> Seeking the code from developers to show the programmed cycles per
second. This</p>
<p>test is considered too advanced for most testers (cycle values have
to be translated through formulas to get a Hz value). Further, other
program and operating system functions can slow or speed up a programmed
value to something that differs from the intended value (in our
analysis, the majority showed flash rates that differed to the
code).</p>
<p> A tester visually following the flashing, along with some counting
aid (counting in the</p>
<p>head "one, one thousand two, one thousand" etc., using a stopwatch or
countdown timer, using a metronome, and other methods). Each test
involving human</p>
<p><span id="Baseline_Tests_for_Software___We_90"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>perception has its limitations and brings up inter-tester and
intra-tester reliability questions.</p>
<p> Using a software tool to blink at a known rate and placing it next
to the flashing</p>
<p>content to visually compare rates. Although this was promising, the
ability of users varied in their capability of making measurements.
After about 2.5 Hz, the testers could not reliably track both flashing
objects. Further, getting the tool to blink at the desired rate on
different computers was problematic.</p>
<p> Using a software tool to capture and analyze the content displayed
on screen. The</p>
<p>tools proved unreliable, in part due to the mismatch between sampling
frequency and the screen refresh rate. Interference can occur when
flashes are in the process of being 'drawn' on the screen at the same
time as the sampling is taking place.</p>
<p> Using a video camera to capture the screen. This is considered a
cumbersome test</p>
<p>for general use, and it is subject to the same interference problems
as with the screen capture software.</p>
<p>Requirement, and draft rationale</p>
<p>Requirement</p>
<p>Sections(s) of the screen should not flash at or above 3Hz.</p>
<p>Note:</p>
<p>Section 508 sets limits at 2Hz, but WCAG, produced later than Section
508, revises that figure to 3Hz based on research. It is likely that the
Section 508 refresh will adopt the 3Hz figure, and so that requirement
is adopted in the baseline.</p>
<p>Rationale</p>
<p>The following is advisory only. It will be finalized in future
versions of this document when an agreed-upon test process is
released.</p>
<p>A component that flashes or blinks in the visual field can cause
adverse reactions in people who have photosensitive epilepsy. The size,
intensity and duration that causes seizures varies from individual to
individual. However, it is well established that objects flickering in
the frequency range from 3Hz to 55Hz (from three times to 55 times per
second) should be avoided.</p>
<p>Notes:</p>
<p>Scrolling ('marquee') text may cause a flashing effect under certain
circumstances.</p>
<p>At flash rates approaching and above 55Hz, flashing can be
imperceptible to the naked eye (the component(s) will look like they
have a steady state). For this reason there is no test that deals with
the higher cut-off point of 55Hz.</p>
<p>How to report on flashing content</p>
<p>When developing test processes, and reporting results from such test
processes, agencies must include a test related to flashing, even though
there is no baseline test.</p>
<p> Results of tests should indicate the test method used.  Results of
tests for flashing can be accepted by other agencies at their
discretion.  Agencies who adopt the baseline tests and share results
with one another cannot reject</p>
<p>another agency's test results just because they do not accept the
methods for testing flashing content. Agencies can reject the flashing
results, but will accept the remainder of the test results, until a
reliable baseline test is chosen.</p>
<p><span id="Baseline_Tests_for_Software___We_91"
class="anchor"></span>Baseline Tests for Software &amp; Web
Accessibility</p>
<p>Attachment C - Baseline Test Report Checklists</p>
<p>Instructions</p>
<p> Include one of the following checklists when sharing results
between agencies:</p>
<p> Software-only test</p>
<p> Web-only test</p>
<p> Web+Software test (use for instances such as a web site that uses
embedded flash content, or</p>
<p>software that uses a web interface for its' user guide)</p>
<p> The checklist should be placed at or near the front of the report.
 Include a short summary of the findings from the main report.  All
applicable lines should be marked in both tables (the baseline
requirements and the Section 508</p>
<p>standards).</p>
<p> For directions on which column to mark (Fail, Pass, N/A) see the
reporting instructions in each</p>
<p>baseline test, or the instructions in the streamlined test you are
working from.  Attach to the checklist a summary table explaining each
baseline failure (the following are</p>
<p>recommended minimum reporting requirements; additional supporting
information may also be</p>
<p>provided):</p>
<p> Enter the Baseline number (from the checklist)</p>
<p> Enter the Applicable requirement's short title (from the
checklist)</p>
<p> Briefly describe what issues failed (e.g., "Missing Alt Text on
Images"), and where the failure</p>
<p>occurred (e.g., "Login screen", "Help Menu", "Multiple
locations")</p>
<p> Add any additional notes on the test results (e.g., AT
compatibility; potential work-arounds that</p>
<p>might mitigate a failure, impact this failure may have on users with
disabilities). If a failure applies to more than one baseline
requirement, it can be mentioned here (it is not necessary to list the
same failure multiple times).</p>
<p> Include, attach, or reference the location of the full test
report.</p>
<p>Note:</p>
<p><em>For general reporting guidance, see the section "</em>Developing
a streamlined test process from this baseline<em>".</em></p>
<p><span id="Software_only_test__Include_this"
class="anchor"></span><em>Software-only test</em> Include this checklist
when sharing results between agencies</p>
<p>Section 508 Baseline Test Report</p>
<p>Checklist</p>
<p>Agency: Agency contact details:</p>
<p>Product name: Version # Date tested:</p>
<p>Summary of main findings:</p>
<p># Applicable Baseline requirements Fail Pass N/A Para. Applicable 508
Std. Fail 1. Keyboard navigation   21(a) Keyboard Accessibility </p>
<p>2. Focus (visible)   21(b) Built-in Acc. Features </p>
<p>3. Focus (order)   21(c) Visual Focus </p>
<p>4. Focus (Revealing hidden content)    21(d) Name, Role, State...
</p>
<p>5. Skip-navigation links    21(e) Bitmap images </p>
<p>6. Multi-state components    21(f) Input text </p>
<p>7. Images    21(g) Color &amp; Contrast </p>
<p>8. Color (meaning)    21(h) Animation </p>
<p>9. Color (contrast)   21(i) Color dependence </p>
<p>10. Flashing (reserved)* () ()  21(j) Color &amp; Contrast (OS)
</p>
<p>11. Forms (associated instructions)    21(k) Blinking objects
</p>
<p>12. Page Titles   21(l) Forms </p>
<p>13. Data Tables (headers)    22(a) Text descriptions... </p>
<p>14. Data Tables (cell-header mapping)    22(b) Synchronized
Alternative </p>
<p>16. Links and user controls    22(j) Flickering </p>
<p>18. Audio (transcripts)    22(l) Scripts </p>
<p>19. Video (descriptions)    22(p) Time out </p>
<p>20. Synchronized Media (captions)    24(c) Captions </p>
<p>21. Synchronized Media (descriptions)    24(d) Video descriptions
</p>
<p>24. Alternate pages    31(a) Use without vision </p>
<p>25. Time outs    31(b) Use with low vision </p>
<p>28. Built-in accessibility features   </p>
<p><em>*</em> Flashing must be tested, but there is no agreed-upon
baseline test. Include evaluation methods in attached test report.</p>
<p><span id="Web_only_test__Include_this_chec"
class="anchor"></span><em>Web-only test</em> Include this checklist when
sharing results between agencies</p>
<p>Section 508 Baseline Test Report</p>
<p>Checklist</p>
<p>Agency: Agency contact details:</p>
<p>Product name: Version # Date tested:</p>
<p>Summary of main findings:</p>
<p># Applicable Baseline requirement Fail Pass N/A # Applicable 508 Std.
Fail 1. Keyboard navigation   21(a) Keyboard Accessibility </p>
<p>2. Focus (visible)   21(c) Visual Focus </p>
<p>3. Focus (order)   21(e) Bitmap images </p>
<p>4. Focus (Revealing hidden content)    21(k) Blinking objects
</p>
<p>5. Skip-navigation links    22(a) Text descriptions... </p>
<p>6. Multi-state components    22(b) Synchronized Alternative </p>
<p>7. Images    22(c) Color dependence </p>
<p>8. Color (meaning)    22(d) Style Sheets </p>
<p>9. Color (contrast)   22(e) Server-side image maps </p>
<p>10. Flashing (reserved)* () ()  22(f) Client side (not server)
</p>
<p>11. Forms (associated instructions)    22(g) Row and column
headers </p>
<p>12. Page Titles   22(h) Associate Data - Headers </p>
<p>13. Data Tables (headers)    22(i) Descriptive Frame Titles </p>
<p>14. Data Tables (cell-header mapping)    22(j) Flickering </p>
<p>15. Headings    22(k) Alternative versions </p>
<p>16. Links and user controls    22(l) Scripts </p>
<p>17. Language    22(m) Plug-ins </p>
<p>1 . Audio (transcripts)  8   22(n) Labels for forms </p>
<p>19. Video (descriptions)    22(o) Skip Links </p>
<p>20. Synchronized Media (captions)     22(p) Time out</p>
<p>21. Synchronized Media (descriptions)     24(c) Captions</p>
<p>22. Style-sheet non-dependence     24(d) Video descriptions</p>
<p>23. Frames     31(a) Use without vision</p>
<p>24. Alternate pages     31(b) Use with low vision</p>
<p>25. Time outs   </p>
<p>26. Image maps   </p>
<p>27. Plug-in Links   </p>
<p><em>*</em> Flashing must be tested, but there is no agreed-upon
baseline test. Include evaluation methods in attached test report.</p>
<p><span id="Web_Software_test_Include_this_c"
class="anchor"></span><em>Web+Software test</em> Include this checklist
when sharing results between agencies</p>
<p>Section 508 Baseline Test Report</p>
<p>Checklist</p>
<p>Agency: Agency contact details:</p>
<p>Product name: Version # Date tested:</p>
<p>Summary of main findings:</p>
<p># Baseline requirements Fail Pass N/A # Section 508 Standard Fail 1.
Keyboard navigation   21(a) Keyboard Accessibility </p>
<p>2. Focus (visible)   21(b) Built-in Acc. Features </p>
<p>3. Focus (order)   21(c) Visual Focus </p>
<p>4. Focus (Revealing hidden content)    21(d) Name, Role, State...
</p>
<p>5. Skip-navigation links    21(e) Bitmap images </p>
<p>6. Multi-state components    21(f) Input text </p>
<p>7. Images    21(g) Color &amp; Contrast </p>
<p>8. Color (meaning)    21(h) Animation </p>
<p>9. Color (contrast)   21(i) Color dependence </p>
<p>10. Flashing (reserved)* () ()  21(j) Color &amp; Contrast (OS)
</p>
<p>11. Forms (associated instructions)    21(k) Blinking objects
</p>
<p>12. Page Titles   21(l) Forms </p>
<p>13. Data Tables (headers)    22(a) Text descriptions... </p>
<p>14. Data Tables (cell-header mapping)    22(b) Synchronized
Alternative </p>
<p>15. Headings    22(c) Color dependence </p>
<p>16. Links and user controls    22(d) Style Sheets </p>
<p>17. Language    22(e) Server-side image maps </p>
<p>18. Audio (transcripts)    22(f) Client side (not server) </p>
<p>19. Video (descriptions)    22(g) Row and column headers </p>
<p>20. Synchronized Media (captions)     22(h) Associate Data -
Headers</p>
<p>21. Synchronized Media (descriptions)     22(i) Descriptive Frame
Titles</p>
<p>22. Style-sheet non-dependence     22(j) Flickering</p>
<p>23. Frames     22(k) Alternative versions</p>
<p>24. Alternate pages     22(l) Scripts</p>
<p>25. Time outs   </p>
<p>22(m) Plug-ins </p>
<p>26. Image maps     22(n) Labels for forms</p>
<p>27. Plug-in Links   </p>
<p>22(o) Skip Links </p>
<p>28. Built-in accessibility features   </p>
<p>22(p) Time out </p>
<p><em>*</em> Flashing must be tested, but there is no agreed-upon
baseline <em>24(c) Captions </em> test. Include evaluation methods in
attached test report. <em>24(d) Video descriptions </em></p>
<p>31(a) Use without vision </p>
<p>31(b) Use with low vision </p>
<p><span id="Summary_of_failures" class="anchor"></span>Summary of
failures</p>
<p>Attach this summary list to the Section 508 Baseline Test Report
Checklist</p>
<p>Include, attach, or reference the location of the full test
report.</p>
<p>Agency: Agency contact details:</p>
<p>Product name: Version # Date tested:</p>
<p># Applicable Baseline Failure Additional Notes</p>
<p>Baseline (description and location)</p>
<p><span id="Document_Content_Change_Log" class="anchor"></span>Document
Content Change Log</p>
<p>Note: Minor punctuation, formatting and spelling changes not
included.</p>
<p>Version 1.0.6, March 2015</p>
<p>First published version.</p>
<p>Version 1.1, February 2016</p>
<p>Location Change</p>
<p>How the baseline Added “In Windows 8.1, testing is performed in
Desktop mode.” Added</p>
<p>tests are structured Inspect URL for Windows 8.1. Added 8.1 SDK
information to footnote.</p>
<p>Section 11, Forms Added information about checking HTML version and
ID naming in HTML5.</p>
<p>Section 13, Data Added information about use of rowgroup and
colgroup. Added information</p>
<p>Tables about checking HTML version and deprecation of TD SCOPE in
HTML5.</p>
<p>Section 14, Data Added information about use of rowgroup and
colgroup. Added information</p>
<p>Tables about checking HTML version and deprecation of TD SCOPE in
HTML5.</p>
<p>Added information about ID naming in HTML 4.01 and HTML5.</p>
<p>Section 28, Built-in Added “system” to “Set the system text size to
200%”. Added Windows 8.1</p>
<p>accessibility instructions. Specified using Windows Key + U to open
Ease of Access</p>
<p>features center. Changed instructions accordingly.</p>
<p>Version 2.0, October 2016</p>
<p>Location Change</p>
<p>Agency issues Removed “use of Heading tags for style instead of
structure, and using</p>
<p>beyond the test both an ALT and a TITLE attribute on an image where
the two clearly process contradict each other” as example of coding
error.</p>
<p>Added last bullet starting with “The baseline test methodology does
not include guidance on managing a testing program. …”</p>
<p>Platforms, Browsers Removed support for IE8, IE9.</p>
<p>and Tools Added support for Windows 10.</p>
<p>Added WAT 2015 to tools list.</p>
<p>Added information on WAF and Color Contrast Analyser. Added content
on the use of WAF, Chrome, and Firefox. Added “Notes on Browsers
Differences ” and “Notes on WAF”.</p>
<p>Various Sections Added “Note: In Chrome, Inspect does not reveal the
correct information for</p>
<p>Flash content” and the note “Interactive Flash and embedded Java
content should be tested in IE to determine the accessibility of the
coded content”.</p>
<p><span id="Location_____________Change" class="anchor"></span>Location
Change</p>
<p>Section 5, Skip Rationale: Changed title to “Repetitive Content”</p>
<p>Links Changed “To enable equitable use by keyboard only users, there
must be a</p>
<p>method to skip past repetitive content. This can be provided by
adding internal links to bypass repetitive content. Similarly, for
screen reader users, if they must read content that is repeated on each
page and cannot skip past it, their experience on the page can be very
frustrating” to “To enable equitable use by keyboard only users, there
must be a method to skip past repetitive content. Similarly, for screen
reader users, if they must read content that is repeated on each page
and cannot skip past it, their experience on the page can be very
frustrating. A common method used to bypass repetitive content is
internal (same page) links.”</p>
<p>Test Instruction 2: Added various instructions: location of skip
target, testing if no skip links are marked, testing skip function,
testing if no interactive target.</p>
<p>Section 7, Images Rationale: Added “If font-based graphics are used
to provide information,</p>
<p>equivalent information must be provided in an accessible format.”</p>
<p>Test Instruction 1: Step a, added bullet: “Look for images that are
rendered by using font-based graphics (e.g. up-arrows to indicate sort
order, etc.).”</p>
<p>Section 8, Color Advisory: added bullet “WAF’s Greyscale test works
in more cases than (meaning) WAT’s, although there may be some sites
where both work only partially or</p>
<p>not at all.”</p>
<p>Section 9, Color Added “minimum” to “There must be contrasting
colors/shades at a minimum</p>
<p>(Contrast) ratio of 4.5:1 for discerning between background and
foreground content.”</p>
<p>Section 11, Forms Test Instruction 2: Added “Forms with ARIA labels
should be tested in (associated Chrome or Firefox to determine the
accessibility of the coded forms.” instructions)</p>
<p>Section 23, Frames Advisory: Repeated content from “Notes on Using
WAF” as relates to frames</p>
<p>Section 28, Built-in Rationale: Added Windows 10</p>
<p>accessibility Test Instruction 1b: Added Windows 10</p>
<p>features Test Instruction 2b: Replaced “Open any text editing
application (e.g., MS</p>
<p>Word). Attempt to close an edited 2.0file without saving it first.
The Sound Sentry indicator should flash” with instructions for Notepad,
since previous test did not work reliably in different environments.</p>
<p>Throughout Removed some references to page numbers and replaced them
with</p>
<p>references to section names</p>
<p>Version 2.0.1, November 2016</p>
<p>Location Change</p>
<p>Various Updated URLs from www.section508testing.org to
www.dhs.gov/dhs-section-</p>
<p>508-compliance-testing-tools</p>
<p>Version 2.0.2, April 2017</p>
<p>Location Change</p>
<p>How the baseline Changed “Notes on browser differences” to “Browser
recommendation” to</p>
<p>tests are structured state a preference for testing in IE 11 as the
most accessibility supported test</p>
<p>environment when testing Flash and embedded Java</p>
<p>Moved “Configure Chrome for testing” earlier in the section to
improve document flow</p>
<p>Location Change</p>
<p>Section 6. Multi- Modified advisory to clarify the need to conduct
further assessment when</p>
<p>state components, encountering multiple ARIA attributes for a single
element rather than for only</p>
<p>Advisory specific attributes.</p>
<p>Section 7. Images, Clarified the use of the ARIA Markup favelet to
identify image attributes Test Instruction</p>
<p>Section 11. Forms, Clarified instructions for inspecting ARIA
attributes and name, role, and state</p>
<p>Test Instruction attributes for software.</p>
<p>Moved content related to testing Flash and embedded Java in IE to the
Notes section.</p>
<p>Various locations Minor wording changes to clarify meaning</p>
<p>Section 1. Keyboard Added advisory regarding visible display of TITLE
attribute information during Navigation, Advisory keyboard
navigation.</p>
<p>And</p>
<p>Section 11. Forms,</p>
<p>Advisory</p>
<p>Section 13. Data Added text to clarify appropriate methods for
including header information in</p>
<p>Tables (headers), some software applications and related methods for
verifying header Test Instruction information when testing</p>
<p>Document status, Added contact information for questions and feedback
review comments,</p>
<p>and feedback</p>
<p>Section 7. Images Removed language related to finding and testing
font-based graphics</p>
</body>
</html>
