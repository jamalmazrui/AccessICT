Centering Disability in Technology Policy


Centering                                        December 2021

Disability in Technology Policy

Issue Landscape and Potential Opportunities for Action

Henry Claypool

Claire Carey

Alexander C. Hart

Linnea Lassiter

[]

Contributing Organizations

American Association of People with Disabilities

The American Association of People with Disabilities (AAPD) is a convener, connector, and catalyst for change, increasing the political and economic power of people with disabilities.

As a national cross-disability rights organization, AAPD advocates for full civil rights for the over 60 million Americans with disabilities by promoting equal opportunity, economic power, independent living, and political participation.

Center for Democracy & Technology

The Center for Democracy & Technology is a 25-year old 501(c) (3) working to promote civil rights and civil liberties in the digital age. Based in Washington, D.C., and Brussels, Belgium, CDT works inclusively across sectors to find tangible solutions to today’s most pressing technology policy challenges. Our team of experts includes lawyers, technologists, academics, and analysts, bringing diverse perspectives to all of our efforts. Learn more: https://cdt.org/.

Freedman Consulting 

Freedman Consulting, LLC, works on a broad portfolio of issues focused on innovations for the greater social good, finding smart solutions to your most challenging problems. We use our diverse experience in philanthropy, politics, public policy, nonprofits, journalism, and communications to advise a broad range of clients advancing the public interest. We have worked with the country’s top policymakers, largest foundations, leading advocacy groups, and other public interest leaders as partners in change. Our approach focuses on helping clients define their goals and develop comprehensive approaches that flexibly respond to client needs.

Centering Disability in Technology Policy: Issue Landscape and Potential Opportunities for Action

Contents

Executive Summary                                                                                                                          4

I. Overview and Methodology                                                                                                                                                                         4

II. Cross-Cutting Themes                                                                                                                                                                                    6

III. Issue Areas                                                                                                                                                                                                          7

IV. Challenges, Needs, and Opportunities                                                                                                                                              10

V. Conclusion                                                                                                                                                                                                         15

Introduction                                                                                                                                    16

Technology’s Benefits for the Disability Community: A Nuanced Understanding                         19

Note on Definitions and Language                                                                                                 21

Methodology                                                                                                                                  22

Cross-Cutting Themes                                                                                                                     23

A. Inescapable Technology                                                                                                                                                                             23

B. Accessibility as Crucial Issue                                                                                                                                                                    24

C. Importance of Representation and Diversity in Technology Development and Policy                                              26

D. Algorithmic Bias and Inability to Capture Disability Experience                                                                                           27

Issue Areas                                                                                                                                      28

A. Access to High-speed Internet & Devices                                                                                                                                         28

B. Economic Security                                                                                                                                                                                         32

C. Equitable Employment                                                                                                                                                                                36

D. Privacy and Commercial Data Practices                                                                                                                                             40

E. Amplifying Hate Speech and Issues of Free Expression                                                                                                             43

F. Education and Student Surveillance                                                                                                                                                     47

G. Law Enforcement                                                                                                                                                                                          50

H. Healthcare                                                                                                                                                                                                         54

I. Emerging Tech                                                                                                                                                                                                   60

Challenges, Needs, and Opportunities                                                                                           63

Conclusion                                                                                                                                      94

Appendix 1: List of Interviewees                                                                                                    96

Appendix 2: Authors and Acknowledgments                                                                                 97

 

American Association of People with Disabilities   |   Center for Democracy & Technology

Executive Summary

1 A detailed explanation of this report’s language

related to disability

and technology issues is offered later in this report.

I. Overview and Methodology

Overview

Technology has the power to create a more just and inclusive society by providing greater autonomy, safety, economic opportunity, and convenience for historically marginalized groups. However, all too often, technology instead exacerbates existing discrimination and the structural barriers faced by historically marginalized groups, including people of color, women, and people with disabilities, and especially those who experience intersecting forms of oppression.¹

Undertaken as a collaboration between the American Association of People with Disabilities (AAPD) and the Center for Democracy and Technology (CDT) with the support of Freedman Consulting, this report is intended to help public interest organizations do more inclusive, effective work at the intersection of technology and disability issues in the United States. Based on conversations with 20 disability and technology leaders, this report will explore issue areas and ways where technology justice organizations can better integrate a disability lens into their work. In addition, issues surfaced in this report may help disability groups identify meaningful opportunities to engage on technology policy issues and advance their often-long-standing priorities. Along with identifying policy issues at the intersection of disability and technology, this report will also highlight the challenges and needs that must be addressed in order to break down barriers between siloed fields and do more effective work.

Historically, technology has played a significant role in improving the quality of life, and in certain instances, longevity, for many disabled people. This report is not meant to contest or stand in denial of that reality. In taking an intersectional approach, this paper aims to ensure that the pursuit of technologies to create opportunity and lower barriers for some does not create inequities or limitations for others. Technology has great potential to improve life and autonomy for people with disabilities, but it also requires equitable and inclusive development, thoughtful, responsive implementation and oversight, and a commitment to identifying and mitigating harms to already-marginalized communities.

Methodology

The research, takeaways, and conclusions in this report draw on expert interviews and supplemental research, all of which were undertaken from May to September 2021.

II. Cross-Cutting Themes

In interviews conducted for this report, stakeholders raised four topics repeatedly across all issue areas, bridging concerns of the disability and technology policy communities. These areas include:

A. Inescapable Technology

The role of technology in our lives is inescapable and grows more and more prominent every day. In order to advocate for inclusive and just technology – as our world continues to advance and concretize many technological changes – a consistent examination of how technology affects disabled people must be undertaken. Technology, and its corresponding benefits and harms, exists in and now also shapes all spheres of life including housing, healthcare, school, and work. The discussion of policy issue areas in this report seeks to lift up how technology is, and can be, especially present and harmful in the lives of disabled people.

B. Accessibility as Crucial Issue

Technology has the potential to change many disabled peoples’ experiences in removing communication and interaction barriers in the physical world. Therefore accessibility on the internet, to devices, in applications, and in many related contexts, as well as all of their benefits (and corresponding harms, many of which will be lifted up throughout this report) must be primary to any conversation or work surrounding technology policy and civil rights.

C. Importance of Representation and Diversity in Technology Development and Policy

Today, algorithms and machine learning systems are used to make decisions in some of the most important spheres of our daily life: government services, employment, commerce, health, housing, immigration, and the criminal and civil legal system. Without diverse design perspectives, algorithms are trained by unrepresentative data/ information sets that can reflect historical inequalities and biases.

D. Algorithmic Bias and Inability to Capture Disability Experience

In addition to this lack of diverse representation, several interviewees emphasized the fundamental inability of algorithms to even capture the full diversity of disability experience and expression.  Or in other words, the experiences, needs, and barriers that marginalized communities face, including disabled people, who, by definition, cannot be quantified neatly.

III. Issue Areas

While technology is nearly inescapable in all aspects of life today, our research identified nine areas in which the intersections between technology and disability are of particular concern.

A. Access to High-Speed Internet and Devices

The internet has become vital to finding and obtaining employment, full inclusion in education, utilizing basic services such as banking, and simply staying connected to the outside world and our communities. However, not only are people with disabilities – particularly those of color – less likely to have the internet at home, but some evidence suggests they are less likely to even use it at all. Challenges include high costs of services and lack of accessible and affordable devices.

B. Economic Security

Technology is playing a growing role in obtaining and maintaining economic security, and advancing economic security lies at the center of the disability community’s advocacy work. People with disabilities are about twice as likely to live in poverty than people without disabilities. Accordingly, many disabled people rely on government income and benefits support such as SSI, SSDI and SNAP, among other programs. Technology today increasingly mediates access to these essential supports and can reinforce preexisting disparities. Automated decision-making – driven by biased or faulty algorithms – can deny disabled people benefits to which they are legally entitled, while unjust tenant screening algorithms may limit access to affordable housing.

C. Equitable Employment

Equitable access to gainful employment, hiring programs, workforce development, and government benefits and services are necessary to an inclusive society that maintains economic security, opportunity, and dignity for all. As our economy becomes increasingly reliant on technology for these systems, many people with disabilities are at an immediate disadvantage and face labor market discrimination as a result. Hiring algorithms, workplace algorithmic management, and gig economy policies all present challenges to disabled people.

D. Privacy and Commercial Data Practices

The United States lacks a baseline federal privacy law, so state and sectoral privacy laws serve as a patchwork system that provides the primary forms of data privacy protections enjoyed by most adults. However, these laws often do not contain explicit anti-discrimination protections or effective enforcement provisions. This lack of regulation of commercial data leaves everyone vulnerable to harm; historically marginalized groups, including people of color and people with disabilities, are even more at risk. Of particular concern for people with disabilities are Internet of Things (IoT) systems and biometric privacy issues.

E. Amplifying Hate Speech and Issues of Free Expression

For many, online platforms are the pre-eminent public space. Yet, the reach of platforms also evokes unanswered free expression questions, requiring more work to protect civil rights online. Given the centrality of platforms to modern life and the disparate harms disabled individuals face, building an online environment that is truly inclusive of and equitable for people with disabilities requires a serious commitment to addressing these challenges. Potential focal topics include content moderation, free expression, and dis/ misinformation (especially focused on voter suppression).

F. Education and Student Surveillance

Today, law enforcement, immigration and customs officers, and now even public school administrators, are using a wide array of surveillance technology purchased from private vendors. These surveillance technologies include social media monitoring, student threat assessment software management, and e-proctoring tools. These technologies can facilitate discrimination based on racism and ableism and ultimately lead to disciplinary action including suspension and/or expulsion from school for children with disabilities, a disproportionate share of whom are students of color either designated as or truly disabled.

G. Law Enforcement

Many interviewees asserted that disabled people, and disproportionately disabled people of color, are over-surveilled, policed, and criminalized by law enforcement agencies. The abuse of technology by policing and immigration institutions can create new avenues to power (and potential abuse of power) that replicate and amplify existing systems of oppression – locking many people with disabilities out of equal opportunity and access to their civil rights, while continuing to criminalize and surveill mental health. Issues of concern included facial and gait recognition, predictive policing and risk assessments, border screening, and video remote interpreting.

H. Healthcare

Similarly to education, criminal justice, and other parts of our societal infrastructure, healthcare has also introduced technology as a means to improve efficiency and improve outcomes. This approach can carry significant consequences, however. Artificial intelligence has been increasingly utilized by the healthcare industry in recent years, but like other forms of AI, can and does result in bias affecting marginalized groups, including people with disabilities. While healthcare technology is evolving at a rapid pace, the growth of telehealth (which often is inaccessible for those with disabilities or otherwise unable to access internet at home), algorithmic management of care decisions, and the fundamental lack of transparency regarding health data all represent significant areas of concern.

I. Emerging Tech

Emerging technologies have created greater opportunities for independence for disabled people, as well as more channels and methods of communication. It is vital that new technological tools are designed and regulated through a truly inclusive technology justice lens, with the disability community’s active participation. Emerging technology issues highlighted by interviewees included autonomous vehicles, virtual reality, and automated speech recognition technology.

IV. Challenges, Needs, and Opportunities

Given the myriad ways tech often creates harm and disparate negative outcomes for disabled people, this section explores two key questions:

•     What are the barriers to work at the intersection of technology and disability?

•     What do the individuals and organizations leading in this domain need to support their work, including seizing on opportunities to make it even more effective?

Types of challenges

+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
| A. Challenges                     | 1. Addressing accessibility is necessary, but not sufficient to solve challenges at the intersection of technology and disability       |
|                                   |                                                                                                                                         |
|                                   | a.      Disabled people are excluded from work technology issues if accessibility is not addressed from the start                       |
|                                   |                                                                                                                                         |
|                                   | b.      Disabled groups’ ongoing need to lead on accessibility work can crowd out engagement on other priorities                        |
|                                   |                                                                                                                                         |
|                                   | c.       Despite these challenges, the assumption that disability and technology justice are only centered on accessibility is harmful  |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 2. Needs and nature of disability member organizations                                                                                  |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 3. Misconception of monolithic disability identity leading to misunderstanding of technology harms and remedies                         |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 4. Limited representation of individuals with disabilities                                                                              |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 5. Shallow pool of professionals with experience in both disability-focused accessibility and rights, as well as techspecific expertise |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 6. Lack of general and/or specific knowledge of how technology can harm people with disabilities                                        |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 7. Few formal and informal bridges between technology and disability advocates                                                          |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 8. Deeper-seated divisions between some civil rights organizations and disability rights/justice organizations                          |
+-----------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+

 

+-----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| B. Needs and Opportunities        | 1. Resource commitment within technology justice organizations to true inclusion                                                                                              |
+-----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 2. Funding for paid fellowships and other long-term opportunities for people with disabilities and disability rights experts to contribute directly to technology policy work |
+-----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 3. Substantial investment in paid listening sessions and focus groups to learn from disability community                                                                      |
+-----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 4. Establish opportunities that promote solidarity and relationship-building across the disability and tech communities:                                                      |
|                                   |                                                                                                                                                                               |
|                                   | a.      Building greater trust and respect                                                                                                                                    |
|                                   |                                                                                                                                                                               |
|                                   | b.      Identifying consensus goals                                                                                                                                           |
|                                   |                                                                                                                                                                               |
|                                   | c.       Driving engagement beyond the public interest community                                                                                                              |
|                                   |                                                                                                                                                                               |
|                                   | d.      Supporting an executive cohort                                                                                                                                        |
+-----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 5. Support greater inclusion for marginalized voices and a commitment to intersectionality                                                                                    |
|                                   |                                                                                                                                                                               |
|                                   | a.      Strengthen understanding of intersectionality                                                                                                                         |
|                                   |                                                                                                                                                                               |
|                                   | b.      Deliberately create spaces in which marginalized voices are centered and empowered                                                                                    |
|                                   |                                                                                                                                                                               |
|                                   | c.       Create an inclusive design coalition                                                                                                                                 |
|                                   |                                                                                                                                                                               |
|                                   | d.      Promote stronger collaboration among disability rights groups and the greater civil rights community                                                                  |
+-----------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

 

+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| B. Needs and                      | 6. Develop plain language and otherwise easily accessible resources for a broad audience                                                                                     |
|                                   |                                                                                                                                                                              |
| Opportunities                     |                                                                                                                                                                              |
|                                   |                                                                                                                                                                              |
| (Continued)                       |                                                                                                                                                                              |
+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 7. Fund equitably across civil rights organizations, including those focused on disability                                                                                   |
+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 8. Build pipelines and partnerships to encourage disability inclusion in the tech sector                                                                                     |
|                                   |                                                                                                                                                                              |
|                                   | a.      Support public-private partnerships                                                                                                                                  |
|                                   |                                                                                                                                                                              |
|                                   | b.      Develop partnerships with tech industry                                                                                                                              |
|                                   |                                                                                                                                                                              |
|                                   | c.       Create an academic pipeline for students and scholars                                                                                                               |
+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                   | 9. Expand and support intersectional research opportunities applying the Americans with Disabilities Act, other federal disability rights laws, and related state-based laws |
|                                   |                                                                                                                                                                              |
|                                   | a.      Invest in deeper research and advocacy on government use of algorithms in public benefits to create a framework and principles for just use                          |
|                                   |                                                                                                                                                                              |
|                                   | b.      Conduct research on how algorithmic decision-making affects content moderation                                                                                       |
|                                   |                                                                                                                                                                              |
|                                   | c.       Fund public opinion research on technology centered on people with disabilities                                                                                     |
|                                   |                                                                                                                                                                              |
|                                   | d.      Explore harms caused by student surveillance and e-proctoring technologies                                                                                           |
|                                   |                                                                                                                                                                              |
|                                   | e.      Conduct research into technology’s role in the criminalization of mental health                                                                                      |
|                                   |                                                                                                                                                                              |
|                                   | f.        Develop policy solutions that support disabilityinclusive tech regulation                                                                                          |
+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

 

+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+
| B. Needs and                      | 10. Resource advocacy projects at the intersection of technology and disability                                                                            |
|                                   |                                                                                                                                                            |
| Opportunities                     | a.      Include and follow the lead of intersectional perspectives in crafting principles and recommendations around comprehensive federal                 |
|                                   |                                                                                                                                                            |
| (Continued)                       | data privacy laws and designing other data privacy recommendations                                                                                         |
|                                   |                                                                                                                                                            |
|                                   | b.      Advocate for federal funding to increase access to reliable devices and high-speed internet                                                        |
|                                   |                                                                                                                                                            |
|                                   | c.       Increase advocacy to encourage employers to take advantage of remote workplace options to increase the number of disabled people in the workforce |
|                                   |                                                                                                                                                            |
|                                   | d.      Include e-proctoring and student surveillance harms in advocacy around privacy rules                                                               |
|                                   |                                                                                                                                                            |
|                                   | e.      Build on existing oversight efforts to investigate DHS and ICE’s use of automated technologies that affect disabled immigrants                     |
|                                   |                                                                                                                                                            |
|                                   | f.        Approach automated captioning and speech recognition tools as needing a spectrum of work                                                         |
|                                   |                                                                                                                                                            |
|                                   | g.      Enable and equip disability organizations with tools necessary to increase their advocacy capacity                                                 |
|                                   |                                                                                                                                                            |
|                                   | h.      Provide dedicated cross-trainings for disability groups to work on federal technology policy advocacy                                              |
|                                   |                                                                                                                                                            |
|                                   | i.        Create sustainable spaces for disability groups to work on federal technology policy                                                             |
+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+

V. Conclusion

Disability issues are fundamental to the pursuit of technology justice. By exploring the wide range of work already taking place at the nexus of these issues, identifying areas ripe for further examination and highlighting existing challenges and field-building needs, this research is intended to serve not as a blueprint, but as a conversation starter to advance systematic efforts to build a more inclusive, coordinated, and effective public interest community.

This report is intended to provide the foundation for identifying the more nuanced questions, tools, resources, policies, and – perhaps most importantly – relationships needed to do technology and disability policy work that uplifts all. Supporting those working to ensure disabled people can use technology to fully participate in their own and our shared communities, achieve greater economic security, and flourish in our society while being protected from harm moves us closer to realizing the promise of human and civil rights in action.

Introduction

At its best, technology can progress us toward a more just and inclusive society by providing greater autonomy, safety, economic opportunity, and convenience for historically marginalized groups. The American Foundation for the Blind – an organization in which Helen Keller was an early and long-time leader – exemplified just technological progress when they first created audiobooks in 1932 so that blind people could have better access to literature. Importantly, this technological progress for people with disabilities was championed and led by disabled people themselves. Audio books also serve as an example of how technologies advanced by those with disabilities may begin as adaptive, but more often than not, result in a technology that benefits all. Today, this inclusive technological progress is noticeable in many types of technologies invented by those with disabilities as well as in how smart home technology, powered by AI, enables independent living for some with physical, cognitive, and sensory disabilities.

Too often, however, technology instead exacerbates existing discrimination and creates new threats to human and civil rights for historically marginalized groups, including people of color, women, immigrants, people with disabilities, and others, especially those who experience multiple, intersecting forms of oppression. Those in positions of power can abuse personal data and artificial intelligence to discriminate at a greater scale that was not feasible before. Algorithms used to screen tenants or run the automated advertising systems of major platforms have facilitated discrimination against people with disabilities – effectively locking

Introduction

them out of housing and commerce opportunities. At the same time, these algorithms and automated systems also create distance from human culpability, accountability and any means of redress. These technological issues go far beyond questions of accessibility and basic inclusion. (Accessibility and inclusion are issues that have themselves have required decades of advocacy in pursuit of equitable treatment and still remain unresolved).

Technology justice work seeks to ensure that technology does not merely avoid doing harm, but instead truly serves all people. Yet in this pursuit of justice in technology policy, issues impacting people with disabilities and the perspective of disabled people themselves are far too often underrepresented in the conversation. Undertaken as a collaboration between the American Association of People with

Disabilities (AAPD) and the Center for Democracy and Technology (CDT) with the support of Freedman Consulting, this report is intended to help public interest organizations do more inclusive, effective work at the intersection of technology and disability issues in the United States.

This work can only succeed by listening to, learning from, working with, and resourcing those with lived disability experience. The refrain “Nothing about us without us”,² widely embraced by disability advocates, was central to the inspiration behind, research method of, and forthcoming recommendations in this report. Based on conversations with 20 disability and technology leaders, this report will explore issue areas and ways in which technology justice organizations can better integrate a disability lens into their work. In addition, issues surfaced in this report may help disability groups identify meaningful opportunities to engage on technology policy issues and advance their often-long-standing priorities.

[]“For a conversation to be successful, it has to be one that is grounded in the goal of increasing and protecting the autonomy and self-direction of disabled people in their own lives.”

2 The phrase “Nothing about us without us” originates from the group Disabled People South Africa (DPSA), which was part of the South African antiapartheid movement coalition. The phrase was used to

signify the disability rights movement as a human rights issue and to convey that it should be disabled people leading their own liberation, in alignment with the pacifist antiapartheid movement, not doctors and social workers. The phrase was then widely embraced by disability advocates throughout the world and is used by the United Nations Convention on the Rights of Persons with Disabilities.

While technology is nearly inescapable in all aspects of life today, key issues surfaced in the research process for this report included:

A.      Access to High-speed Internet and Devices

B.      Economic Security

C.      Equitable Employment 

D.     Privacy and Commercial Data Practices

E.      Amplifying Hate Speech and Issues of Free Expression

F.       Healthcare

G.     Education and Student Surveillance

H.     Law Enforcement

I.        Emerging Tech

Along with identifying policy issues at the intersection of disability and technology, this report will also highlight the challenges and needs that must be addressed in order to break down barriers between these siloed fields. Building relationships between civil rights, disability, and technology is intended to spark dialogue and collaboration on policy issues in service of more inclusive – and effective – work. One disability rights leader underscored what will be necessary for this work’s success, declaring, “For a conversation to be successful, it has to be one that is grounded in the goal of increasing and protecting the autonomy and selfdirection of disabled people in their own lives.” Centering the disability experience and perspective is vital to an inclusive and just technology policy agenda.

Technology’s Benefits for the Disability Community: A Nuanced Understanding

Historically, technology has played a significant role in improving the quality of life, and in certain instances, longevity, for many disabled people. The current wave of data-driven technological innovation is transforming how we live, work, and play. The rapid pace of change, however, calls for thoughtful reflection on the effect of these changes, particularly for disabled people still struggling to be recognized as equal and visible members of our society. Echoing perspectives similar to others interviewed for this report, one disability rights leader emphasized that the net impact of technology has been positive for their community. “Technology creates opportunities for people with disabilities and breaks down barriers,” this expert declared. For example, screen readers for blind individuals, video chat and automated captioning for deaf and hard-of-hearing individuals, and voice recognition technology allow people with certain disabilities greater autonomy in their home. These are just a few examples of technology producing benefits for people with disabilities. This report is not meant to contest or stand in denial of that reality. 

Instead, this report intends to help develop a nuanced disability and technology policy agenda, one that identifies and mitigates real risks, even as it celebrates benefits. This nuanced technology policy approach aims to capture both the benefits of technology for people with disabilities, while also highlighting the need to prevent and address discrimination and other harmful applications. Building from the work of countless others, this report equips advocates and researchers with a potential landscape of harms at the intersection of technology and disability, as well as opportunities to address them.

In taking an intersectional approach, this report aims to ensure that the pursuit of technologies to create opportunity and lower barriers for some does not simultaneously create inequities or limitations for others. Technology has great potential to improve life and autonomy for people with disabilities, but it also requires equitable, inclusive development, as well as thoughtful, responsive implementation and oversight, and a commitment to identifying and mitigating harms to already-marginalized communities.

Note on Definitions and Language

In conducting interviews for this report, we found a diverse set of preferred ways to describe disability status and identity. Some individuals and organizations preferred “identity-first” language (e.g., disabled person), while others preferred “person-first” language (e.g., person with disabilities). Resolving these long-standing discussions is beyond the scope of this report. In addition, some experts considered themselves part of a disability rights movement, while others framed their work in terms of disability justice. As a result, this report makes reference to both disability rights and justice efforts and uses both identity-first and person-first language.

More broadly, disability itself has several competing definitions within the American policy and legal system. To be defined as a person with disabilities under the Social Security Act, which provides life-sustaining access to healthcare through the Medicare and Medicaid programs as well as other financial supports, individuals must pass a narrow eligibility test. The Social Security eligibility test requires long-term major impairment and a near-inability to perform substantial gainful activity. On the other hand, the Americans with Disabilities Act defines disability more broadly as “a physical or mental impairment that substantially limits one or more major life activities.” These two examples illustrate just some of the challenges faced in defining disability in a uniform and consistent fashion. This report also later discusses issues interviewees raised about disability status, identity, and the diversity of perspectives on these topics.

On technology issues, we defaulted to using the language interviewees did in describing these topics. As a result, we use both the general term “artificial intelligence,” as well as more narrow terms, such as algorithmic decision-making and automated decision-making. While these terms are not fully interchangeable, their definitions often overlap, and individual experts emphasize different distinctions among them.

Methodology

The research, takeaways, and conclusions in this report draw on expert interviews and supplemental research, all of which were conducted from May to September 2021.

Our approach included:

•     Expert Interviews: Interviews with 20 individuals divided between technology-policy-first and disability-policy-first experts and advocates. These interviewees included individuals with lived disability experience and those from a justice background with identities from multiple marginalized and historically oppressed groups.

•     Literature Scan: This research was informed by reviewing over 50 news articles, reports, and other literature and media relevant to the intersection of disability and technology.

•     Discussion Draft and Stakeholder Feedback: In order to conduct this research in an iterative and responsive process, a draft of this report was circulated to stakeholders within the technology and disability policy and justice fields, with their feedback incorporated into future drafts. Additional interviews and research were conducted based on these stakeholders’ feedback and incorporated into the final version of this report.

Cross-Cutting Themes

In interviews conducted for this report, stakeholders raised four topics repeatedly across all issue areas, bridging concerns of the disability and technology policy communities. These areas include:

A.      Inescapable Technology

B.      Accessibility as Crucial Issue

C.      Importance of Representation and Diversity in Technology Development and Policy

D.     Algorithmic Bias and Inability to Capture Disability Experience

A. Inescapable Technology

The role of technology in our lives is inescapable and grows more and more prominent every day. One advocate noted how apparent technology’s role has become due to COVID-19, especially for members of the disability community: “Navigating the online system – vaccines, government programming – we’re seeing different ways that tech tries to enforce a pace of living and way of interacting based on assumptions around how people function that do not work for how disabled people function.” Yet, another advocate also cited the events of the COVID-19 pandemic as having increased virtual options for people with disabilities in improving access to healthcare and civic events like town hall meetings, and creating new educational opportunities. Technology, and its corresponding benefits and harms, exists in and now also shapes all spheres of life including housing, healthcare, school, and work. That same

[]“Navigating the online system – vaccines, government programming – we’re seeing different ways that tech tries to enforce a pace of living and way of interacting based on assumptions around how people function that do not work for how disabled people function.”

advocate cautioned, however, “There are so many ways technology can harm – through surveillance, privacy, control, and discriminatory decisions.” In order to advocate for inclusive and just technology, as our world continues to advance and concretize many technological changes, a consistent examination of how technology affects disabled people must be undertaken. The discussion of policy issue areas in this report seeks to lift up how technology is and can be especially present and harmful in the spheres of life of disabled people.

B. Accessibility as Crucial Issue

Accessibility is both central and primary to discussions of technology policy and civil rights. According to the Web Accessibility Initiative, accessibility means that people with disabilities can “equally perceive, understand, navigate, and interact with websites and tools and that they can contribute equally without barriers.” Technology has the potential to change many disabled people’s experiences in removing communication and interaction barriers in the physical world. Yet, as one disability rights leader explained, technology “has so much potential, but if technology doesn’t address accessibility and disability, it also has the potential to recreate existing barriers, exacerbate barriers, or create new barriers.” Basic accessibility to the internet and devices is still a pressing issue – in February 2021, for example, WEBAIM’s annual evaluation of the home pages of the top 1,000,000 websites found that over 86% of homepages had violations detected for low contrast text and across the 1,000,000 home pages there was an average of 51.4 accessibility errors per page. Facebook didn’t correctly label advertising as ads for blind individuals’ screen readers for almost two years. Most recently, the Markup found that Facebook has broken basic accessibility rules in making changes that attack code features that were previously used to support people using screen readers. Additionally, a study conducted by the

Cross-Cutting Themes

Information Technology and Innovation Foundation tested the most popular federal websites and found that, despite legal requirements, 48% failed an accessibility test on at least one of their three most popular pages. Especially as government services move online, this lack of accessibility threatens disabled people’s rights, and, in some cases, their ability to survive.

Therefore accessibility to digital technologies and all of its benefits (and its corresponding harms, many of which will be referenced throughout this report) must be primary to any conversation or work surrounding technology policy and civil rights. This same disability rights leader underscored this primacy, declaring, “Still having to insist that accessibility needs to be present within a number of tech applications and tools, it becomes hard to engage in a next level conversation when you still can’t access the application in question in the first place.” Advocating for stronger accessibility has long been a priority for many working on disability issues, and it is an issue rich with needs and opportunities.

Ensuring full accessibility also means ensuring full access to education and training around use of the internet and devices. School age students with disabilities and adults are still fighting for equitable education that complies with the Individuals with Disabilities Education Act (IDEA) and the Americans with Disabilities Act (ADA). Due to this historic inequity in education for people with disabilities, disabled adults are less likely than those without a disability to say that they have a high level of confidence in their ability to use the internet and other communication devices to keep up with information. Challenges in affordability and lack of high-speed internet are related barriers, which are discussed later in this report.

C. Importance of Representation and Diversity in Technology Development and Policy

Today, algorithms and machine learning systems are used to make decisions in some of the most important spheres of our daily life: government services, employment, commerce, health, housing, immigration, and the criminal and civil legal systems. One disability justice leader describes the algorithm’s role as: “ubiquitous – renting, food stamps, hiring, decisions about whether or not you are allowed out on bail . . . Algorithms affect every part of our lives.” Yet, the technology and design sector, where these systems and tools are created, is not representative of today’s daily life as it continues to be dominated by white men. A report developed by AI Now Institute found that in 2019, Black workers represented only

2.5 percent of Google’s workforce and 4 percent of Facebook’s and Microsoft’s, while globally only 22 percent of AI professionals were female. The report did not account for disability, and as a general matter, reporting among major technology companies in their public diversity demographics with respect to disability is spotty; many smaller companies may not be reporting this information at all. (However, a lack of reporting does not necessarily mean companies lack disabled employees). Without diverse design perspectives, and especially when algorithms are trained on unrepresentative datasets that reflect historical biases, inequitable outcomes are less likely to be anticipated and mitigated. Argued one advocate, “We also know from work by technologists, public policy experts, and activists that systems of oppression in society are baked into these algorithms.”

Cross-Cutting Themes

D. Algorithmic Bias and Inability to Capture Disability Experience

In addition to this lack of representation, several interviewees emphasized the fundamental inability of algorithms to even capture the full diversity of disability experience and expression. Said one disability rights scholar, “Disability is not well defined from a data perspective – the only common characteristic is sufficient difference from the norm . . . Bias detection systems do not detect bias against diverse, variable populations in flux.” Compared to other characteristics like race, gender or education level, disability is much harder to account for in code, the expert argued, given the wide array of disabilities. Or in other words, the experiences, needs and barriers that marginalized communities face, including disabled people, by definition cannot be quantified neatly, causing traditional “bias auditing” efforts to fail. Some interviewees argued that the bias contained in artificial intelligence technology is inherent, thus creating an even greater need for collaborative approaches to combat and lessen the potential harms baked into these systems.

Many interviewees emphasized how algorithms serve to make decisions based on a perceived “normal,” and this focus inherently marginalizes individuals with disabilities. One technology justice advocate explained the dual danger of these algorithms in diminishing rights to positive and negative liberty: “Really anywhere that algorithms are deterministic, anyone who is not normative will be more harshly impacted or will not be able to get access to what they need.” The decision-making power of these biased tools can and does have a disparate impact on historically marginalized groups, perpetuating and amplifying racism, sexism, ageism, and ableism. One technology policy advocate described the dangers of this technology, “There are very broad implications and intersections with white supremacy in how technology defines a normative range/ideal and compares everyone to it.” A disability expert, however, cautioned that these challenges around “normal” should be viewed in a wider, historical context. “Even before algorithms, concepts of normal have been used to oppress and bias systems and policies against disabled people and other historically excluded groups,” this individual noted.

[]“Disability is not well defined from a data perspective – the only common characteristic is sufficient difference from the norm.”

Issue Areas

A. Access to High-speed Internet & Devices

Issue Overview

Access to high-speed internet is essential to participating in today’s society and economy. The internet has become vital to finding and obtaining employment, full inclusion in education, utilizing basic services such as banking, and simply staying connected to the outside world and our communities. In addition to social and economic inclusion, the internet is also vital to democratic inclusion as connecting with movements to organize for racial and social justice, keeping up with community events, and discussing political priorities all frequently happens online.

Since the COVID-19 crisis began, the need for high-speed affordable internet is more apparent than ever; as one disability rights leader stated, “Now people understand what it means to go without broadband. The pandemic has crystallized how much of a civil rights issue broadband is for communities of color, people in rural areas, and those with disabilities.” Despite the clear need for high-speed internet in the home to fully engage in society and our economy, millions of people in the United States lack adequate home internet access. (High-quality data is in short supply, but one estimate puts it at approximately 42 million people who do not have true high-speed internet at home).

Unsurprisingly, people of color and people with low incomes are disproportionately without high-speed internet. In 2018, the Census Bureau estimated that among Native Americans who live on tribal lands and own a computer, only 53 percent have high-speed

   A. Access to High-speed Internet & Devices

[]
internet. Not only are people with disabilities – particularly those of color – less likely to have the internet at home, but some evidence suggests they are less likely to even use it at all. According to a survey conducted by Pew Research Center in 2021, 75 percent of

U.S. adults living with a disability report using the internet on a daily basis, compared with 87 percent of adults without a disability. In the same survey 26 percent of disabled adults reported having highspeed internet at home, a smartphone, a desktop or laptop and a tablet, compared with 44 percent of those who reported not having a disability.

[]“Now people understand what it means to go without broadband. The pandemic has crystallized how much of a civil rights issue broadband is for communities of color, people in rural areas, and those with disabilities.”

Sub-issues

•     Cost of high-speed internet services: In addition to accessibility, one major barrier to internet adoption and use for people with disabilities is the high and fluctuating cost of the internet. And due to systemic barriers, such as labor market discrimination, lack of opportunity and restrictive income and asset limits for supportive programs like Medicaid, individuals with disabilities are more than twice as likely as nondisabled people to live in poverty. These wealth and income gaps are even more apparent across race and disability status: the poverty rate for adults with disabilities is 27 percent, while the poverty rate for Black adults with disabilities is even higher at 37 percent.

•     Accessible and affordable devices: Disability and technology advocates emphasized that the high cost of accessible devices or the high cost to have accessibility features added on to devices could be acting as a barrier to internet use and adoption by people with disabilities. Additionally current federal programs that provide subsidies for devices are one-size-fits-all and do not incorporate the potential extra costs of assistive technology. Assistive technology can be a significant expense not covered by insurance, leaving many individuals to rely on nonprofit providers.

One technology justice advocate also explained how the combination of a lack of affordable accessible devices and highspeed internet can also lead to the harm of greater surveillance, especially for low-income and marginalized groups who can’t afford other devices: “If you are a student without access to broadband, it is much more likely that there is technology that has access to you. When you only have access through mobile phones, it is much more likely to be tracked and surveilled.”

   A. Access to High-speed Internet & Devices

Example Opportunities

•     Create a permanent broadband benefit: In an effort to make high-speed internet service affordable for all, many in the technology justice field advocated to make the Emergency Broadband Benefit, or EBB, permanent. One technology justice expert explained, “I see broadband as another utility like gas, power, and water, and the access should be at a similar level.” EBB is a temporary program created by the Federal Communication Commission (FCC) to provide a discount toward broadband services and a subsidy for devices during the COVID-19 pandemic. Following extensive advocacy from the public interest community, EBB will be replaced with a permanent $30 monthly benefit under new legislation enacted in November 2021.

•     Enhance Lifeline and the Tribal Benefit: Advocates are calling for increased voice and broadband support through the Lifeline program. Lifeline is the FCC’s program to help make communication services, including internet and telecom, more affordable for low-income consumers. A coalition managed by MediaJustice works on Lifeline and related issues.

•     Support assistive technology programs: States run assistive technology (AT) programs authorized and funded under federal law. The Association of Assistive Technology Act Programs (ATAP) is a nonprofit network that supports and coordinates state AT programs and helps achieve their mission of demonstrating, loaning, and supporting re-use of assistive devices. Advocates, private sector actors, and others have the opportunity to support funding for these and related programs.

[]“I see broadband as another utility like gas, power, and water, and the access should be at a similar level.”

B. Economic Security

Issue Overview

Technology is playing a growing role in obtaining and maintaining economic security, and advancing economic security lies at the center of the disability community’s advocacy work. The U.S. Census Bureau reports that people with disabilities are twice as likely to live in poverty than people without disabilities; one advocate underscored this gap, declaring, “Our biggest challenge 30 years post-ADA is most of us are still living in poverty.” According to research done by the National Disability Institute, this inequity is exacerbated for people of color and women with disabilities.

These income gaps are all the more harmful because living with disabilities is inherently more costly – the National Disability Institute estimated that for the average adult with a disability to achieve a similar standard of living as their non-disabled counterpart, they would need to have 28 percent more income. As a result, disability is both a cause and consequence of poverty. As demonstrated above, disability increases the likelihood one is living in poverty, and living in poverty exposes one to living conditions that can increase the likelihood of developing a disability.

Given both added living costs and the long history of discrimination in our society people with disabilities face, government income and benefit supports are vitally important to economic security. For example, one out of five households using the Supplemental Nutrition Assistance Program (SNAP) includes a person with a disability. Benefits programs span a variety of other needs contributing to stability and economic security, like housing and utilities, healthcare, and other income support.

Technology today increasingly mediates access to these essential supports and can reinforce pre-existing disparities. “General government services like SNAP and SSI are offered to people with disabilities with low incomes, including disproportionately those with Black and brown skin. But the government doesn’t understand that it is their responsibility to provide communication

   B. Economic Security

access,” said one interviewee, underscoring the difficulty for some disabled people to access benefit programs that have moved online. This individual added, “Deaf people get referred to a private interpretation service that they are supposed to pay for themselves, but they cannot afford an interpreter.” In addition, algorithmic decision-making, apps, and AI tools are not just relegated to the private sector, but are increasingly being adopted by federal and local government, including to make decisions around benefit access and apportionment, creating additional barriers to an inclusive economy for those with disabilities who are more reliant on these programs. At many steps in the process, algorithms are now the decision-makers, lifting accountability from the shoulders of government, while also gatekeeping and reinforcing barriers to economic security that exacerbate power asymmetries and leave people with disabilities out. (During the pandemic, these barriers have been further compounded by the closure of in-person offices).

Sub-issues

•     Benefits access/management: In some cases, the government uses automated decision-making around benefit access and use, including healthcare services and home healthcare screenings. These algorithms have caused individuals with disabilities to wrongly lose the support services they need. For example, an algorithm used to assess healthcare needs in Arkansas was found to have failed to account for whether a patient had diabetes or cerebral palsy, and, in doing so wrongly, assigned patients too few hours of care. Additionally, these algorithmic systems have disrupted patients’ experience with their benefits. For example, Electronic Visit Verification (EVV) is a federally mandated system for Personal Care Services and Home Health Care Services that is funded through Medicaid. EVV requires caregivers to clock in and out of an app, taking up time that could be devoted to providing assistance and creating new burdens for low-wage workers who may not have adequate devices. It also creates a maximum distance at which the worker can clock in and out, functionally relegating them and their client to a specific geofenced space. (And for those living in rural areas or others with poor connectivity, it may be difficult for workers to verify

their visits). One technology justice leader explained the threat behind these systems: “It is a program meant to help people live a full life in society and then limits and surveils them.” In creating a geofenced location and adding administrative burden, the EVV system erodes disabled people’s autonomy and places the home care worker, many of whom are women of color, under unnecessary scrutiny.

•     Housing algorithms and disparate impact: Landlords and property managers use tenant screening tools to send tenant’s applications to systems that compare their data against records. Advocates stress that these systems, which can use data on past arrests, evictions, or credit scores, can in effect be making denials on proxies for disability and race. The tools lessen the opportunity for recourse and provide greater opportunity for discrimination, even where the law prohibits it. “Now landlords can attempt to evade accountability or culpability through screening companies,” one disability justice leader said. “Tenant screening companies use algorithms that use information, some of which is illegal to consider, and others may be legal, but have amplified discriminatory impact.” These technological tools can make it even harder for disabled people to use benefits – like Section 8 vouchers – to which they have a right.

Example Opportunities

• Support efforts in partnership and led by disability organizations to design benefit programs that work best for them: In response to the threats to disabled individuals’ autonomy and home direct support workers’ privacy perpetuated by the EVV system, United Domestic Workers and Disability Rights California designed an in-house web portal that utilized California’s existing Electronic Timesheet system and did not collect GPS data or require workers to log their hours in real time.

The federal government rejected this proposal as not compliant. There is an opportunity for technology justice organizations to bolster advocacy and technical support for these types of ongoing efforts.

   B. Economic Security

• Bolster advocacy efforts to strengthen legal protections against algorithmic discrimination: In September 2020, the Department of Housing and Urban Development proposed a rule that would change disparate impact claims under the Fair Housing Act and make it more difficult to bring cases involving algorithms. The public interest community opposed this rulemaking on grounds of racism and ableism. The Biden administration has since released guidance against this rule, and most recently, HUD has proposed a rule reinstating the discriminatory effects standard. Collaborations between technology and disability advocates may present further opportunities, such as for reports advocating for accessible and affordable housing to include the implications of tenant screening algorithms in their recommendations to HUD.

C. Equitable Employment

Issue Overview

Equitable access to gainful employment, hiring programs, workforce development, and government benefits and services are necessary to an inclusive society that maintains economic security, opportunity, and dignity for all. People with disabilities face many added barriers to employment that can put economic security out of reach and make access to government benefits, as discussed earlier, all the more imperative. These barriers include: added living costs, transportation difficulty, insufficient housing, and lack of access to needed supports and services. Crucially, technology now plays a role in mediating and often exacerbating these challenges.

Due to these barriers and long-term biases in the workforce and employment sector, in 2020 the unemployment rate for people with disabilities was 12.6 percent compared to 7.9 percent for people without a disability. This inequity is heightened for disabled women and disabled people of color. The unemployment rate for men with a disability was 12 percent, while the unemployment rate for women with a disability was 13.2 percent. The unemployment rate for white people with a disability was 11.6 percent, whereas the unemployment rate for Black people with a disability was 16.3 percent, for Hispanic people with a disability was 13.2 percent, and for Asian people with a disability was 15.7 percent.

Now, in addition to added barriers and a lack of employers that are inclusive of people with disabilities, technology and the way algorithms are designed can diminish disabled people’s chances at even getting an interview, let alone successfully obtaining a job, regardless of their qualifications. These new tools can perpetuate (and formally embed) long-standing biases across the job market at large. Additionally, technology and how algorithms are used to manage employees poses new challenge for disabled individuals to successfully maintain a job and can shift accountability from employers to provide workplace accommodations.

   C. Equitable Employment

Sub-issues

•     Hiring technologies: Algorithm-based online hiring assessments and other AI recruiting tools perpetuate biases before a candidate can advance in the employment process. A report examining a commonly used hiring assessment, found that its algorithm “massively discriminates against many people with disabilities that significantly affect facial expression and voice: disabilities such as deafness, blindness, speech disorders, and surviving a stroke.” A disability rights leader also noted the disparate impact personality tests specifically have on people with mental health, developmental, and cognitive disabilities, declaring, “Personality tests most directly get at disability in that they are designed in a way that asks questions that are trying to ferret out disability in many cases, particularly for those who have a psychiatric disability or autism.” “The Americans with Disabilities Act specifically prohibits the screening out of candidates with disabilities through inaccessible hiring processes or ones that do not measure attributes directly related to the job in question,” one disability rights leader explained, noting that technology in many cases has enabled the removal of direct accountability, putting distance between human decision makers and the outcomes of hiring processes.

•     Workplace algorithmic management: The use of algorithms to remotely oversee and manage human workers can be used to hide discrimination, surveil individuals, and distance companies from the effects of their decisions. One example of this is Amazon’s Flex program in which drivers pick up and deliver packages using routes indicated on an app and receive incentives and penalties from the app to guide their behavior. Many of these tools are purported to foster efficiency; thus, one advocate argued these tools most likely do not accommodate for the lived experience of workers with disabilities. “Technology tries to enforce a pace of living and way of interacting based on assumptions around how people function that do not work for how disabled people function,” the expert noted. For example, Amazon’s algorithmic management system has been reported to fire the slowest people, regardless of the individual’s disability or access needs.

[]“Personality tests most directly get at disability in that they are designed in a way that asks questions that are trying to ferret out disability in many cases, particularly for those who have a psychiatric disability or autism.”

•     Gig economy: Gig economy jobs offer both opportunities and peril for people with disabilities. The freedom and flexibility that comes with working a gig job and setting one’s own schedule can be highly beneficial to people with disabilities. This flexibility is valuable when, for example, there is a frequent need to take time off for medical appointments or if one cannot work long, contiguous hours. Some gig companies are also actively working to hire individuals with disabilities. Lyft, for example, has partnered with the National Association of the Deaf to hire more deaf drivers, and Uber built a partnership with Communication Service for the Deaf to improve the experience for deaf drivers.

On the other hand, the nature of the gig economy also leaves many people with disabilities vulnerable to income volatility and exploitation. Since gig workers are currently categorized as independent contractors, employees receive no employee benefits like health insurance, retirement, unemployment, paid leave, or Social Security; similarly, most employment anti-discrimination and worker protection laws do not protect independent contractors, a gap that is likely to have an outsized impact on disabled people. As noted, due to historic discrimination and added barriers, people with disabilities also face a higher cost to living that would make living without these benefits or protections extremely difficult. Additionally, not being able to budget how much one will earn on a regular basis could be especially dangerous for people with disabilities if they are unable to meet or plan for unexpected needs, such as medical bills.

Example Opportunities

• Advocates have called for government oversight and accountability to stem the disparate impact of hiring technologies in the private sector: Technology justice advocates have urged the Office of Science and Technology Policy, the Senate, the Equal Employment Opportunity

Commission, and the Office of Federal Contract Compliance Programs to protect job seekers and specifically disabled job seekers through investigations, increased oversight, and updated

   C. Equitable Employment

guidance. Advocates are also engaged in work to explore specific types of hiring technologies to inform government agencies, employers, and jobseekers about the range of technologies used and their potential violation of civil rights laws, including the ADA.

•     Approach hiring technology with nuance: AAPD’s program StartAccess, which focuses on building accessibility in start-up companies from the beginning, is working with disability-led startups to elevate the use of technology to help people with disabilities find work and adapt ableist job applications. For example, AI-enabled assistance can help individuals complete an inaccessible application or interview with automated transcription or text-to-speech services. On the other hand, many of these tools are rarely offered separately from the capabilities of gathering data on user preference and could pose a threat to the candidate’s privacy.

•     Crafting intersectional disability principles and recommendations around these technologies: Projects like the Civil Rights Principles for Hiring Assessment Technologies and Algorithmic Accountability Policy Toolkit are intended to challenge and inform the development and use of algorithmic decision-making tools, especially those in the context of hiring and benefits. Additional efforts for other use-cases are likely needed, emphasizing the voices of the disability community.

D. Privacy and Commercial Data Practices

Issue Overview

Across the United States, state and sectoral privacy laws provide the primary forms of data privacy protections enjoyed by most adults. However, these laws often do not contain explicit antidiscrimination protections or effective enforcement provisions. This lack of regulation of commercial data leaves everyone vulnerable to harm, but historically marginalized groups, including people of color and people with disabilities, are even more at risk. Personal data can often act as a proxy for race, gender, income, age, and disability, enabling explicit and implicit discrimination alike. People with disabilities’ use of platforms and other technologies can create a digital footprint leading to targeting, discrimination, exclusion, or the misuse of sensitive medical data.

In recognizing these privacy harms, disability advocates stressed the need to strike a balance between protecting disabled people from further marginalization, while also acknowledging the benefits of data sharing in its ability to promote independence for people with disabilities. For example, a person who is blind may use an app for wayfinding that constantly shares their location data, exposing them to potential targeting, but this data also provides new means to independence. One disability advocate explained, “Members of our community are accustomed to revealing intimate details about our lives, bodies, and minds to get access to resources that meet our basic needs. Our relationship to privacy is very different from a community that does not live that reality every day.” In the work to shape and pass much needed comprehensive federal privacy legislation, it will be essential to grapple with the unique needs of the disabled community.

   D. Privacy and Commercial Data Practices

Sub-issues

•     Internet of Things (IoT): In some cases, IoT devices in homes, cars, and on bodies have enhanced the autonomy of people with disabilities in reducing their dependence on others. For people with certain physical disabilities, “smart home” technologies allow them to adjust temperature, lights, or security systems without ever needing to physically touch them. Yet, IoT devices pose unique privacy risks as they collect, share, and use intimate data that can be used to discriminate against or target disabled people. One technology justice expert cautioned, “IoT paints a granular and dynamic picture of your daily behavior. We will need to ensure IoT data is not used to discriminate against people with disabilities around health and home insurance premiums or other benefits and services.” Some advocates also noted that many of these IoT devices are not inclusive of all disabilities if they only use voice recognition. As one disability expert warned, “If we move away from having the ability to press the button, then we [deaf individuals] are out. How do we think about that in the design?”

•     Personal biometric data: Makers of IoT systems and other connected devices are adopting biometric authentication, a process that uses unique biological characteristics such as one’s iris or fingerprint to verify their identity, as a security system.

Although biometric authentication may provide additional means of accessibility for people with certain disabilities, advocates also noted that the use of personal biometric data may include highly sensitive information related to someone’s disability that could pose added privacy concerns. Such technologies may also exclude individuals with certain disabilities, for example those with prosthetic eyes.

Example Opportunities

•     Technology policy and disability leaders have produced a report addressing the implications of data privacy harms for people with disabilities: The Future of Privacy Forum and Community Living Policy Center at the University of California, San Francisco co-authored a report addressing the benefits, challenges, and privacy implications of IoT technology.

•     Host convenings and cross-sectoral meetings around the implications of data privacy regulations for people with disabilities: Advocates called for forums and collaboration on privacy that include advocates and organizations from the technology justice, broad civil rights, and disability rights communities. One current example of this type of forum is AAPD’s Tech Forum which convenes disability organizations and industry groups to discuss technology, access, autonomous vehicles, and data privacy in order to strike a balance between civil rights protections and recognizing the benefits data sharing can have for people with disabilities. In other cases, public interest organizations have partnered with accessible/assistive technology companies to review and amend their privacy practices.

   E. Amplifying Hate Speech and Issues of Free Expression

E. Amplifying Hate Speech and Issues of Free Expression

Issue Overview

For many, online platforms are the pre-eminent public space. Just a few of the forms platforms assume for users include hubs for taking in information, consuming and creating entertainment, conducting business, and socializing. These public spaces are not restricted by physical bounds; instead, they reach across borders and oceans to connect billions of people. Importantly, for members of many historically marginalized groups, social media provides a space to reach others who have similar experiences, share their story, organize, and make money. For example, #CripTheVote is a hashtag that has been used to reinforce the need for voting stations to be accessible and to bring political candidates’ attention to issues affecting the disability community. Additionally, Aaron Phillip, a Black disabled transgender influencer, became a model for Sephora, Nike, and Dove after building a presence and community on Twitter.

Yet, the reach of platforms also evokes unanswered free expression questions, requiring more work to protect civil rights online. Inadequate content moderation systems and processes have heightened the speed and spread of propaganda, targeted disinformation, voter suppression campaigns, and discriminatory hateful content often targeted at people of color, religious minorities, women, disabled people, and transgender and gender-nonbinary people. A UK study, conducted in 2018, reported online hate and abuse targeting people with disabilities was growing at a rate of 33 percent from year to year. But at times, even good-faith efforts to address abuse also harm these groups, unfairly limiting their ability to organize. Given the centrality of platforms to modern life and the disparate harms these individuals face, building an online environment that is truly inclusive of and equitable for people with disabilities requires a serious commitment to addressing these challenges.

[]“I strongly suspect the training data that companies use is under-inclusive of people with disabilities. AI will not learn to meet the needs of that population.”

Sub-issues

•     Content moderation/free expression: Several disability advocates explained that – in addition to their communities being subject to online hate and abuse – the disability perspective is not included in the policies and systems put in place to moderate content. Said one expert, “We see all kinds of design challenges where disability is constructed as a problem to be solved as opposed as an identity to be embraced. People with disabilities are tacked on and not brought into the design process as experts themselves.” In 2019, TikTok admitted to hiding the content of creators deemed “vulnerable to cyberbullying,” such as people with “facial disfigurement, autism, and Down Syndrome.” Although TikTok might have crafted this policy in good faith (and has reportedly since removed it), because the company did not design these policies with the consultation of people with disabilities, this policy discriminated against disabled creators and denied them access to the platform’s full economic, political, and cultural opportunities.

•     Automated content moderation: Confronted with an evergrowing volume of content to oversee and growing costs for human-driven oversight, large platform companies are turning to automated moderation tools. The COVID-19 pandemic further accelerated these trends. However, when platforms use AI in content moderation, marginalized groups are often treated unfairly, a technology justice leader explained. “I strongly suspect the training data that companies use is under-inclusive of people with disabilities. AI will not learn to meet the needs of that population,” and “it can’t handle context well,” this expert said. When an algorithm makes the initial decision to flag posts and accounts are removed or suspended, it is particularly difficult to determine why the posts were flagged or get them reinstated. When Facebook sent their human content moderators home during the pandemic, the number of successful content appeals went from 2.3 million in the first quarter to 12,600 for the second quarter. Advocates questioned whether the AI used to

   E. Amplifying Hate Speech and Issues of Free Expression

substitute for human content moderation and the corresponding delays in the appeals process might have a disproportionate impact on people with disabilities, especially those who have communication barriers. (One advocate cautioned, however, that these disproportionate impacts on people with disabilities might also apply to the use of standardized processes with underpaid and overworked human content moderators).

These challenges with automated content moderation can even show up in the advertising context. The algorithms that are used by platforms to manage commercial practices, like advertising, have real potential to discriminate against people with disabilities and lessen the ability of the disability community to engage in online commerce. Facebook’s automated advertising center has repeatedly mislabeled and taken down ads for adaptive clothing brands for people with disabilities.

• Dis/misinformation and voter suppression: Following an election cycle riddled with online mis- and disinformation, some advocates highlighted the disproportionate impact this content would have on disabled people’s ability to vote. One technology justice leader explained how online mis- and disinformation could have a disproportionate impact on people with disabilities who might face additional accessibility challenges to voting, “Their ability to access voting might be more reliant on the information about the state of a voting facility or the drop box.” Due to systemic inaccessibility in the voting process disabled people were about 7 percent less likely than nondisabled people to vote in 2020 elections. A disability rights advocate explained the disproportionate impact targeted online disinformation campaigns could have on disabled people of color, arguing, “There is an attempt to restrict voters of color, and a huge subset of those voters of color are people with disabilities.”

Example Opportunities

•     Include disability organizations in campaigns to stop online hate: Stop Hate for Profit and Change the Terms are ongoing campaigns to hold social media companies accountable for hate on their platforms; advocates noted that there is an opportunity for future campaigns like this to center the impact online hate has on the disabled community.

•     Explore disability perspectives on online hate and extremism through public opinion research: Advocates called for greater documentation of how online hate affects disabled people, groups in the United Kingdom have conducted surveys that include the disability perspective on online hate. Current annual polling of online hate and extremism in the United States, like the American Views on Trust Media and Democracy, could specifically include the disability perspectives to document the severity of hate, misinformation, and disinformation targeted at people with disabilities and people with disabilities who identify as coming from multiply marginalized communities in the United States.

   F. Education and Student Surveillance

F. Education and Student Surveillance

Issue Overview

Today law enforcement, immigration and customs officers, and now even public school administrators are using a wide array of surveillance technology purchased from private vendors. These surveillance technologies include social media monitoring and student threat assessment management software, which can facilitate discrimination based on racism and ableism and ultimately lead to disciplinary action including suspension and/or expulsion from school. These tools purport to identify students who are at risk of committing violent acts or self-harm, but their effectiveness is unproven, and the consequences can exacerbate disparities. One disability justice leader explained how school surveillance tools specifically amplify those disciplinary measures that affect disabled students, and in particular disabled students of color: “Because we know from previous circumstances that discipline falls on marginalized students – the monitoring will most likely have a similar impact.”

The use of these discriminatory surveillance technologies can have threatening and life-altering impacts for disabled students, particularly those of color. According to a report by the U.S. Commission on Civil Rights, disabled BIPOC students are disproportionately disciplined or removed from schools, contributing to the school-to-prison pipeline. This school-to-prison pipeline is important to note, as a report from the Center on American Progress found that people with disabilities are disproportionately represented in state and federal prison. Technology that exacerbates these long-standing disparities should be of significant concern, many interviewees argued.

The use of technologies to monitor children in schools has been catalyzed even further by the pandemic and the advent of widespread e-learning and e-proctoring tools to oversee test taking. One technology justice leader explained how automated surveillance technologies can have a disparate impact on people

[]“A lot of what automation does is it makes deviating from an average trigger all kinds of scrutiny, leading your existence to push you up against what is the status quo.”

with disabilities: “A lot of what automation does is it makes deviating from an average trigger all kinds of scrutiny, leading your existence to push you up against what is the status quo.” For example, e-proctoring video software that monitors movement with AI could flag a student with cerebral palsy who has spasms as suspicious, and “disengagement monitoring” features may not be effectively tailored for all disabled individuals.

Sub-issues

•     Student social media monitoring software: In the wake of mass school shootings many districts have started spending more on social media monitoring software, but there is little evidence that these tools are making students safer. In addition to privacy concerns, students who are already at a higher risk for surveillance and punishment, like disabled students of color, may censor themselves. One technology justice expert highlighted the chilling effect of this over-surveillance on students’ free expression: “Social media allows people to have a vision of their life. That can be a rich part of the internet, but what does it mean to have that data be misinterpreted or used to make determinations about eligibility for services or risk for other things?”

•     Student threat assessment software: School districts and states have begun adopting student threat assessment management software that collects information such as history of mental illness, social media posts, feelings of anger, and foster care records to create profiles of students that when triggered can lead to disciplinary action while removing culpability for those actions from school authorities. A disability justice leader explained how technology amplifies the reach of these programs, noting, “We know that schools increasingly use safety management software to bolster threat assessment programs.” A disability rights leader stressed the disparate impact these tools would have on disabled students, especially those with cognitive disabilities: “Some of the factors they are using are very directly disability related, for example if someone had a psychological evaluation – they seem to be screening for disability.”

   F. Education and Student Surveillance

• Student monitoring through devices and e-proctoring: To address the inequity of the digital divide, which has been shown to be wider for low-income students and particularly for low-income students of color, some schools issued devices to students. The COVID-19 pandemic and the shift to remote learning have further expanded the use of school-sponsored devices as well as AI tools that enable the monitoring of students. E-proctoring service Proctorio saw its business increase 900 percent during the first few months of the pandemic. These services use facial recognition technology and monitor students by tracking eye movement and keyboard typing as they take tests. A recent report issued by CDT found that students using these school-issued devices were under more monitoring than wealthier students who were using their own personal devices. Disability and mental health advocates stressed that in addition to violating student’s privacy, these monitoring tools have produced false positives and mislabeled atypical behavior as cheating and could inaccurately flag disabled students due to differences in how they move or communicate.

Example Opportunities

•     Inform child privacy legislation with a disability lens: Student Privacy Compass released these inclusive principles, signed by 40 organizations including civil rights, disability and technology groups, for school safety to protect all students’ privacy, dignity, and right to equal education. The principles address student surveillance, data collection and use, and other topics.

•     Include disability organizations in campaigns to ban e-proctoring: Advocates called for including the disability perspective in advocacy around e-proctoring. There is an opportunity for campaigns calling to ban e-proctoring like this one from Fight for the Future to collaborate with disability advocates and others working on accommodation in education.

G. Law Enforcement

Issue Overview

Many interviewees argued that disabled people, and disproportionately disabled people of color, are over-surveilled, policed, and criminalized by law enforcement agencies. The abuse of technology by policing and immigration institutions can create new avenues to power that replicate and amplify existing systems of oppression – locking many people with disabilities out of equal opportunity and access to their civil rights, while continuing to criminalize and surveil mental health. One disability rights leader explained, “Things escalate, and the police are not situated to handle someone who is having a mental health crisis or is just behaving differently, contributing to why there is such a significant disproportionate number of criminal records among people with psychiatric disabilities in particular.”

The dangers of law enforcement surveillance are intersectional. For example, police use of algorithms to forecast crime risk perpetuates a cycle that uses historical data generated by concentrating policing in areas with a large population of people of color to justify more policing in those areas; there is also a disproportionate frequency of intellectual and developmental disabilities among low-income people of color who may live in many of these neighborhoods targeted by police. One technology policy advocate explained, “The technology aspect doesn’t account for mental health – it just says, ‘This is a crime hot spot, and because you have had many interactions with police, we think you are dangerous.’” (Some predictive policing technologies use person-based approaches, while others are place-based). To the extent these surveillance and predictive analytics tools generate additional interactions between police and disabled individuals, they create new risks of harmful outcomes. One expert from the disability community warned of the harms that can result when police are not aware of

individuals’ disabilities. “We are seeing situations where there is a communication breakdown because the person [law enforcement] are dealing with is deaf, and that person could be having a mental

   G. Law Enforcement

health issue and also has brown or Black skin. [The police] are expecting people to comply, but how is that possible when they can’t hear you?” the expert cautioned.

One effect of policing and surveillance can be seen in the mass incarceration of people with disabilities; a report from the Center for American Progress found that people in state and federal prison are almost three times as likely to report having a disability and almost four times as likely to report having a cognitive disability like Down syndrome than the non-incarcerated population. Additionally, the implementation of automated systems and technologies to surveil and screen immigrants has further threatened immigrants’ rights and the lives of disabled immigrants. Interviewees argued that the government’s use of technology in immigration settings also has reduced due process protections and stripped away avenues and means to communicate for immigrants.

Sub-issues

•     Facial recognition software: An MIT study, led by researcher Joy Buolamwini, showed the dangerous inaccuracy of major facial recognition tools. It found that algorithms powering three facialanalysis software systems had an error rate of only 0.8 percent for light-skinned men, compared to an error rate of 34.7 percent for dark-skinned women. Although facial recognition software is used by entities other than law enforcement like schools and retail stores, the use of this biased AI in the criminal and legal system can lead to false accusations and arrests. These tools further endanger the lives of Black and brown people and Black and brown disabled people who are already historically targeted for policing and surveillance, as exemplified by the wrongful arrest of Robert Williams in 2020. Yet, technology justice leaders also cautioned that facial recognition technology, when not used by law enforcement or government in a surveillance setting, has increased autonomy for members of the disabled community, for example through a face recognition app for people with visual impairments. “ On the flip side about calls to prohibit use of facial recognition: if not carefully tailored, those calls could have a negative impact on people with disabilities” one expert warned of blanket bans on facial recognition.

[]“Things escalate, and the police are not situated to handle someone who is having a mental health crisis or is just behaving differently, contributing to why there is such a significant disproportionate number of criminal records among people with psychiatric disabilities in particular.”

[]“Technology policy decisions are being made to buy VRI tech without the inclusion of deaf people to see if this tech does work for us.”

•     Predictive policing and risk assessments: One technology justice advocate noted that AI-informed hotspots for policing might have a disproportionate impact on people experiencing homelessness with developmental disabilities, who due to these hot spots, may have had many interactions with police and correspondingly become tagged as dangerous. A technology justice leader explained that in addition to violence prediction tools and hotspots, other automated assessments like those predicting failure to appear might disproportionately affect disabled people. “There is a lot of acknowledgement of poverty being a measure of whether you have transportation, childcare, a job that you can take time off of, but disability might relate with transportation access and the need for appearing,” this expert noted.

•     Video Remote Interpreting: Video Remote Interpreting is used by police to connect with an interpreter on demand instead of waiting for one in person. But according to the leaders of a disability organization, “The tendency is to over-rely on this technology that is sometimes inaccurate. Black and brown deaf and hard of hearing individuals are disproportionately harmed by the unreliable use of VRI.” Advocates stressed that when police interactions are a matter of life and death, these technologies are not sufficient due to the imperfect way they convey sign language and their potential to malfunction during a time-sensitive moment. Further these advocates noted that this technology is being treated as a panacea without incorporating the perspectives of deaf people. Said one expert, “Technology policy decisions are being made to buy VRI tech without the inclusion of deaf people to see if this tech does work for us.”

•     Video phones in prison: Few jails or prisons have video phones, even though they are the equivalent of the telephone for hearing people, having a disproportionate impact on Black and brown deaf people’s ability and right to communicate.

•     Border screening: DHS’s purchase and use of surveillance technology and automated decision-making tools, including those provided by Palantir, may screen families and children without recognizing that they are deaf or hard of hearing and

   G. Law Enforcement

most likely communicate with a different, non-ASL version of sign language, potentially leading to some deaf and hard of hearing immigrants sitting at the border having no way to communicate or mislabeling them as “threats” further targeting them for surveillance.

• Gait recognition: Gait recognition is a surveillance technology used to identify individuals and track the way one moves when walking, in the past DHS has used gait recognition at travel checkpoints to flag individuals as a threat and target them for further surveillance or questioning. One technology justice advocate explained that these tools have flagged people based on the number of times they go to the bathroom or even because of the way they walk, all of which could have a disproportionate impact on someone with disabilities and lead to unjust scrutiny.

Example Opportunities

• Include disability justice groups in drafting proposed legislation and regulation of facial recognition technology: Leaders in the disability justice space called for current advocacy work, like coalition letters to the administration on federal use of facial recognition technology, to lift up the potential harms and impact of facial recognition on people with disabilities. While advocates also called for proposals around the use and regulation of facial recognition to incorporate the perspective of individuals with disabilities, especially as comprehensive bans on facial recognition in the private sector could disproportionately impact disabled users who rely on the technology.

H. Healthcare

Issue Overview

Healthcare is one of the systems many people interact with on a regular basis. Similarly to education, criminal justice, and other parts of our societal infrastructure, healthcare has also introduced technology as a means to improve efficiency and outcomes. This approach can carry significant consequences, however. Artificial intelligence has been increasingly utilized by the healthcare industry in recent years, but like use in other areas, can and does result in bias affecting marginalized groups, including people with disabilities. “Companies will hide [AI] behind trade secrets and HIPAA. There is a need to figure out if companies are being honest,” said one advocate, noting the lack of transparency in the health industry’s use of AI and the corresponding danger. “a lot of what tech companies have said about auditability was false.” AI bias in healthcare is particularly alarming in the context of disability rights because depending on individual health conditions and medical needs, some people with disabilities must rely on and interact with the healthcare system on an extremely frequent basis, and for some, as a means of survival and ability to perform daily functions. As a result of this interconnected relationship between disability and healthcare, AI- and other technology-driven harms within the medical and health-related fields can have particularly devastating results for disabled people.

One of the ways in which these harms manifest is through the use of algorithms. Algorithmic decision-making systems are used in healthcare settings to make treatment decisions, guide or limit care, as well as inform other high-stakes decisions that directly impact patient care. As one disability rights expert expressed, “Algorithms and [their] impact is inescapable.” When these automated tools intersect with false, racially biased beliefs about health issues such as pain tolerance, their harmful impact can be compounded further. As discussed in other sections of this report, algorithms (and AI, more broadly) generally do not capture disability well. The vast diversity among people with disabilities requires nuance and individualized approaches, which runs counter to the nature of algorithmic decisions within healthcare.

Sub-issues

•     Telehealth: In part, due to COVID-19, telehealth appointments are becoming increasingly common. According to the Kaiser Family Foundation, nearly half of all primary care visits among Medicare recipients in April 2020 were via telehealth; this represents a 350-fold increase as compared to pre-pandemic levels. This growth reflects both greater participation rates among patients, as well as expanded Medicare coverage to include telehealth visits. The expanded use of, and need for, telehealth visits as a result of COVID-19, results in obvious barriers for many in the disability community, based on the need for greater accessibility and disability-centered design within the technology sector. Many disabled people are simply unable to use tech platforms and programs because they weren’t built with disability in mind, in addition to lack of broadband access and other socioeconomic circumstances that limit tech usage and are overrepresented among people with disabilities.

Additionally, although expanded use of telehealth by medical providers may benefit some with disabilities, particularly those whose primary condition limits mobility, this can also create barriers for others within the disability community, especially those with sensory impairments. One disability rights expert stated, “Telehealth has been a big issue, especially [in the context of] disability and low-income [status]. Who has access and what communication access is built into these systems?” They continued by explaining that most medical providers use their own private platform, most of which do not allow for a third screen. This setup effectively eliminates the ability for a deaf or hard-of-hearing person to use an interpreter, which unless the medical provider happens to know sign language, renders them unable to take part in telehealth appointments. Videobased telehealth services also carry similar limitations for others with vision-related disabilities, as well as some with intellectual disabilities.

•     Decisions informed by algorithms: Algorithms can directly

[]“The bias arises because the algorithm predicts health care costs rather than illness, but unequal access to care means that we spend less money caring for Black patients than for white patients.”

influence decisions made by medical providers and other actors within the healthcare system, oftentimes without patients even being aware. For example, many hospitals and healthcare providers rely on databases that attempt to measure a patient’s risk level in regard to prescribing controlled substances, namely opioid pain medications. Data is collected from hospitals, pharmacies and other providers within the healthcare system, resulting in the equivalence of a credit score assigned to a patient, with the intent to flag harmful behaviors such as “doctor shopping” or other indicators of prescription abuse. This can result in negative and disparate impacts on individuals with disabilities, particularly those with conditions requiring ongoing pain management.

Bias has also been detected in other healthcare risk-prediction algorithms. For example, a 2021 study examined one of the most prevalent health risk-prediction tools – an algorithm used nationwide and applied to an estimated 200 million people in the U.S. each year – and found it improperly assessed health needs for some marginalized individuals. This particular algorithmic tool aims to flag for hospitals and insurance companies patients who need high-risk care management with the hope that by doing so, they can reduce costs and preemptively prevent more serious and costly medical interventions. To determine which patients should qualify for this high-risk care, the algorithm used previous health spending as a proxy for medical needs. However, the study revealed that this was a faulty metric. White patients were found to have higher medical expenses related to preventative care, while Black patients more often had lower medical expenses due to several factors, from fewer accessible medical interventions to distrust in the overall healthcare system. Black patients had substantially greater health care needs than white patients who were assigned to the same levels of risk. “The authors estimated that this racial bias reduces the number of Black patients identified for extra care by more than half,” according to an abstract published in Science. “The bias arises because the algorithm predicts health care costs rather than illness, but

unequal access to care means that we spend less money caring for Black patients than for white patients,” the study’s authors concluded. “Thus, despite health care cost appearing to be an effective proxy for health by some measures of predictive accuracy, large racial biases arise.”

Although this particular study focused on racial discrimination – which is not mutually exclusive with disability status – it is reasonable to suggest that people with disabilities may also be similarly impacted by lack of transportation access, strain on the doctor-patient relationship, and distrust in the healthcare system. These impacts may act as proxies that inaccurately measure disabled people’s health risks, given the healthcare services they utilize – like the Black patients in this study – may likely differ from those without disabilities. And as a result, fail to be properly identified or classified by healthcare algorithms intended to improve care, because they are ultimately designed with white, non-disabled patients as the norm.

• Lack of data transparency: Another source of concern for some in the disability rights community is the lack of transparency regarding health-related data, as well as the lack of information and regulation surrounding large-scale databases that store individual patient data. As illustrated by the opioid and health needs risk assessment tools listed above, the data that underlie these systems directly inform decisions at various points in the healthcare system, which has resulted in concern within the disability justice space considering the potential for disparate negative impacts on disabled individuals who must interact with healthcare providers and systems on an intensive and frequent basis due to their disability needs or medical condition(s).

Health data – which refers to data collected and used for healthrelated purposes – is not regulated by any nationwide privacy framework. Although HIPAA has governed the availability and usage of some health-related information obtained by medical providers and insurance companies, there is a substantial contingency of health data, largely fueled by advancements in technology, that falls outside of the scope of HIPAA protections. For example, data collected from wearable devices, cell phones and other “smart” devices. The applications on these devices track enormous amounts of information regarding user’s mental and physical health, spanning from daily eating and exercise habits to highly personal information regarding menstrual and otherwise reproductive-based insights.

Despite various levels of awareness among consumers and disability rights professionals that this data – which prior to the advent of “smart” technology was largely protected by HIPAA and other privacy laws, but is now largely unregulated – is collected in databases accessible to some private and public sector bodies, the way in which this data is used, shared, and otherwise utilized remains largely unclear. And more broadly, because these algorithms are used by private healthcare providers, even the limited transparency and redress procedures that exist with public sector systems are not necessarily available to provide accountability.

Many describe these databases as opaque and due to this general lack of available information in regard to potential for disability harms and bias, the concerns shared by disability rights professionals interviewed for this report regarding health data and its corresponding usage were somewhat speculative in nature and serves as an opportunity for additional exploration and research.

Example Opportunities

•     In 2019, the AI Now Institute at New York University Center (NYU), the NYU Center for Disability Studies, and Microsoft held a convening: This convening was among disabilitycentered scholars and researchers, AI developers and other computer science and human-centered design professionals to explore the intersection between disability, bias, and AI. This event, and a corresponding research report, identified areas where additional AI bias research and opportunities for intervention are needed, including in healthcare.

•     A 2017 book by Dr. Khiara M. Bridges: This book, cited by at least one disability rights expert interviewed for this report, focuses on violations in medical privacy rights among people forced to interact with the state when accessing health services, including those on Medicare and other forms of public assistance due to disability status. Many of these individuals, the majority of whom are low-income and disproportionately of color and/ or disabled, are subjected to routine privacy violations and lack of the regulatory oversight that those outside of public health system interaction are generally protected and served by.

I. Emerging Tech

Issue Overview

Emerging technologies have created greater opportunities for independence for disabled people, as well as more channels and methods of communication. It is vital that new technological tools are designed and regulated through a truly inclusive technology justice lens, with the disability community’s active participation. This approach is necessary so this “progress” does not contribute to the harms highlighted throughout this report – like breaches of data privacy, targeted harassment, and over-surveillance – but rather contributes to a more inclusive and just world.

One example of these developments is automated captioning, which has significantly increased accessibility to all types of programming. However, the automation used in these technologies is imperfect and can perpetuate continued inequity. Advocates also expressed concern that some individuals also wrongly deem this emerging technology as a panacea for any/all accessibility needs, reducing momentum for more effective solutions. “It happens all the time – I request interpreters, and they say, ‘We will do automated captions,’” one disability leader explained. “You need to make sure that it is the right sound quality, the right voice . . . so in most situations, it is actually not highly accurate.” Another disability leader raised the potential surveillance and discrimination harms automated captioning could exacerbate, noting, “If the algorithm picks up that this person has an accent or an impediment and then profiles them, what do we do?”

One disability advocate explained the tension between how helpful this technology can be and the dangers of people seeing it as a cure all to any accessibility or other concerns, “So we are working on convincing folks that just because the technology is there doesn’t mean it’s the right fit or the real, full access.” For example, many of these emerging technologies are designed to be speechrecognition based, which creates barriers to access for the Deaf community.

   I. Emerging Tech

Automated captioning provides just one example of how new technology has the potential to reshape the landscape for the good yet still requires significant shepherding to ensure it fulfills that promise. The opportunity to shape emerging technology and policy that deeply impacts people with disabilities through the lens of technology justice is as strikingly salient and potentially as crucial as working on well-established technology problems.

Sub-issues

•     Autonomous vehicles: Vehicles that can drive themselves could be liberating for members of the disability community, but advocates also warned of potential surveillance and privacy implications around this relatively unregulated industry as companies collect highly contextual data about passenger’s habits, routines, and movements. If people with disabilities rely heavily on autonomous vehicles, they will be disproportionately impacted by the rules governing them. Early studies also show that, due to algorithmic bias, autonomous vehicles sometimes do not detect people in a wheelchair or if they are Black – creating serious safety risks.

•     Virtual reality (VR): VR technology is meant to simulate a user’s physical presence in a virtual environment. The user should be able to look around, move in, and interact with this virtual environment, just as one would in daily life. Yet, experts are concerned that the deployment and governance of these technologies are not taking into account the lived experience of people with disabilities. Said one expert of the needs to develop content moderation and other rules around VR, “If you are building norms and expectations . . . we are talking about bullying in VR spaces, and how you moderate that. My point is if you are going to start baking these norms [into VR] you need more perspectives, one of those areas where having a variety of perspectives is important is including disability rights advocates.”

[]“It happens all the time – I request interpreters, and they say, ‘We will do automated captions,’” one disability leader explained. “You need to make sure that it is the right sound quality, the right voice . . . so in most situations, it is actually not highly accurate.”

•     Automated captioning/automated speech recognition technology (ASR): Advocates stressed the importance of access to free automated captioning and speech recognition tools, but that because of the imperfect nature of this technology it has censored certain types of speech and provided incorrect information around medical appointments, legal meetings, and COVID information sharing. One disability rights advocate and policy expert described the danger around ASR: “Where it is information that is critical to our life, it needs to be higher quality.” “I was watching the inauguration and Amanda Gorman gave her poem, and you could compare across channels the quality of captioning,” a disability leader shared, highlighting a situation where this problem played out on a national stage. “Some were able to give a live caption, but other channels that were using AI said ‘bruised butt hole,’ [instead of ‘bruised, but whole’] which is completely inappropriate and is what showed up on people’s screens. A clear, egregious example, but what is happening all the time.” An expert also highlighted how some automated captioning technology will not render swear words, preventing disabled people from participating in a conversation on a truly equal basis.

Example Opportunities

• Bolster support for intersectional disability rights and justice groups working on these issues: Disability rights leaders called for advocacy efforts to ensure surveillance concerns are baked into the design perspectives of automakers. There is an opportunity to bolster support for ongoing work by groups like We Will Ride and the Transportation Equity Caucus that call for equitable transportation policy and ensuring that automakers make accessible autonomous vehicles.

Centering Disability in Technology Policy: Issue Landscape and Potential Opportunities for Action

Challenges, Needs, and Opportunities

As technology becomes increasingly centered in the daily functions of our lives, it is important that individuals with disabilities – who may interact with tech systems differently and/or may be at disparate risk of harm – are considered when these tech systems are developed and implemented. Given the myriad of ways tech often creates harm and disparate negative outcomes for disabled people, this section explores two key questions:

•     What are the barriers to work at the intersection of technology and disability?

•     What do the individuals and organizations leading in this domain need to support their work, including seizing on opportunities to make it even more effective?

Although many disability rights organizers, advocates and other professionals engage on many tech issues affecting the disabled community, our interviews surfaced a need for greater collaboration in order to make technology systems, tools, and policies more inclusive. Without minimizing the existing work disability justice professionals and advocates have undertaken in the technology space, interviewees suggested significant challenges remain on both the tech and disability rights side. One civil rights leader also underscored the challenge and opportunity inherent throughout this body of work. “Whatever philanthropy does, it has to think about the ways in which the entire philanthropy system underpays marginalized communities for the benefit of the entire nation,” this individual said. This leader highlighted “the strain that it puts on communities and folks who do not come from a place where they can afford to be paid as little as they are.”

American Association of People with Disabilities   |   Center for Democracy & Technology

[]“Technology has so much potential, but if technology doesn’t address accessibility and disability, it also has the potential to recreate or exacerbate existing barriers, and even create new barriers.”

Through a series of qualitative interviews with technology experts, advocates, researchers, and directly impacted individuals and professionals in the disability rights field, several gaps and challenges were identified that both tech and disability spaces face in establishing justice in technology. These challenges are described below, followed by a wide variety of needs and potential opportunities organizations looking to invest in work at the intersection of disability and technology could support.

I. Challenges

These challenges include:

1. Addressing accessibility is necessary, but not sufficient, to solve challenges at the intersection of technology and disability

A series of persistent challenges that many stakeholders identified relate to accessibility. While accessibility in the context of disability historically refers to creating physical spaces that are accessible to everyone, access to digital technology is emerging as a new frontier in the fight for civil rights. As one disability expert stated: “Technology has so much potential, but if technology doesn’t address accessibility and disability, it also has the potential to recreate or exacerbate existing barriers, and even create new barriers.” Interviewees argued that work on technology and disability justice must often start with accessibility but cannot end there. Aspects of challenges related to accessibility included:

a.   Disabled people are excluded from work technology issues if accessibility is not addressed from the start: Interviewees suggested there is often an inherent tension in technology and disability work that can often result in a Catch-22 for many in the disability community: in order to make tech more accessible, those most directly impacted must first be able to engage with tech system; but, if the technology isn’t accessible in the first

place, disabled people and disability rights organizations find it difficult or impossible to engage with it. Without basic accessibility concerns addressed by the technology sector first, some interviewees expressed that there is often little ability or incentive for disability groups to engage on other harms technology creates for their community. This inaccessibility also results in less external pressure on the technology sector to incorporate accessibility across platforms and systems as a function of their design. Progress has been made – including, for example, the enactment of the 21st Century Communications and Video Accessibility Act in 2010 – but significant additional work is needed to ensure people with disabilities are able to engage effectively with the development of technology.

b.   Disabled groups’ ongoing need to lead on accessibility work

can crowd out engagement on other priorities: Relatedly, several interviewees suggested that generally, disability organizations are the main stakeholders focused on accessibility and as a result, lack bandwidth to take on other technologyrelated issues. This disconnect has led some in the disability justice space to express the sentiment that “since no one else is creating accessibility in tech, we have to.” Some disability rights experts acknowledged that serving as the de facto leader on accessibility makes sense, given their expertise, but it can also limit the ability for disability groups and individuals to engage more broadly on other tech issue areas and develop tech expertise outside of accessibility. There is a need for technology justice groups and other allies to elevate and put resources behind the issue of digital accessibility. Amplification of this issue will be necessary both so this work does not just fall to a few disability groups and to create a pathway for disability groups to engage in other technology justice work. Until there is more support for this issue, one advocate said, “Still having to insist that accessibility needs to be present within a number of tech applications and tools . . . it becomes hard to engage in a next level conversation when you still can’t access the application in question in the first place.”

c.    Despite these challenges, the assumption that disability

and technology justice are only centered on accessibility is harmful: Interviewees suggested that while accessibility is a vital factor in creating the “even playing field” required to even begin addressing disparate harms, it is overly reductive to conclude that accessibility is at the core of the disability rights movement with respect to technology. In interviews, many expressed resistance to the notion that disabled communities and their fight for civil rights in technology be defined solely or even primarily by accessibility. As such, this report acknowledges the crucial need for accessible forms of tech, while also illustrating the various ways in which tech must be more inclusive beyond just reasons of accessibility, as well as other disparate outcomes and harms experienced by disabled people.

2. Needs and nature of disability member organizations

Several interviewees also identified that disability-centered organizations and member groups must often balance the immediate and most pressing needs of their diverse members; and as a result, technology is not often prioritized. “One of the tricky balances that you have as a member organization or a disability organization is if you have members who are reaching out saying, ‘I need X and Y,’ you will prioritize housing, food security, and accessible transportation,” said one leader working on disability issues. “I would be shocked if one of the major disability organizations had people reaching out saying I am worried Google is tracking me.” Another disability advocate argued that “disability rights organizations miss the vast majority of disabled people, who are the most likely to have been homeless, incarcerated, incompetent-presumed, or institutionalized,” making it less likely issues affecting these populations are prioritized generally.

3. Misconception of monolithic disability identity leading to misunderstanding of technology harms and remedies

Many interviewees emphasized the disability community is not a monolith, despite often being perceived as such. These experts instead highlighted a wide array of disability identities and emphasized that many individuals with a disability may not even consider themselves disabled.

The misconceptions that surround what it means to have a disability are a challenge to bridging this gap between technology and disability justice as well as doing truly inclusive work to the benefit of all. Interviewees explained that sometimes a “win” for some in the disability sphere can constitute a setback for others, given that the vast diversity amongst individuals warrants equally diverse and nuanced solutions, rather than a one-size-fits-all approach. For example, one leader of a disability organization noted that ridesharing systems were a convenient and more affordable transportation option for deaf and blind users, but undermined significant progress in the fight for wheelchair accessible transportation.

Even attempts to limit and mitigate potential bias built into AI can have unintended consequences that actually further disability bias themselves. For example, “bias audits” intended to catch forms of potential harm for marginalized communities in automated decision-making tools may, in only addressing racial discrimination, ignore or exacerbate discrimination against people with disabilities. The 2019 AI Now report highlighted research that found sheer mentions of disability led a machine learning text moderation model to classify content as “more toxic.” “Systems used to determine bias may work for bounded identity groups,” said one disability expert, but cautioned that disability status was not well-defined in a rigid data context. For example, if a tool is declared bias-free based only on metrics related to race, it will allow the tool to continue perpetuating disability discrimination unchecked. It might even lift the burden of accountability from those using the AI since they

can claim to have conducted a bias audit. One disability rights leader explained, “Companies are being approved and certified as not having bias, but that doesn’t hold for disability at all. That is a pattern that happens quite frequently.”

4. Limited representation of individuals with disabilities

Engagement with disability rights groups and others may not necessarily include hearing directly from people with disabilities and gaining from their firsthand, lived experience of the ways in which tech has not been accessible or benefitted them. Several experts highlighted representation more broadly, including the need for a greater number of people with disabilities holding leadership and otherwise positions of power, both within disability justice organizations and ideally, also within tech spaces. As one technology justice advocate stated: “Are we actually talking to the people that are impacted by this and finding a nuanced approach that accounts for those practical needs?” “As far as I can tell, there are [very few people] who are openly disabled working at the nexus of disability and tech from a civil rights perspective,” said a disabled advocate. A priority should be “deliberately inviting to the table and centering in conversations disabled people from multiply marginalized communities who are least likely to be invited,” this individual argued. Given stigmatization of disability in many fields, ensuring individuals feel safe about being open about their disability status may also be a key need.

Several disability rights leaders recognized the tension of consultation fatigue for many in the disability community who currently engage in cross-over field work and are called upon frequently. Citing this concern, many expressed the importance of balancing greater representation and hiring more disabled people with the expectation that it is not these individuals’ jobs to fix or heal the need for greater accessibility and disability-centered solutions within tech. 

5. Shallow pool of professionals with experience in both disability-focused accessibility and rights, as well as tech-specific expertise

What further complicates this is that just as tech systems are built with inherent bias baked in because of a lack of representation and awareness among those who construct the platforms we use every day, similarly, the underrepresentation of disabled people among many disability rights organizations’ leadership means that even if the tech and disability rights sectors achieve greater cross-collaboration, it doesn’t necessarily mean that the firsthand, lived experiences by those directly impacted by inaccessible and otherwise biased tech systems, will be centered. And without centering these voices and perspectives, the tech sector will potentially further incorporate additional bias as a result of engagement with disability rights communities that themselves are not directly informed by and centered on disabled people and their inherent, lived expertise.

Additionally many across both tech and disability rights identified the widespread lack of disability experts embedded into tech companies in paid positions. The limited pool of professionals with both tech experience and a disability rights-orientation was widely acknowledged by members of the disability rights community, many of whom identified the need for pipelines, fellowships and funding for other opportunities to encourage disability experts in tech positions, one of whom stated a desire for “money for fellowship programs that prioritize disabled people [and disability experts] and embed programs within tech.” Currently disability groups are working with allies across the technology industry and academia to improve accessibility. Teach Access is an initiative that aims to elevate accessibility in higher education and across technology disciplines like engineering, research, and design. XR Access is an initiative to improve accessibility in virtual spaces and integrate inclusive design processes. The Web Accessibility Initiative brings people with diverse disabilities into dialogue with the developers of digital technology standards. These initiatives provide examples of how additional collaborations could be structured to center the perspectives and experience of disabled people in technology design and policy.

[]“From top to bottom, tip to toes, we are not doing good enough work to make sure that legislation or what we are doing in comms is accessible and incorporating disability.”

6. Lack of general and/or specific knowledge of how technology can harm people with disabilities

As previously discussed in the report, this lack of basic knowledge, in part reflects the lack of diversity and representation within the tech field. But interviews conducted for this report revealed something more nuanced: it is not only that tech is comprised primarily of white men and/or individuals who may be less aware of disability justice and other civil rights causes, but also that there is a true lack of opportunity for those in tech to engage disability rights experts in meaningful and organic ways due to a lack of knowledge of these harms. One technology justice advocate explained this need for and lack of basic knowledge in the field, declaring, “I think identifying where the issues are, where there is a nexus with disability” is valuable. The individual continued this education could include saying, “Here are practices that you are working on that have a disparate impact on individuals with disabilities” or “These are the ways you need to think about the disparate impact on individuals with disabilities.” While increasing attention has been paid in recent years to algorithmic bias, and more specifically risk assessments, the harm inherent for people with disabilities has often not translated into a greater awareness and sense of accountability on the technology side. Said another expert, “From top to bottom, tip to toes, we are not doing good enough work to make sure that legislation or what we are doing in comms is accessible and incorporating disability.”

7. Few formal and informal bridges between technology and disability advocates

Many interviewees highlighted a lack of connective tissue and overlap between the tech and disability justice world. Several experts interviewed identified a significant need for opportunities that facilitate relationship-building. One tech expert expressed the need for tech-oriented groups to engage, learn and listen to disability communities, stating that this type of interaction with disability rights groups is “how we actually change.” But illustrating the challenges creating these opportunities, the

individual continued: “I don’t have a good sense of what the organizations are that we could be partnering with. To what extent do these organizations exist . . . and how can we build this shared understanding and analysis?”

8. Deeper-seated divisions between some civil rights organizations and disability rights/justice organizations

Another challenge identified by a number of interviewees in the disability rights space are varying degrees of historical tension and distrust between those in disability-centered spaces and other civil rights groups. Today, civil rights groups range from modern-day movements such as Black Lives Matter, which represents a new era and younger generation, as well as historically prominent and highly visible groups, often referred to as “legacy groups” that still hold a powerful and prominent space within civil rights circles. Many of these legacy organizations served leading roles in some of the most important civil rights wins and reforms in U.S. history, such as the Voting Rights Act and other landmark wins that changed the course of American history.

However, some interviewees argued that historically, disability rights were not central to many of these civil rights movements, nor are disability-centered issues at the core of these groups’ efforts today. These longer-standing divisions can serve as a practical barrier to further work at the intersection of technology, disability, civil rights, and justice. This gap has led some in disability justice groups to feel there are limited opportunities for collaboration that elevates their disability-focused issue areas and objectives, and therefore these groups may be less incentivized to engage. Additionally, the nature of disability groups has changed over time, according to a disability rights leader, who expressed that, as compared to the 1980’s and 1990’s with the passage of the ADA, many groups are smaller in size and may specialize in specific issue areas within disability justice. This may also contribute to challenges in bridging the gap between civil and disability rights groups.

II. Needs and Opportunities

Interviewees identified a wide set of needs and opportunities, including:

1. Resource commitment within technology justice organizations to true inclusion

Incorporating an initial plan for resource commitment from technology justice organizations to include the disability perspective in project design and scope will be imperative. For example, one interviewee noted how Legal Aid organizations may act as a model for this work in how they provide resources early on to individuals who can help them identify and challenge unjust systems. On the other hand, one technology policy leader noted how their organization had recently created a website to help individuals access an important technology subsidy, but they did not have the resources to do an accessibility audit of this website. Broadly, several interviewees emphasized the need to orient themselves more fully toward both basic accessibility practices and more deeprooted inclusion of disabled perspectives in their work. “We don’t need a new suite of tools; we need a new suite of mental facilities. When I [facilitate], we are not using those tools,” one advocate said. “How are we making it so folks in disability justice can be a part of a coalition, for us to make it a priority?” This individual emphasized there was a fundamental need to rethink facilitation and engagement practices to be inclusive of disabled people, rather than just adding technical tools and considering the need met.

2. Funding for paid fellowships and other longterm opportunities for people with disabilities and disability rights experts to contribute directly to technology policy work

Several technology justice advocates expressed the desire for their organizations to support a position, grounded in experience, dedicated to addressing disability throughout their portfolio of work. “You can become experts, but really by finding ways for folks [with disabilities] to help audit us [technology organizations] and find tools and resources that we need,” said one interviewee. “It would be great if every major public interest organization had a fellow . . . designed to bring this intentional thinking and grounding to the work,” said another technology leader. “It is really important having capacity built into the organization’s structure – there is no substitute.”

Many stressed the need for long-term oversight from the disability perspective on technology advocacy, especially in regard to advocating for regulation or drafting legislation. One disabled advocate said, “Who will begin providing actual resources to disabled people at all career levels to develop skills necessary to contribute at a leading level? I want to see reallocation of resources.”

While there was near-universal agreement on the importance of funding the work of disability experts (particularly disabled individuals), many interviewees nonetheless warned of the risks associated with relying on the placement of a few disability rights experts within public interest organizations and companies as the solution to bridging this divide or supporting true inclusion. While this representation is important, expectations for those who do cross-sector work must be managed to avoid burnout and consultation fatigue, interviewees warned, also noting that the panoply of disability experiences makes it difficult for a small number of individuals to truly represent all disabled people.

3. Substantial investment in paid listening sessions

and focus groups to learn from the disability community

Many experts within both technology and disability justice supported the creation of focus groups and other spaces in which individuals with disabilities can share their experiences in regards to technology use. These paid sessions would ideally consist of

[]“People closest to the problem have the solutions. It’s always better to have a conversation with someone who is directly impacted.”

disabled people not coming from a professional disability rights advocacy perspective, but rather consist of non-experts who are representative of groups the technology industry wishes to better address in expanding accessibility into programs and systems. This need for opportunities to expose tech professionals to candid stories and perspectives was suggested by several experts, illustrating that many within tech are simply unaware of or lack education on the barriers that individuals with disabilities face in accessing and using various forms of technology. Hearing directly from a diverse group of individuals sharing their perspectives, is likely an opportunity that most professionals outside of the disability community simply wouldn’t have, if not for structures in place like focus groups and listening sessions. One technology advocate noted the importance of including a diversity of disabled individuals affected by technology harms, “Efforts need to be in compensating people from formal and informal orgs that represent disability people at margins.”

Interviewees emphasized the need for these listening sessions to be paid opportunities, particularly given the barriers to employment many disabled people face. By providing paid opportunities, disabled participants and the technology and disability professionals these sessions serve to educate and inform. Multiple experts in the disability rights space indicated the scarcity of – but great need for – such opportunities, describing alternative efforts by tech to benefit from the perspectives of disabled people through unpaid, biased, tokenizing, or otherwise one-sided ways that overly center the needs of technology companies or advocates. One leader elaborated that people with disabilities are “often expected to give time, labor and emotional energy without compensation, while our community is disproportionately unemployed and impoverished.” They described this situation as “not an environment that incentivizes participation.” In contrast, a technology policy advocate offered an example where such a listening effort would be beneficial: in an effort to improve the Medicaid Long Term Services & Supports program, this expert suggested efforts were needed on listening and learning from disabled users, asking “What is it like experientially, what was missing, what was wrong with it?”

Others expressed a tendency to overlook the value of disabled perspectives and the experiences of this population altogether. Illustrating the benefits the technology sector – and related public interest community – can gain simply by providing paid opportunities that seek the feedback and wisdom of people with disabilities, one disability justice leader stated, “People closest to the problem have the solutions. It’s always better to have a conversation with someone who is directly impacted.” “We’ve learned that none of us is safe until all are. [We should be] beginning at the margins, designing at the margins,” another disability expert argued. “Disability is a horizontal condition that everyone will experience.”

4. Establish opportunities that promote solidarity and

relationship-building across the disability and tech communities

Most interviewees emphasized a need to build bridges between these communities. This could include convenings and meetings whose purpose is to create space and time for individuals and groups to connect, and in doing so, build trust and crosscommunity relationships. As one expert said, “You cannot do work with people who you don’t have relationships with. The first strategy is to get to know one another. [There has to be] consistency and respect; that doesn’t come quickly.” In exploring opportunities to create collaboration, interviewees emphasized priorities including:

a.   Building greater trust and respect: To build spaces that promote respect and trust, it is vital that both disability rights and tech are equally and fully represented. One interviewee described this as the need for “space and time to be in solidarity and meaningful relationship with the disability community, making sure that it doesn’t overly center tech.” Although there is a clear need for meetings that facilitate meaningful relationship-building across tech and disability rights, these spaces can be hard to come by. One disability rights expert noted: “There hasn’t been a lot of connective tissue between advocates in the disability rights space and advocates in the technology policy space; there is a lot of opportunity whether it’s funders or organizations that set out to create more spaces for these [tech and disability-focused] conversations at scale and in a facilitated and constructive setting.”

[]“You cannot do work with people who you don’t have relationships with. The first strategy is to get to know one another.”

Some in the disability community shared that opportunities and convenings may also serve to help clarify misconceptions or misunderstandings others may have about disability groups, which left unaddressed, can limit collaboration. “Many disability groups are largely focused on [lived, personal] experience; people get overwhelmed [hearing this array of vast and different experiences] and think the community isn’t organized,” a disability rights expert expressed. “In reality, all of these communities will have different experiences. [Tech] partners need to understand that dynamic and to see how the community is organized.” This individual also then shared a question tech groups can ask themselves when attempting to gain better understanding of disability rights groups: “Are we actually talking to the people who are working on this and [directly] impacted and finding a nuanced approach that accounts for those practical needs?”

b.   Identifying consensus goals: Many expressed the need to establish

shared goals when engaging across tech and disability rights. One challenge to this is that organizations work on a variety of topics – within the overarching disability and civil rights umbrella – and are not necessarily focused on the same aspects of or issues pertaining to disability rights. This divergence can limit the ability to galvanize and form widespread support and organized efforts. One advocate expressed the need for more groups across a wide array of communities to engage with disability-centered issues in order to bring more attention. This work, the advocate argued, is particularly necessary because across these groups, there is an incredible amount of expertise and skill that can bolster unified efforts. They summarized this desire and the inherent challenges in accomplishing this as: “All I want is for us to think of these issues outside of silos.” This individual emphasized reaching these goals would be an endeavor that should be focused on the long term (“We need to plan for 2024”) and “beginning through listening and

embedding deeply in the movement before saying anything about tech.”

c.    Driving engagement beyond the public interest community: While many in both the tech sector and disability rights space expressed the need for a greater number of paid fellowships specifically designed to employ disabled people and individuals

with disability rights expertise directly within tech companies, they emphasize a need for tech companies to find ways to incorporate people with disabilities into existing programs and diversity programs. One disability leader said, for example, that disability is frequently excluded from diversity initiatives and conversations within tech, as evidenced by the frequent tendency of tech companies to hire nondisabled people to lead disability initiatives. For disability rights to begin to be integrated into tech in a meaningful way, said one disability rights advocate, it “has to

start with the tech companies understanding the value of disability community engagement.”

d.   Supporting an executive cohort: Several interviewees suggested that a convening strategy focused on building bridges between executive directors in disability and technology organizations may be a beneficial starting point or a supplement to other bridge-building efforts. “There are opportunities for the funder community to support spaces for organizational leaders to intentionally think through organizational issues,” said one technology policy leader. “It could be a lot more knowledge and experience sharing and ideation around building capacity into all of our organizations across racial justice, gender, and disability.”

5. Support greater inclusion for marginalized voices and a commitment to intersectionality

The voices, perspectives and expertise of those with multiple marginalized identities – meaning those who in addition to being disabled also belong to other disadvantaged and historically oppressed groups – are often underrepresented, undervalued, or excluded altogether from meaningful spaces in which disability rights leaders and decision-makers determine what inclusive and disability-centered tech should look like. Several interviewees noted this effect of multiple marginalization and the underrepresentation faced by those belonging to more than one structurally disadvantaged group, is present across all facets of our society, economy and culture and replicates in many public interest organizations.

A disability rights leader declared, “It’s 2021, and there are still barely any BIPOC people working in disability rights; until that changes [efforts to advance disability-related issues] still won’t cover all that is harming people.” Interviewees suggested efforts to address these challenges could focus on approaches that:

a.   Strengthen understanding of intersectionality: Several

disability rights experts argued that both disability rights groups, as well those within the broader civil rights community, generally do not approach their work in an intersectionality-mindful way, despite the inherent overlap between the two. Because disabilities are present across all demographic groups, every civil rights community – by definition – has members with disabilities. The inverse is true for disability rights communities. Yet this overlap is not always evident or reflected in these groups’ strategies and efforts, in part due to a lack of education, some interviewees argued.

Building in this intersectional approach will require greater education on why disability is relevant to all civil rights communities and vice versa, and importantly, on how by incorporating these intersections into their work, all groups can bolster their individual and collective efforts. A disability rights advocate said, “It will take showing, for example, the Latinx community what these tech harms look like for disabled members of their community. The Latinx community has engaged a lot in special education; [but] you can’t do education advocacy without having a strong emphasis on kids with [special education status].” Additionally, some in the disability rights space expressed the need for events and meetings designed with an intersectional lens that promote learning and greater awareness for both the tech sector and disability rights groups, for example a large-scale summit centering the history of technology sector harms towards Black and brown people, in addition to disabled Black and brown people.

b.   Deliberately create spaces in which marginalized voices are centered and empowered: Due to the nature of multiple marginalization and the compounding disadvantage it creates, BIPOC and otherwise marginalized members within the disability community arguably experience the greatest barriers and harms brought on by tech, and yet they have the least opportunity to have these perspectives heard by those with power and influence, let alone have their needs reflected by these leaders’ efforts in engaging tech, several interviewees noted.

A disability rights advocate illustrated how this lack of representation results in disparate tech harms for those most marginalized, explaining that most disability rights organizations are overwhelmingly “white, male, cisgender, [and] heterosexual.” The result, they argued, is that individuals most likely to have been homeless, incarcerated, institutionalized, reliant on public assistance, and otherwise experiencing severely disadvantaged outcomes, are disparately impacted by tech harms in the form of law enforcement surveillance and inaccessible public benefits platforms, for example. And yet these experiences – and those who live them – are not typically elevated or even present in decision-making and other meaningful spaces that serve to make tech more inclusive.

Several disability rights professionals expressed that unless the individuals most marginalized within the disability community are actively sought out in an intentional, targeted manner to ensure they have an equal seat at the table, their voices will simply go unheard. One expert emphasized this point, saying, “Free registration for conferences is not the answer; [we] need to sit down and have serious conversations about the harm done to these people. Until we have some serious, honest conversations about what is happening in the disability rights community, none of this will change.” There is a need for funding and resources that incentivize the inclusion of Black, brown and otherwise disadvantaged people within the disabled community at events and meetings where policy development and strategic decisions are made, including funding for the capacity to participate in these endeavors.

c.    Create an inclusive design coalition: Disability leaders

highlighted the opportunity to invest time and resources in advocating for inclusive design, a methodology in which the designer includes and learns from people with the full range of

4 The terms inclusive and universal design are sometimes used interchangeably, but have different definitions. We include the term universal design as used in the quote, but choose to use the phrase inclusive design to capture the perceived meaning of the quoted speaker.

human diversity and perspectives. This endeavor would level the playing field for people with disabilities to enter more fully into conversations around data privacy and protections. One leader said, “We need a cross-disability/cross-civil-rights coalition to even begin the right kind of dialogue that would lead to universal design⁴ for all, not just for disability but, race, gender, background, and religion.”

d. Promote stronger collaboration among disability rights

groups and the greater civil rights community: When discussing why this divide between disability-focused advocates and other stakeholders and parties within broader civil rights groups, collectives and coalitions exist, many identified intersectional marginalization as occurring both in the greater society, economy and culture, and therefore, also present in civil and disability rights circles.

Similarly, some – but not all – interviewed suggested a historic tendency for civil rights movements to de-center or neglect disability issues, in comparison to other more prominent civil rights issues pertaining to race, sex/gender, LGBTQ+ status and other areas that are at the forefront. Correspondingly, the lack of Black and brown people within disability organizations, and especially in prominent leadership positions, also contributes to civil rights groups feeling less inclined to promote greater partnership and collaboration, some interviewees argued. These individuals suggested an importance of focusing on justice more broadly.

Given these factors that some interviewees said limit the opportunity to meaningfully engage in cross-collaboration, some disability rights professionals expressed the need for greater philanthropic funding and other opportunities to strengthen organizational bandwidth and ability to take part in broader civil rights events. Others suggested fellowship opportunities within civil rights organizations focused on disability, as a means to increase awareness within these groups, as well as allow for a sense of greater representation of disability issues by the disability community. And lastly, many expressed the need for co-sponsored and other partner-based events in which members from both sides can establish the relationship-building and trust necessary for cross-group collaboration and shared efforts.

6. Develop plain language and otherwise easily accessible resources for a broad audience

Some interviewees argued that given the ways in which many disabled people, and particularly those with multiple marginalized identities, have been categorically excluded from educational and employment opportunities, it is also important to create educational materials, and written texts otherwise intended to inform others on tech and disability issues that are accessible and easily understood. An example shared by a disability justice leader is languagedecoding glossaries to accompany research and advocacy materials, the purpose of which are to encourage the use of accessible language among those utilizing these groups’ research and other communications materials. The push for accessible and plainly written materials is in part to ensure that the population disability rights groups aim to serve – those with disabilities themselves – can actually access the information relevant to disability justice and their lives. Additionally, there is an opportunity to foster dialogue with the technology justice research community and the advocacy community to help translate academic papers into information that is actionable for local disability advocates.

The need for plain-language, public-facing documents on technology and disability issues was illustrated by one expert who pointed to variations in literacy frequently observed within the deaf and hard-of-hearing community. According to this leader, vast diversity across educational programs and experiences among hearing-impaired children and adults, mean that some within the deaf community may not have had the same exposure to, or emphasis placed on, written language skills and written texts, as compared to many in the hearing world. This example underscores the need for plain-language documents and any other barriers that may exist based on the complexity of experiences amongst disabled people which may impact their ability to consume written materials intended to educate and promote disability rights, particularly as they relate to complicated technical issues. “There is a really steep learning curve,” on tech issues, said a disabled advocate. “I think that the more that all our orgs can offer plain language explainers, the better off we will be. It will literally benefit anyone

[]“I think that the more that all our orgs can offer plain language explainers, the better off we will be. It will literally benefit anyone who tech might affect and who want to understand policies.”

who tech might affect and who want to understand policies.” Another advocate noted of an effective advocacy campaign led by disabled individuals, “When they talk about technology, they relate it to the core needs around housing and transportation, and it’s a mechanism for advocating for material needs.”

7. Fund equitably across civil rights organizations, including those focused on disability

Among the experts and professionals interviewed in both the tech sector and the disability rights community, there was a near-unanimous identification of an overall need for expanded grantmaking and other funding opportunities that strengthen the ability of disabled individuals and organizations advancing disability rights and justice to engage on technology issues. But in addition to a need for more funding across the board, some expressed concerns that what limited funding currently does exist is not being distributed in an equitable manner that allows for disabled and disability rights-focused individuals or groups to take part.

One interviewee at a tech-focused organization argued that resources currently tend to go to individuals or organizations that are already engaged in tech, as opposed to disability rights groups themselves. This interviewee, as others did, argued the majority of these funding opportunities and resources should be directed toward the disability rights community, to build out their own work and break into the tech world.

Lastly, some of the disability rights leaders interviewed for this report identified a lack of equitable funding as a barrier in disability rights groups and civil rights organizations working more collaboratively. As previously discussed in this report, there are tensions that some report between disability and civil rights spaces, which can ultimately impact the inclusion of disability within civil rights groups’ partnerships in working on tech. One of these tensions, according to a disability rights leader, are perceived funding disparities between disability groups and other types

of civil rights organizations. And as a result, the leader argued, disability rights and disability justice groups “tend to be not as well-resourced, have less bandwidth [and therefore] are not always present, but that doesn’t mean there isn’t a disability impact.”

8. Build pipelines and partnerships to encourage disability inclusion in the tech sector

Interviewees highlighted additional, larger-scale opportunities to build pipelines that better bring perspectives on technology issues with a disability lens to bear. These potential needs included:

a.   Support public-private partnerships: This is one way in which

local and state agencies, in alignment with philanthropy or other private entities can support greater disability rights inclusion within tech systems. This suggestion put forth by a disability rights nonprofit director refers to the creation of a public-private partnership that would engage members of the disability community and disability rights groups as thought partners to develop a plan alongside philanthropy for a diversity pipeline within the tech sector. The goal being that this pipeline would allow for input from disability experts – which includes disabled people who derive expertise from their lived experience – at the intersection of tech and systems such as housing, community transportation, and public benefits platforms.

b.   Develop partnerships with tech industry: Some interviewees

noted the opportune moment for collaboration with the private sector, as business leaders are asking for help and direction in regulating and auditing technology – especially AI systems. “Fortune 500 companies don’t even have the infrastructure to internally audit their AI. The crucial point is where disability justice and disability rights come together and say now is the time to invest in this,” one leader explained. “AI is a basic civil rights issue. We can win on this because the industry does not want to be on the hook for it.” Developing early partnerships with the private sector may be necessary to ensure disability inclusion in these AI systems in addition to broader efforts to regulate these tools.

[]“AI is a basic civil rights issue. We can win on this because the industry does not want to be on the hook for it.”

c.    Create an academic and professional pipeline for students, scholars, and designers: Alternatively, another idea put forth by a disability rights leader is to develop an academic pipeline, similar to those that other civil rights groups and universities have established to increase racial and ethnic diversity, as well as a greater number of women, within tech companies. One disability rights leader explained the need for real long-term investment and resources from academia and the private sector to include the disability community, “Elite institutions don’t have a strong record of recruiting or retaining disabled students or scholars. The pipeline of centering disabled people is really limited.” As a growing and new area of work, emerging tech could be an opportune area to focus on creating this initial pipeline of crossdisability and technology experts. The goal of this disabilityfocused design would also be to promote greater representation of disabled professionals in tech, through streamlining a process through which students, scholars, and designers with disabilities can work in tech positions rarely held by disabled people. (One opportunity may be collaboration with the Public Interest Technology University Network and its members). If established, this pipeline of tech experts with disabilities could also bolster the practice of inclusive design or co-design, in which technology design involves people with disabilities from the outset. Inclusive design is imperative to maintaining the principle of “nothing about us without us.” A pipeline of disabled designers and technology professionals will be critical in both preventing technology harms from the beginning and ensuring a technology policy or product adequately addresses the needs of disability populations.

9. Expand and support intersectional research opportunities

There are a variety of ways that investment into disability-centered research and funding opportunities for researchers, scholars and other relevant professionals with disabilities would benefit both tech and disability rights groups interested in bridging the gap between

these two worlds. A consistent theme among the tech professionals, as well as members of the disability justice community interviewed, was the need for greater education, awareness and understanding of how disabled people engage in tech, experience barriers and harms, as well as qualitative information in the form of stories and anecdotes to promote greater awareness. As one advocate declared, “There is always a need for more research about how different communities are using services, tech, and platforms. How and where and why we might be falling [short] and failing to meet the needs of communities.” Several other technology experts expressed the need for shared language, common terminology across disabled and non-disabled groups in tech, as well as a greater library of disabled tech user’s accounts of ways in which tech has been inaccessible, hard to use, or harmful as a result of their disability.

There is also a need for research funding that both allows for the establishment of a stronger empirical evidence base across a wide array of disabilities and advocates for alternate models of expertise and validity. Said one disability rights expert, “The gold standard for publishing is statistical significance and empirical evidence. You cannot reach that in terms of a disability. There never is a large enough ‘n’ [number of people/observations].” Therefore, the expert argued, it is nearly impossible to draw statistically significant inferences and research-backed conclusions about this population across a myriad of research areas.

Some interviewees highlighted this challenge as one way disability bias is perpetuated in technology work; the emphasis on empirical evidence – which is often difficult to draw in terms of disability beyond the most reductive versions – means that there are few scholars or research institutions incentivized to incorporate disabled populations and issues of disability justice into peer-reviewed articles in academic journals and otherwise credible publications focused on technology issues.

Targeted funding could allow for a greater collection of research designed with disability rights and disabled populations in mind, ultimately creating more opportunities for disability groups, advocates, and others committed to centering disability justice within tech to use research as a valuable tool across efforts.

Interviewees also proposed a wide array of potential policy, legal, issue, and strategic research projects, with a focus on topics such as:

a.   Applying the Americans with Disabilities Act, other federal disability rights laws, and related state-based laws: Many disability and technology policy experts alike highlighted the potentially powerful applications of federal disability law like the ADA, Rehabilitation Act of 1973, and the Communications and Video Accessibility Act (CVAA), to a wide variety of problematic tech issues. They argued the landmark ADA’s relatively lower standard of harm/evidence offered potential to advance longstanding priorities for stakeholders in the. “The ADA doesn’t require quite the same hurdles in many cases that other civil rights laws do,” said one disability expert. With “practices that have a disparate impact based on race or gender, you have . . . some difficult hurdles to overcome in terms you have to make with population level data that are not usually required in the same way” for ADA claims. This expert added, “Frankly, [ADA violations] are often the same things that have a disparate impact based on race and other protected characteristics.” A more comprehensive mapping of potential applications of federal disability law challenges to tech harms, like algorithmic bias in hiring, could advance advocacy work, especially as the Supreme Court may clarify in coming years how public accommodations law applies to online platforms. One advocate also emphasized the importance of state-based disability and public accommodations laws.

b.   Invest in deeper research, data sets, and advocacy on government use of algorithms in public benefits to create a framework and principles for just use: One technology justice expert called for deeper research, “Now we can try to do proactive deeper research work and analytical framing work around this issue, to unpack why this algorithm cuts benefits. What is happening? In what way is this technology? And what way is it not?” Keying off ongoing efforts such as President Biden’s executive order on racial equity (which is in part examining federal data voids) and other efforts to evaluate federal use of AI, further research to develop effective guardrails may be beneficial. Additionally, advocates noted the need to build a better data ecosystem to address quality of services and issues for people with disabilities using government benefits. For example, proposed legislation calls for the creation of carequality metrics for home- and community-based services.

c.    Conduct research on how algorithmic decision-making

affects content moderation: Advocates called for greater research on how automated content moderation affects people with disabilities. As major platforms rely more heavily on AI to make moderation decisions, the algorithmic biases and disparate impacts of these technologies may be all the more important. In 2018, the Content Moderation & Removal at Scale conference produced the Santa Clara Principles. Further dialogue in the public interest community has produced additional efforts to improve content moderation. There is an opportunity for public interest principles on content moderation to be updated taking into account the increased use of automated content moderation and its effect on marginalized communities, including disabled people.

d.   Fund public opinion research on technology centered on

people with disabilities: In addition to the listening sessions proposed above, high-quality public opinion research on disability and technology is generally in short supply, and what exists often has severe methodological limitations. (Pew Research studies conducted in the mid-2010s, for example, noted, “Due to the nature of the surveys associated with this data, certain Americans with disabilities are likely undercounted.” These individuals included “adults who are deaf or have difficulty speaking,” “blind people,” and “those living in institutionalized group quarters,” depending on the specific data set). In ensuring intersectional disability-tech justice is truly grounded in the priorities and needs of people with disabilities, better understanding those needs is essential. Public opinion research, including polling, can help identify those priorities.⁵ In addition, better data may support litigation and advocacy. Said one tech policy advocate, “One of the areas of research that was most helpful to me was Pew does an online harassment survey every two years, and it is a trove of data on how different people are targeted for harassment . . . That research is valuable and can be cited in legal briefs.”

e.   Explore harms caused by student surveillance and

e-proctoring technologies: There is an opportunity for the public interest community to update briefs and reports on the reach and harms of student surveillance to incorporate a disability rights lens, especially with respect to students of color. After the rapid spread of these technologies due to COVID-19, there are many more potential case studies and longer-term data that could support intersectional advocacy efforts.

f.     Conduct research into technology’s role in the criminalization

of mental health: There is a gap in the research documenting technology’s role in the criminalization of mental health. This opportunity for multifaceted research could bring together criminal justice, mental health, civil rights, and technology organizations. Especially given the disproportionate share of BIPOC individuals with disabilities who have police encounters or are otherwise affected by the criminal justice system, this work may help address long-standing inequities.

g.   Develop policy solutions that support disability-inclusive tech regulation: Given the inherent tension discussed in this report regarding efforts to rein in forms of technology that may create harms for some groups, yet may also serve as a beneficial workplace accommodation assistive technology for some in the disability community – for example, jurisdictional bans on facial recognition software – there is a need for additional thought on how these forms of tech can be regulated to coexist in workplace and educational settings. One approach could include creating policy solutions and/or model legislation to allow for disabilityspecific carveouts if they serve an accommodation need that

won’t result in perpetuating the harms that such regulations serve to prevent. (These carveouts could focus on facial recognition software as well as other forms of technology that can facilitate disparate harms for some groups). An additional opportunity is to develop research that attempts to document or measure the impact of facial recognition technology or other potentially assistive technologies used in isolated settings as a workplace accommodation within jurisdictions, agencies and employers that are otherwise banned from using these tools.

10. Resource advocacy projects at the intersection of technology and disability

Through the course of interviews for this project, experts consulted offered a wide variety of potential areas where disability and technology organizations could work together. In addition to the ongoing activities captured earlier in this report, the list below identifies other potential areas of opportunity. (One disability justice advocate cautioned, however, that for these efforts to succeed “You need to train your staff first [about disability issues], and then we can have a conversation. Groups that didn’t do that were not very successful.”) Potential opportunities for joint advocacy include:

a. Include and follow the lead of intersectional perspectives in crafting principles and recommendations around comprehensive federal data privacy laws and designing other data privacy recommendations: Intersectional work may ultimately make tech advocacy more effective and increase the likelihood that policy reforms serve the needs of all people. Calling for this kind of approach, two disability rights leaders explained how they incorporated this type of intersectional thinking into their own advocacy. In working to get a text 988 service added to the FCC’s suicide prevention hotline so deaf and hard of people could access the service, they learned from mental health advocates that these texts could reveal geographic location and might prevent some people from using the service. As a result, the organization highlighted the need for an opt-out provision around location-sharing in their comments to the FCC. One opportunity would be to expand coalition advocacy on data privacy to explicitly reflect the needs of disabled individuals.

5 The same Pew report

highlighted the need for careful development of research methodology, as traditional techniques may systematically underrepresent people with disabilities that make it harder for them to use phones or computers.

[]“You need to train your staff first [about disability issues], and then we can have a conversation. Groups that didn’t do that were not very successful.”

b.   Advocate for federal funding to increase access to reliable devices and high-speed internet: There is a need for broader advocacy support to close the digital divide and its outsized impact on people with disabilities. One disability rights expert explained the disparate impact of pandemic e-learning for children with disabilities who lacked access to proper devices and internet as follows: “Lack of access to devices or broadband, all of that has made it worse for many Black and brown deaf children who are left even further behind.” Additionally, in order to connect to high-speed internet people with disabilities often need more expensive assistive devices. Especially in the wake of the pandemic, there is an opportunity for disability and technology justice groups to advocate for federal funds or philanthropic programs to be devoted to ensuring that all individuals have access to proper devices to connect them online. This advocacy and funding could also be directed at empowering community-based organizations run by and for people with disabilities to increase adoption, address local barriers to deployment by large Internet service providers, and facilitate access to the right equipment like assistive technology. These supports could help avoid benefit/support cliffs associated with when individuals complete school.

c.    Increase advocacy to encourage employers to take

advantage of remote workplace options to increase the number of disabled people in the workforce: The flexibility accompanied by remote work has fostered a better and more inclusive work environment for many individuals with disabilities. Advocating for companies to maintain or put in place flexible remote work options will be imperative especially as working from a home office can be classified as a reasonable accommodation under the ADA, meaning employers will have a legal obligation to provide disabled employees with at-home devices, adaptive technology, or other supports needed to do their job and connect to the internet.

d.   Include e-proctoring and student surveillance harms

in advocacy around privacy rules: College students with disabilities also face disparate impact from e-proctoring and other intrusive student surveillance. As privacy reform efforts potentially heat up, advocacy efforts could integrate these related topics.

e.   Build on existing oversight efforts to investigate DHS and ICE’s use of automated technologies that affect disabled immigrants: In order to pursue further advocacy, leaders across both technology and disability justice emphasized the opportunity to identify and document how immigration technologies affect disabled immigrants.

f.     Approach automated captioning and speech recognition

tools as needing a spectrum of work: One disability rights leader stressed the opportunity to treat emerging technology as a spectrum of work that is iterative and intersectional in addressing access and potential harms. For example, this leader called for support in advocating for automated captioning to first exist on all platforms and be readily available. They then also called for work to improve the quality and design of the technology so that it works for a variety of speech patterns while ensuring that identity is protected and that these tools aren’t used to persecute people with disabilities. This approach could be applied to other technologies – like virtual reality – with potential for significant benefit that nonetheless present other concerns.

g.   Enable and equip disability organizations with tools

necessary to increase their advocacy capacity: According to interviewees for this report, a number of the national disability organizations serve on consumer advisory committees to major tech companies. There is an opportunity for the technology public interest organizations to create toolkits and resource materials to better equip these disability groups to raise issues and questions of concern on technology harms, in addition to accessibility of products and services. For example, a plain language tool kit that promoted ways to move the focus of a conversation from AI fairness to AI justice could be useful to disability leaders in their conversations with major technology companies. In addition to these kinds of specific collaborations, resources for dedicated technical capacity and expertise within disability organizations was identified as another area of opportunity. “Philanthropy can make a much greater investment in real technology issues and teach folks what to think about AI and how to understand it within their issue area,” argued a technology justice leader, emphasizing the importance of increasing dedicated technologist capacity to inform advocacy on AI and other technical policy areas. “Having a technologist at your organization makes a world of difference. Training people to be able to do that is incredibly important.”

h.   Provide dedicated cross-trainings for disability groups to work on federal technology policy advocacy: Interviewees suggested that there is a need to provide policy advocacy training for disability groups. More specifically, there is a need to orient disability groups on how to advocate in the federal technology policy landscape. An interviewee working on disability issues explained, “Many disability advocates have no orientation, let alone training, on what the existing policies are, and what the evolution will be of tech policy.” To sustainably engage in this work, this individual argued, disability leaders must be equipped not only with the knowledge of how technology impacts people with disabilities, but also with the knowledge of how to work in a new and changing federal policy landscape.

i.     Create sustainable spaces for disability groups to work on federal technology policy: Even when individuals are better informed on policy matters, interviewees noted the few disabled people doing this work can find themselves isolated. One leader working on disability issues underscored this opportunity: “What is missing is a strategy and the means for sustaining people with disabilities at the table, equipped with an understanding of the technology, policy, and advocacy context they are in, and of the time-sensitivity of this moment to influence future development of inclusive technology.” Creating a space for mutual, ongoing support and engagement between these trained members of the disability community would enable connected and sustained work. This dedicated space for disability advocates to routinely share lessons learned and provide mutual and ongoing support to one another would increase the likelihood that technology policy engagement will be sustained.

Conclusion

Disability issues are fundamental to and inextricable from the pursuit of technology justice. By exploring the wide range of work already taking place at the nexus of these issues, identifying areas ripe for further work and highlighting challenges and field-building needs, this research is intended to serve not as a blueprint, but as a conversation starter to advance systematic efforts to build a more inclusive, coordinated, and effective public interest community.

Interviewees noted that technology companies often develop misleading or superficial relationships with disability organizations to promote a product line, not to address concerns from a disability perspective. One disability leader explained, “Disability is often used as a mechanism to whitewash a new technology.” Many disability advocacy communities are still unaware of the issues and potential harms these tech companies may be creating or are otherwise dependent on the technology companies for financial support.

If the work identified in this report is successful, we should see this relationship change as a fuller public interest and technology justice community form. One technology justice leader underscored this potential: “At end of day, this work is changing people’s lives. We just need to do it better.”

We are deeply grateful for the generosity of those who offered their time to participate in interviews and/or developed the extensive body of research and advocacy on which this report relies. Without their insights and leadership, this report would not have been possible. Any errors or oversimplifications are ours alone.

Centering Disability in Technology Policy: Issue Landscape and Potential Opportunities for Action

This report is intended to provide the foundation for identifying the more nuanced questions, tools, resources, policies, and – perhaps most importantly – relationships needed to do technology policy work that uplifts all. Supporting those working to ensure disabled people can use technology to fully participate in their community, achieve greater economic security, and flourish in our society while being protected from harm moves us closer to making real the promise of human and civil rights.

[]“At end of day, this work is changing people’s lives. We just need to do it better.”

American Association of People with Disabilities   |   Center for Democracy & Technology

Appendix 1:  List of Interviewees

The list of individuals below were interviewed for this report. Affiliations are presented as they

were at time of interview.

Maria Town

American Association of People with

Disabilities (AAPD)

Jennifer Mathis

Bazelon Center for Mental Health Law

Ángel Díaz

Brennan Center for Justice

Rachel Levinson-Waldman

Brennan Center for Justice

Lydia X.Z. Brown

Center for Democracy and Technology

Dara Baldwin

Center for Disability Rights

Andy Imparato

Disability Rights California

Jutta Treviranus

Inclusive Design Research Center

Anil Lewis

National Federation of the Blind

David Brody

Lawyers’ Committee for Civil Rights Under

Law

Bertram Lee, Jr.

Leadership Conference on Civil and Human

Rights

Thomas Earle

Liberty Resources

Brandon Forester MediaJustice

Hannah Sassaman

Movement Alliance Project

Howard A. Rosenblum

National Association of the Deaf

Zainab Alkebsi

National Association of the Deaf

K.J. Bagchi

New America’s Open Technology Institute

Sarah Morris

New America’s Open Technology Institute

Emily Paul Upturn

Judy Brewer

W3C

Appendix 2: Authors and Acknowledgments

Appendix 2:  Authors and Acknowledgments

Henry Claypool

Henry Claypool brings over 25 years of experience working on federal policy to shape policy development and program implementation. He currently applies his extensive disability policy experience in the healthcare and technology sectors. As a fellow at the Center for Democracy and Technology and a consultant to the American Association of People with Disabilities, his work in technology policy involves promoting an enhanced understanding of consumer data privacy, confronting the effects of algorithmic bias on disabled people, and bringing enhanced accessibility to emerging technologies.

He currently serves as the Policy Director of the Community Living Policy Center at Brandeis University and works as an independent consultant to public interest groups and disability advocacy organizations. His public service includes working on the BidenHarris transition as a member of the Health and Human Services agency review team. He was appointed by the President to serve on the Commission on Long Term Care in 2013. He served as the founding Principal Deputy Administrator at the Administration for Community Living (ACL) at the Department of Health and Human

Services in 2012. Prior to ACL, he was the Director of the Office on

Disability from 2009 - 2012. He served as the Senior Advisor for Disability Policy to the Administrator of the Centers for Medicare and Medicaid Services from 1999 – 2001.

Centering Disability in Technology Policy: Issue Landscape and Potential Opportunities for Action

Claire Carey

Claire Carey is a Senior Associate at Freedman Consulting, LLC. As a Senior Associate, she supports project teams in strategic planning, research, and communications for clients. Prior to joining Freedman Consulting, LLC, Claire was a Fulbright Scholar in Brazil, where she acted as an English Teaching Assistant at the University Federal de Viçosa. Claire has experience working in communications and policy as an intern for the Center on Budget and Policy Priorities and for Public Knowledge where she worked on anti-poverty and technology justice issues. Claire graduated summa cum laude from Villanova University with a Bachelor of Arts in Political Science and minors in Sociology and Spanish. Alexander C. Hart

Alexander C. Hart is a Vice President with Freedman Consulting, LLC, where he manages projects in policy and strategic planning, research, communications, public opinion, evaluation, and event facilitation. His work for firm clients covers a broad portfolio of issues, including technology policy, poverty and economic opportunity, democracy, and municipal innovation. Alex has worked with major political campaigns, foundations, and nonprofit organizations including the Ford Foundation, Open Society Foundations, NetGain Partnership, President Obama’s 2012 reelection campaign, the

Leadership Conference on Civil and Human Rights, and Spotlight on Poverty and

Opportunity. He graduated magna cum laude with a Bachelor of Science in Foreign Service degree from Georgetown University’s Walsh School of Foreign Service, majoring in international economics. Linnea Lassiter

Linnea Lassiter is a Project Manager at Freedman Consulting, LLC, where she conducts public policy research, strategic planning, and coalition management across a variety of policy issue areas with a social and racial justice impact. Linnea has over ten years of public policy analysis, research, and advocacy experience; much of her work has focused on the criminal justice system, anti-hunger, and anti-poverty efforts, as well as a variety of policy issue areas centered in anti-racism and racial justice. Prior to joining the Freedman team, Linnea worked at a number of DC-based think tanks, including: The Urban Institute, The Pew Charitable Trusts, The West Coast Poverty Center, and The Center on Budget and Policy Priorities. Linnea graduated magna cum laude from The George Washington University with a Bachelor’s in Political Science & Public Policy. She also holds a Master’s in Public Policy from the University of Washington.

Appendix 2: Authors and Acknowledgments

Acknowledgments

The authors are grateful to all the outside experts and advocates who generously shared their insights and time for interviews or provided feedback on drafts of this document. We also thank Francesca Galazzi for her contributions to researching and writing this report, as well as Emily Paul, Aaron Rieke, and Ridhi Shetty for their extensive and thoughtful feedback. We are grateful to Lydia X. Z. Brown, who both shared their insights in our research process and developed a plain language version of this report to make it more widely accessible. Any errors or omissions are solely our own.

More broadly, this project owes its existence to the leadership of AAPD’S Maria Town and CDT’s Alexandra Givens. Under their respective leadership, AAPD has dedicated significant resources to addressing the wide array of technology policy issues that impact people with disabilities, beyond accessibility; CDT has integrated disability law, policy tools, and impacts to their scrutiny of the rapidly evolving technology policy landscape. We hope the collaboration between these two organizations, which has produced this report and other efforts to ensure technology truly serves all, can inspire many further partnerships in the public interest community.

We also wish to thank the Ford Foundation for providing support for this project, which made this report possible.

Design and layout by Objectively.

Centering Disability in Technology Policy: Issue Landscape and Potential Opportunities for Action

[]
