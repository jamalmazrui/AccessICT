<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<title>Digital accessibility in the era of artificial intelligence—Bibliometric
analysis and systematic review</title>
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:"Cambria Math";
	panose-1:2 4 5 3 5 4 6 3 2 4;}
@font-face
	{font-family:Calibri;
	panose-1:2 15 5 2 2 2 4 3 2 4;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin-top:0in;
	margin-right:.45pt;
	margin-bottom:.2pt;
	margin-left:0in;
	text-align:justify;
	text-justify:inter-ideograph;
	text-indent:13.45pt;
	line-height:112%;
	font-size:9.0pt;
	font-family:"Calibri",sans-serif;
	color:#282828;}
h1
	{mso-style-link:"Heading 1 Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:6.45pt;
	margin-left:.5pt;
	text-indent:-.5pt;
	line-height:107%;
	page-break-after:avoid;
	font-size:13.5pt;
	font-family:"Calibri",sans-serif;
	color:#856DF0;
	font-weight:normal;}
h2
	{mso-style-link:"Heading 2 Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:9.1pt;
	margin-left:11.5pt;
	text-indent:-.5pt;
	line-height:102%;
	page-break-after:avoid;
	font-size:12.0pt;
	font-family:"Calibri",sans-serif;
	color:#282828;
	font-weight:normal;}
h3
	{mso-style-link:"Heading 3 Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:0in;
	margin-left:11.5pt;
	text-indent:-.5pt;
	line-height:107%;
	page-break-after:avoid;
	font-size:10.5pt;
	font-family:"Calibri",sans-serif;
	color:#282828;
	font-weight:normal;}
h4
	{mso-style-link:"Heading 4 Char";
	margin-top:0in;
	margin-right:0in;
	margin-bottom:.5pt;
	margin-left:.5pt;
	text-indent:-.5pt;
	line-height:107%;
	page-break-after:avoid;
	font-size:9.0pt;
	font-family:"Calibri",sans-serif;
	color:#282828;
	font-weight:normal;}
span.Heading3Char
	{mso-style-name:"Heading 3 Char";
	mso-style-link:"Heading 3";
	font-family:"Calibri",sans-serif;
	color:#282828;}
span.Heading2Char
	{mso-style-name:"Heading 2 Char";
	mso-style-link:"Heading 2";
	font-family:"Calibri",sans-serif;
	color:#282828;}
span.Heading1Char
	{mso-style-name:"Heading 1 Char";
	mso-style-link:"Heading 1";
	font-family:"Calibri",sans-serif;
	color:#856DF0;}
span.Heading4Char
	{mso-style-name:"Heading 4 Char";
	mso-style-link:"Heading 4";
	font-family:"Calibri",sans-serif;
	color:#282828;}
.MsoChpDefault
	{font-size:12.0pt;}
.MsoPapDefault
	{margin-bottom:8.0pt;
	line-height:115%;}
 /* Page Definitions */
 @page WordSection1
	{size:595.25pt 842.1pt;
	margin:34.45pt 59.25pt 34.05pt 447.45pt;}
div.WordSection1
	{page:WordSection1;}
@page WordSection2
	{size:595.25pt 842.1pt;
	margin:82.3pt 49.25pt 34.05pt 49.7pt;}
div.WordSection2
	{page:WordSection2;}
@page WordSection3
	{size:595.25pt 842.1pt;
	margin:357.1pt 49.7pt 34.05pt 49.7pt;}
div.WordSection3
	{page:WordSection3;}
@page WordSection4
	{size:595.25pt 842.1pt;
	margin:79.6pt 49.7pt 34.05pt 49.7pt;}
div.WordSection4
	{page:WordSection4;}
@page WordSection5
	{size:595.25pt 842.1pt;
	margin:79.6pt 49.7pt 34.05pt 49.7pt;}
div.WordSection5
	{page:WordSection5;}
@page WordSection6
	{size:595.25pt 842.1pt;
	margin:79.05pt 49.7pt 69.2pt 49.7pt;}
div.WordSection6
	{page:WordSection6;}
@page WordSection7
	{size:595.25pt 842.1pt;
	margin:83.75pt 49.65pt 70.75pt 49.7pt;}
div.WordSection7
	{page:WordSection7;}
 /* List Definitions */
 ol
	{margin-bottom:0in;}
ul
	{margin-bottom:0in;}
-->
</style>

</head>

<body lang=EN-US style='word-wrap:break-word'>

<div class=WordSection1>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:.5pt;text-align:left;text-indent:-.5pt;
line-height:107%'><img width=1 height=41
src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image001.gif"
align=left hspace=12><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>TYPE
</span><a
href="https://www.frontiersin.org/journals/artificial-intelligence#editorial-board"><span
style='font-size:7.0pt;line-height:107%;color:black;text-decoration:none'>Systematic
Review</span></a></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:-398.45pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:11.0pt;line-height:107%;color:black'><img
border=0 width=286 height=20 id="Group 44401"
src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image002.gif"></span><span
style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>PUBLISHED </span><a
href="https://www.frontiersin.org/journals/artificial-intelligence#editorial-board"><span
style='font-size:7.0pt;line-height:107%;color:black;text-decoration:none'>16</span></a><span
style='font-size:7.0pt;line-height:107%;color:black'> </span><a
href="https://www.frontiersin.org/journals/artificial-intelligence#editorial-board"><span
style='font-size:7.0pt;line-height:107%;color:black;text-decoration:none'>February</span></a><span
style='font-size:7.0pt;line-height:107%;color:black'> </span><a
href="https://www.frontiersin.org/journals/artificial-intelligence#editorial-board"><span
style='font-size:7.0pt;line-height:107%;color:black;text-decoration:none'>2024</span></a></p>

</div>

<span style='font-size:9.0pt;line-height:112%;font-family:"Calibri",sans-serif;
color:#282828'><br clear=all style='page-break-before:auto'>
</span>

<div class=WordSection2>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:20.15pt;margin-left:0in;text-align:left;text-indent:0in;
line-height:107%'><span style='font-size:11.0pt;line-height:107%;color:black'><img
border=0 width=98 height=19 id="Group 44451"
src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image003.gif"></span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:4.75pt;margin-left:0in;text-align:left;text-indent:0in;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>OPEN ACCESS</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:1.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>EDITED
BY</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>Timothy Arndt,</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:4.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>Cleveland
State University, United States</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:1.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>REVIEWED
BY</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>Amadeo José
Argüelles,</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>National
Polytechnic Institute (IPN), Mexico</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>Angela
Guercio,</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:4.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>Kent State
University at Stark, United States</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:1.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>*CORRESPONDENCE</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:23.85pt;
margin-bottom:5.8pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>Achraf Othman </span><span
style='font-size:11.0pt;line-height:108%;color:black'><img border=0 width=8
height=7 id="Group 44452"
src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image004.gif"></span><span
style='font-size:7.0pt;line-height:108%'> aothman@mada.org.qa</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:5.5pt;line-height:108%;color:#7D7F7F'>RECEIVED
</span><span style='font-size:7.0pt;line-height:108%'>05 December 2023</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:34.0pt;
margin-bottom:3.9pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:5.5pt;line-height:108%;color:#7D7F7F'>ACCEPTED
</span><span style='font-size:7.0pt;line-height:108%'>29 January 2024 </span><span
style='font-size:5.5pt;line-height:108%;color:#7D7F7F'>PUBLISHED </span><span
style='font-size:7.0pt;line-height:108%'>16 February 2024</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:1.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>CITATION</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>Chemnad K and
Othman A (2024) Digital</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>accessibility
in the era of artificial intelligence—Bibliometric analysis and systematic
review.</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:43.15pt;
margin-bottom:4.7pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><i><span style='font-size:7.0pt;line-height:108%;font-family:
"Times New Roman",serif'>Front. Artif. Intell. </span></i><span
style='font-size:7.0pt;line-height:108%'>7:1349668. doi: </span><a
href="https://doi.org/10.3389/frai.2024.1349668"><span style='font-size:7.0pt;
line-height:108%;color:#282828;text-decoration:none'>10.3389/frai.2024.1349668</span></a></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:1.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>COPYRIGHT</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:.2pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:108%'><span style='font-size:7.0pt;line-height:108%'>© 2024 Chemnad
and Othman. This is an open-access article distributed under the terms of the </span><a
href="http://creativecommons.org/licenses/by/4.0/"><span style='font-size:7.0pt;
line-height:108%;color:#856DF0;text-decoration:none'>Creative</span></a><span
style='font-size:7.0pt;line-height:108%;color:#856DF0'> </span><a
href="http://creativecommons.org/licenses/by/4.0/"><span style='font-size:7.0pt;
line-height:108%;color:#856DF0;text-decoration:none'>Commons</span></a><span
style='font-size:7.0pt;line-height:108%;color:#856DF0'> </span><a
href="http://creativecommons.org/licenses/by/4.0/"><span style='font-size:7.0pt;
line-height:108%;color:#856DF0;text-decoration:none'>Attribution </span></a><a
href="http://creativecommons.org/licenses/by/4.0/"><span style='font-size:7.0pt;
line-height:108%;color:#856DF0;text-decoration:none'>License</span></a><span
style='font-size:7.0pt;line-height:108%;color:#856DF0'> </span><a
href="http://creativecommons.org/licenses/by/4.0/"><span style='font-size:7.0pt;
line-height:108%;color:#856DF0;text-decoration:none'>(CC BY)</span></a><a
href="http://creativecommons.org/licenses/by/4.0/"><span style='font-size:7.0pt;
line-height:108%;color:#282828;text-decoration:none'>.</span></a><span
style='font-size:7.0pt;line-height:108%'> The use, distribution or reproduction
in other forums is permitted, provided the original author(s) and the copyright
owner(s) are credited and that the original publication in this journal is
cited, in accordance with accepted academic practice. No use, distribution or
reproduction is permitted which does not comply with these terms.</span></p>

<p class=MsoNormal align=right style='margin-top:0in;margin-right:0in;
margin-bottom:44.25pt;margin-left:0in;text-align:right;text-indent:0in;
line-height:107%'><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>DOI
</span><a href="https://doi.org/10.3389/frai.2024.1349668"><span
style='font-size:7.0pt;line-height:107%;color:black;text-decoration:none'>10.3389/frai.2024.1349668</span></a></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:.95pt;
margin-bottom:0in;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><a
href="https://www.frontiersin.org/articles/10.3389/frai.2024.1349668/full"><span
style='font-size:21.0pt;line-height:107%;color:#282828;text-decoration:none'>Digital
accessibility in the era of</span></a></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:.95pt;
margin-bottom:0in;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><a
href="https://www.frontiersin.org/articles/10.3389/frai.2024.1349668/full"><span
style='font-size:21.0pt;line-height:107%;color:#282828;text-decoration:none'>artificial</span></a></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:.95pt;
margin-bottom:7.1pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><a
href="https://www.frontiersin.org/articles/10.3389/frai.2024.1349668/full"><span
style='font-size:21.0pt;line-height:107%;color:#282828;text-decoration:none'>intelligence—Bibliometric
analysis and systematic review</span></a></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:3.0pt;margin-left:0in;text-align:left;text-indent:0in;line-height:
107%'><span style='font-size:11.0pt;line-height:107%;color:#6E6E6E'>Khansa
Chemnad </span><span style='font-size:11.0pt;line-height:107%;color:black'><img
border=0 width=10 height=10 id="Group 44453"
src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image005.gif"></span><span
style='font-size:11.0pt;line-height:107%;color:#6E6E6E'> and Achraf Othman </span><span
style='font-size:11.0pt;line-height:107%;color:black'><img border=0 width=10
height=10 id="Group 44454"
src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image006.gif"></span><span
style='font-size:11.0pt;line-height:107%;color:#6E6E6E'> *</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:23.95pt;margin-left:0in;text-align:left;text-indent:0in;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>Mada
Qatar Assistive Technology Center, Doha, Qatar</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:-.35pt;margin-bottom:
3.25pt;margin-left:-.25pt;text-indent:-.5pt;line-height:112%'>Introduction:
Digital accessibility involves designing digital systems and services to enable
access for individuals, including those with disabilities, including visual,
auditory, motor, or cognitive impairments. Artificial intelligence (AI) has the
potential to enhance accessibility for people with disabilities and improve
their overall quality of life.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:-.35pt;margin-bottom:
3.25pt;margin-left:-.25pt;text-indent:-.5pt;line-height:112%'>Methods: This
systematic review, covering academic articles from 2018 to 2023, focuses on AI
applications for digital accessibility. Initially, 3,706 articles were screened
from five scholarly databases—ACM Digital Library, IEEE Xplore, ScienceDirect,
Scopus, and Springer.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:-.35pt;margin-bottom:
3.25pt;margin-left:-.25pt;text-indent:-.5pt;line-height:112%'>Results: The
analysis narrowed down to 43 articles, presenting a classification framework
based on applications, challenges, AI methodologies, and accessibility
standards.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:-.35pt;margin-bottom:
.15in;margin-left:-.25pt;text-indent:-.5pt;line-height:112%'>Discussion: This
research emphasizes the predominant focus on AI-driven digital accessibility
for visual impairments, revealing a critical gap in addressing speech and
hearing impairments, autism spectrum disorder, neurological disorders, and
motor impairments. This highlights the need for a more balanced research
distribution to ensure equitable support for all communities with disabilities.
The study also pointed out a lack of adherence to accessibility standards in
existing systems, stressing the urgency for a fundamental shift in designing
solutions for people with disabilities. Overall, this research underscores the
vital role of accessible AI in preventing exclusion and discrimination, urging
a comprehensive approach to digital accessibility to cater to diverse disability
needs.</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:6.75pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:5.5pt;line-height:107%;color:#7D7F7F'>KEYWORDS</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:24.7pt;margin-left:0in;text-align:left;text-indent:0in;
line-height:102%'><span style='font-size:8.0pt;line-height:102%;color:#6E6E6E'>digital
accessibility, artificial intelligence (AI), research analysis, systematic
review, persons with disabilities</span></p>

<h1 style='margin-left:13.7pt;text-indent:-14.45pt'><span style='line-height:
107%'>1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Introduction</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:17.65pt;
margin-left:-.75pt'>Digital accessibility is integral to modern times,
especially because a significant percentage of the population is with one or
multiple disabilities today. According to the World Health Organization (WHO),
16% of the global population (or &#8764;1.3 billion people) currently suffers
from significant disability (<span style='color:#856DF0'>World Health
Organization, 2022</span>). This statistic highlights the need for digital
content and services to be accessible to people with disabilities so that they
are not excluded from actively participating the digital society today (<span
style='color:#856DF0'>Dobransky and Hargittai, 2016</span>). Consequently,
digital accessibility is not only a social responsibility, but also essential
for legal compliance, inclusion, and business benefits. It ensures that
everyone, regardless of their abilities or disabilities, has equal access to
digital content and services, and is an essential factor of an organization
that provides digital content or services. Digital accessibility, as defined by
the Web Accessibility Initiative (WAI),</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:73.05pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>01</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt;text-indent:0in'>implies that people with disabilities
should be able to access, navigate, perceive, and interact with content [<span
style='color:#856DF0'>Initiative (WAI), 2022</span>]. Digital accessibility
refers to the practice of designing digital systems and services in a manner
that makes them accessible to all individuals, including those with
disabilities (<span style='color:#856DF0'>Sharma et al., 2020</span>). This
includes ensuring that websites, software, and other digital products can be
used by people with visual, auditory, motor, or cognitive impairments.
Therefore, it is important to ensure that everyone, regardless of their
ability, can access and use digital products without facing barriers or
discrimination. If this is not done, it may result in people with disabilities
being excluded from opportunities, diminishing their degree of independence.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>Artificial intelligence (AI) is the capacity of a machine
or computer system to simulate and perform tasks that typically require human
intelligence, such as logical reasoning, learning, and problem resolution (<span
style='color:#856DF0'>Hassani et al., 2020</span>). The determination of when
applications and services can be classified as intelligent, as opposed to
merely emulating intelligent behavior, is a topic of debate (<span
style='color:#856DF0'>Schank, 1991</span>). Notwithstanding the ongoing
philosophical discourse surrounding the extent and limitations of AI, remarkable
progress has been made in a vast array of disciplines, such as machine
learning, natural language processing, and computer vision. For example,
AI-powered voice assistants such as Amazon Alexa, Apple Siri, and Google
Assistant have become increasingly popular because of their ability to
interpret natural language and offer user-friendly responses (<span
style='color:#856DF0'>McLean et al., 2021</span>). In addition, AI pattern
recognition algorithms have proven beneficial in several applications,
including facial recognition, image processing, and object detection (<span
style='color:#856DF0'>Abiodun et al., 2019</span>; <span style='color:#856DF0'>Fu,
2019</span>; <span style='color:#856DF0'>Liu et al., 2020</span>). AI has
benefited industries by monitoring and detecting defects in various processes,
resulting in increased productivity and decreased downtime (<span
style='color:#856DF0'>Pimenov et al., 2023</span>). AI has also been
instrumental in forecasting using intricate data analysis to make predictions.
AI has been beneficial for improving treatment processes in the healthcare
industry. For instance, tools powered by AI have been used to analyze medical
images and identify abnormalities, resulting in more precise diagnosis and
treatment recommendations (<span style='color:#856DF0'>Liu et al., 2006</span>).
Smart assistive technologies, such as wheelchairs designed for people with
limited mobility (<span style='color:#856DF0'>Leaman and La, 2017</span>) and
canes intended for people with visual impairments (<span style='color:#856DF0'>Hapsari
et al., 2017</span>), leverage advancements in AI to offer enhanced products
and services. These advancements demonstrate the immense potential of AI in
improving accessibility and user experience, making it an intriguing field of study
for both researchers and practitioners.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>The importance of digital accessibility in the AI era
cannot be overstated. With the increasing use of AI in all spheres of life, it
is crucial to ensure that these technologies are accessible to all individuals.
This review presents the current state of the application of AI in the digital
accessibility sector and proposes a classification system for identifying
accessibility standards and frameworks, challenges, AI methodologies, and
functionalities of AI in digital accessibility.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:24.6pt;
margin-left:-.75pt'>The next section provides background information on AI and
its applications in various industries. Subsequently, an overview of current
applications of AI in the digital accessibility sector is provided. This is
followed by the research methodology, which describes the process of systematic
review mapping and presents research results based on a classification
framework. Subsequently, we discuss the current literature on the four
dimensions of accessibility frameworks/standards, challenges, methodologies, and
applications of AI for digital accessibility. Finally, future research
directions and implications are discussed.</p>

<h1 style='margin-left:25.45pt;text-indent:-14.45pt'><span style='line-height:
107%'>2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Background</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:11.0pt'>As artificial intelligence continues to permeate various
aspects of our lives, it is important to investigate its impact on the digital
accessibility of people with disabilities. The inception of the term
“Artificial Intelligence” or “AI” dates back to the 1950’s when it emerged as a
concept for designing machines with the ability to perform tasks that resemble
human-like cognitive abilities (<span style='color:#856DF0'>Schwendicke et al.,
2020</span>). In recent years, AI has made significant advancements in various
industries including healthcare, finance, and transportation. With the
development of machine learning, natural language processing, and deep learning
algorithms, machines can now learn from data and improve their performances
over time. This has the potential to significantly improve accessibility for
people with disabilities, particularly in the health care industry. For
example, AI is already being used to analyze medical images and diagnose
diseases, such as cancer (<span style='color:#856DF0'>Bi et al., 2019</span>).
In the finance industry, AI can also be used for tasks such as fraud detection
and credit scoring (<span style='color:#856DF0'>Zhou et al., 2018</span>),
which could potentially affect the financial accessibility of people with
disabilities. However, it is important to monitor the use of AI in finance to
ensure that it does not perpetuate discrimination against people with
disabilities or other marginalized groups. Overall, although AI has the
potential to improve accessibility and inclusion, it is important to approach
its development and implementation with caution and focus on inclusivity.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:33.65pt;
margin-left:11.0pt'>Rapid advancements in technology have led to an increase in
the use of digital devices for various purposes, including access to healthcare
services. However, not everyone has equal access to these digital resources
because of various barriers, such as physical, sensory, and cognitive
disabilities. AI-powered technologies such as Automated Speech Recognition
(ASR), Google Neural Machine Translation (GNMT), Google Vision API, and
DeepMind are increasingly being used to improve accessibility for people with disabilities
(<span style='color:#856DF0'>Bragg et al., 2019</span>). These technologies
have the potential to transform interactions with digital devices and
platforms. For example, ASR can provide captions and subtitles for video
content (<span style='color:#856DF0'>Alonzo et al., 2022</span>), and image and
facial recognition technologies can assist people with visual impairments (<span
style='color:#856DF0'>Feng et al., 2020</span>). The utilization of
AI-generated summaries in digital content can provide an advantage for screen
reader users by breaking down lengthy texts into more manageable portions (<span
style='color:#856DF0'>Chen et al., 2023</span>). Furthermore, AI can simulate
user behavior to pinpoint and rectify navigation issues, and automate
regression testing. Additionally, the implementation of AI-powered chatbots and
virtual assistants can offer accessible communication options for people with
speech and hearing impairments (<span style='color:#856DF0'>Shezi and
Ade-Ibijola, 2020</span>; <span style='color:#856DF0'>Subashini and
Krishnaveni, 2021</span>). However, the potential risks associated with AI in
this context must be considered, such as the possibility of perpetuating
existing biases</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>02</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt;text-indent:0in'>and neglecting the needs and experiences of
certain groups of people with disabilities. It is crucial to address these
potential drawbacks to ensure that these technologies are truly inclusive and
provide benefits for all users.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>Machine learning algorithms can recognize patterns and
identify accessibility barriers to digital content (<span style='color:#856DF0'>Abduljabbar
et al., 2019</span>). For example, image recognition algorithms can
automatically provide alternative text descriptions for images, making them
accessible to the visually impaired (<span style='color:#856DF0'>Bigham et al.,
2006</span>). Similarly, natural language processing algorithms can identify
and correct language that may be difficult for people with cognitive
impairments to understand (<span style='color:#856DF0'>Le Glaz et al., 2021</span>).
By creating machine-learning algorithms that specifically address the issues of
digital accessibility, we can create technology that benefits all users,
regardless of their abilities. However, it is crucial that these algorithms are
developed with inputs from people with disabilities to ensure that they are
effective and meet their needs. In addition, it is important to consider the
potential biases present in the data used to train these algorithms, as they
may perpetuate existing inequalities and exclusion. By addressing these issues
and prioritizing accessibility in machine-learning algorithms, we can work
toward a more inclusive and equitable digital future for all.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:22.55pt;
margin-left:-.75pt'>Advancements in AI have created new opportunities to
enhance digital accessibility for people with disabilities (<span
style='color:#856DF0'>Hapsari et al., 2017</span>). However, as AI technology
progresses, it is crucial to closely examine its impact on accessibility and to
ensure that these technologies are developed in an equitable and inclusive
manner. Despite the growing interest in the intersection of AI and digital
accessibility, a comprehensive systematic review of the current state of
knowledge and practices in this field is yet to be conducted. This systematic
review aimed to fill this research gap by providing a comprehensive analysis of
the current state of knowledge and practices related to AI and digital
accessibility. By reviewing the existing literature, this study offers valuable
insights into the potential benefits of AI for people with disabilities as well
as identifying potential challenges and opportunities. Furthermore, this review
can guide future research and development activities toward creating more
inclusive and accessible technologies. The results of this systematic review
can provide valuable resources for researchers, practitioners, and policymakers
working in the fields of digital accessibility and AI by identifying gaps in
current knowledge and practices, which can help promote digital accessibility
and support the development of inclusive technologies that benefit everyone.</p>

<h1 style='margin-left:13.7pt;text-indent:-14.45pt'><span style='line-height:
107%'>3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Materials
and methods</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>This literature review followed the procedures and
processes for conducting literature searches proposed by <span
style='color:#856DF0'>Watson </span>(<span style='color:#856DF0'>2015</span>),
and was conducted in three phases: planning, execution, and reporting. The
systematic review methodology used in this study incorporated the strategies
and guidelines outlined by <span style='color:#856DF0'>Kitchenham et al. </span>(<span
style='color:#856DF0'>2007</span>) and <span style='color:#856DF0'>Ali et al. </span>(<span
style='color:#856DF0'>2018</span>, <span style='color:#856DF0'>2020</span>, <span
style='color:#856DF0'>2021</span>, <span style='color:#856DF0'>2023</span>). <span
style='color:#856DF0'>Figure 1 </span>depicts the steps involved in the
systematic review.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>In the planning phase, the need for a systematic review was
identified, a classification framework was defined, research questions were
defined, and a research protocol was developed.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:25.1pt;
margin-left:11.0pt;text-indent:0in'>During the execution phase, the search
query was conducted based on the following keywords: exclusion and inclusion
criteria were applied; screening based on title and abstract reading, full-text
reading, and quality assessment were conducted. The reporting phase included
classification of the chosen articles and discussion of the findings.</p>

<h2 style='margin-left:33.0pt;text-indent:-22.75pt'>3.1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span>Planning stage</h2>

<h3 style='margin-left:39.55pt;text-indent:-28.55pt'><span style='line-height:
107%'>3.1.1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Identify
the need for a systematic review</h3>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:23.0pt;
margin-left:11.0pt'>To our knowledge, no systematic review has comprehensively
outlined these research findings, while providing a profound analysis of the
research and practice related to the topic of digital accessibility, with a
specific focus on AI applications for people with disabilities. Although
limited in number, existing surveys on digital accessibility are often
specialized in nature, with many being country-specific studies or tailored to
specific fields, such as education and software engineering processes (<span
style='color:#856DF0'>Bong and Chen, 2021</span>; <span style='color:#856DF0'>Chadli
et al., 2021</span>; <span style='color:#856DF0'>Paiva et al., 2021</span>; <span
style='color:#856DF0'>Prado et al., 2023</span>). However, despite these
valuable efforts, no comprehensive systematic review has yet extensively
examined the intersection of digital accessibility and AI applications within
the existing literature. This study seeks to address this gap by providing an
extensive analysis of this field, revealing potential benefits, challenges, and
opportunities.</p>

<h3 style='margin-left:39.55pt;text-indent:-28.55pt'><span style='line-height:
107%'>3.1.2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Develop
a research review protocol</h3>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:22.95pt;
margin-left:11.0pt'>In this step, the research review protocol used for the
literature review was finalized. The classification framework is based on a
model initially developed by <span style='color:#856DF0'>Ngai and Wat </span>(<span
style='color:#856DF0'>2002</span>), which is based on how advanced technologies
have enhanced various fields. The framework was developed and modified by <span
style='color:#856DF0'>Ali et al. </span>(<span style='color:#856DF0'>2018</span>,
<span style='color:#856DF0'>2020</span>, <span style='color:#856DF0'>2021</span>,
<span style='color:#856DF0'>2023</span>). The framework used in our study takes
into consideration four dimensions of how AI is used in different sectors about
accessibility: applications, AI methodology and techniques, design standards
and frameworks used, and challenges. <span style='color:#856DF0'>Table 1 </span>provides
more details on the classification framework used in our study.</p>

<h3 style='margin-left:39.55pt;text-indent:-28.55pt'><span style='line-height:
107%'>3.1.3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Defining
the research questions</h3>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.65pt;
margin-left:11.0pt'>Formulating the research questions for this study is a
crucial step in systematic reviews (<span style='color:#856DF0'>Paul et al.,
2021</span>). The research questions identified for the study are as follows:</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:29.0pt;text-indent:-10.0pt'>RQ 1. What are the AI applications that
have been used to enhance digital accessibility?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:29.0pt;text-indent:-10.0pt'>RQ 2. What are the different AI
techniques that have been used to enhance the accessibility of digital systems
for people with disabilities?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:29.0pt;text-indent:-10.0pt'>RQ 3. What are the key challenges and
barriers that must be overcome to achieve accessible AI systems for people with
disabilities ?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:23.7pt;
margin-left:29.0pt;text-indent:-10.0pt'>RQ 4. What are the different
accessibility standards that have been used to guide the design and
implementation of accessible AI systems?</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>03</span></p>

</div>

<span style='font-size:9.0pt;line-height:112%;font-family:"Calibri",sans-serif;
color:#282828'><br clear=all style='page-break-before:always'>
</span>

<div class=WordSection3>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 align=left
 width=662 style='width:496.2pt;border-collapse:collapse;margin-left:-2.25pt;
 margin-right:-2.25pt'>
 <tr style='height:25.55pt'>
  <td width=168 valign=top style='width:125.7pt;border-top:#A6B0A8;border-left:
  #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
  border-width:1.0pt;background:#8F9496;padding:5.15pt 5.75pt 0in 6.15pt;
  height:25.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Applications</span></p>
  </td>
  <td width=130 valign=top style='width:97.4pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  background:#8F9496;padding:5.15pt 5.75pt 0in 6.15pt;height:25.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>AI methodology</span></p>
  </td>
  <td width=205 valign=top style='width:154.1pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  background:#8F9496;padding:5.15pt 5.75pt 0in 6.15pt;height:25.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>Design</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>standards/guidelines/frameworks</span></p>
  </td>
  <td width=159 valign=top style='width:119.0pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  background:#8F9496;padding:5.15pt 5.75pt 0in 6.15pt;height:25.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>Challenges</span></p>
  </td>
 </tr>
 <tr style='height:114.25pt'>
  <td width=168 valign=top style='width:125.7pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 5.75pt 0in 6.15pt;height:114.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.85pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Artificial vision</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.9pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Navigation</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.9pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Fire safety</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.85pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Road safety</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.9pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Educational</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Banking</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.75pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>lighting solutions</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.7pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Virtual assistant</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.65pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Communication with smart devices</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.7pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Sign language recognition</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.75pt;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Accessible transport</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:8.55pt;text-align:left;text-indent:-8.55pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Entertainment</span></p>
  </td>
  <td width=130 valign=top style='width:97.4pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 5.75pt 0in 6.15pt;height:114.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.9pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Computer vision</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Edge AI</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>NLP</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.75pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Machine learning</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Deep learning</span></p>
  </td>
  <td width=205 valign=top style='width:154.1pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 5.75pt 0in 6.15pt;height:114.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:71.6pt;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>• Design
  standards • Accessibility standards</span></p>
  </td>
  <td width=159 valign=top style='width:119.0pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 5.75pt 0in 6.15pt;height:114.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.75pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Data challenges</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.7pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Technical issues</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.7pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Operational challenges</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.7pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Knowledge and awareness</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
  style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
  style='font-size:7.0pt;line-height:107%'>Security and privacy</span></p>
  </td>
 </tr>
</table>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#7D7F7F'>TABLE
2 </span><span style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>Eligibility
criteria for article inclusion in the review.</span></p>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 width=321
 style='width:240.95pt;margin-left:.3pt;border-collapse:collapse'>
 <tr style='height:16.25pt'>
  <td width=149 valign=top style='width:111.55pt;border-top:#A6B0A8;border-left:
  #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
  border-width:1.0pt;background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;
  height:16.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Inclusion criteria</span></p>
  </td>
  <td width=173 valign=top style='width:129.4pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;height:16.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>Exclusion criteria</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=149 valign=top style='width:111.55pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Papers
  published between the years</span></p>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>2018–2023</span></p>
  </td>
  <td width=173 valign=top style='width:129.4pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Papers not
  written in English.</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=149 valign=top style='width:111.55pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:1.05pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%'>The paper should have
  been written in English</span></p>
  </td>
  <td width=173 valign=top style='width:129.4pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Duplicated
  studies</span></p>
  </td>
 </tr>
 <tr style='height:33.6pt'>
  <td width=149 valign=top style='width:111.55pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>The
  paper should answer one or more of the research questions</span></p>
  </td>
  <td width=173 valign=top style='width:129.4pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:9.55pt;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Papers that
  were not peer-reviewed i.e., reviews, books, posters, and editorials;</span></p>
  </td>
 </tr>
 <tr style='height:42.55pt'>
  <td width=149 valign=top style='width:111.55pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>The
  publication should have been peer reviewed and should either be a journal
  article or a conference paper.</span></p>
  </td>
  <td width=173 valign=top style='width:129.4pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:15.2pt;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>The paper is
  about elderly or medical diagnosis</span></p>
  </td>
 </tr>
 <tr style='height:33.55pt'>
  <td width=149 valign=top style='width:111.55pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>The
  paper length shall be a minimum of five pages excluding references.</span></p>
  </td>
  <td width=173 valign=top style='width:129.4pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:14.3pt;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Paper is not
  about digital accessibility</span></p>
  </td>
 </tr>
</table>

<h3 style='margin-left:27.8pt;text-indent:-28.55pt'><span style='line-height:
107%'>3.1.4<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Defining
the strategies for article selection</h3>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:26.2pt;
margin-left:-.75pt'>

<table cellpadding=0 cellspacing=0>
 <tr>
  <td width=66 height=0></td>
 </tr>
 <tr>
  <td></td>
  <td><img width=662 height=352
  src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image007.gif"></td>
 </tr>
</table>

<br clear=ALL>
To minimize bias, strategies for article selection were determined at this
stage. As a part of this process, a comprehensive search strategy was created
to encompass a wide-ranging search of various databases, and a manual review of
the selected articles was conducted. The databases chosen for this systematic
review included the ACM Digital Library, IEEEXplore, ScienceDirect, Scopus, and
Springer. During the research process, filtering tools were employed for every
database to minimize duplication. In conducting the manual review, the broad
manual review method was utilized, which entailed scanning the title and
abstract of each research article (<span style='color:#856DF0'>Golder et al.,
2014</span>), followed by reading the full content of the selected articles to
eliminate any irrelevant ones. <span style='color:#856DF0'>Table 2 </span>lists
the eligibility criteria used in this study.</p>

<h2 style='margin-left:33.0pt;text-indent:-22.75pt'>3.2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span>Execution stage</h2>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:12.6pt;
margin-left:11.0pt'>The execution stage involved the implementation of the
steps outlined in the planning phase. The main steps undertaken in the
execution stage are as follows:</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:23.5pt;
margin-left:17.95pt;text-indent:-10.0pt'><span style='line-height:112%'>•<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span>To ensure
a thorough search, we utilized key terms extracted from relevant research
papers and research questions,</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>04</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:17.95pt;text-indent:0in'>including synonyms, acronyms, and spelling
variations of these terms. The search terms were then classified into three
categories: those related to AI, technology-specific terms, and accessibility
in the context of disability. The keywords identified for this study were:
((“Artificial Intelligence” OR “AI”) AND (“Digital” OR “technology” OR
“technologies” OR “technological”) AND (“accessibility” OR “inclusion” OR
“inclusivity” OR “disability” OR “disabled” OR “special needs” OR “impaired” OR
“impairment”)).</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:17.95pt;text-indent:-10.0pt'><span style='line-height:112%'>•<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span>Filtering
tools were used to refine the research results while conducting the online
database search. Several filters were implemented in this study, including the
year of publication (2018–2023), document type (journal articles and conference
papers), and language (English). Given the vast quantity of results, additional
filters, such as “title,” “abstract,” and “keyword” search, as well as “open
access” filters, were utilized to refine the search. Of the 50,655 search
results returned by the Springer database, only the first 1,000 were considered
for this review.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:17.95pt;text-indent:-10.0pt'><span style='line-height:112%'>•<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span>The
articles were subjected to abstract and keyword screening followed by full-text
screening.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.6pt;
margin-left:17.95pt;text-indent:-10.0pt'><span style='line-height:112%'>•<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp; </span></span>To ensure
the validity of the articles included in this study, certain quality assessment
criteria were applied to confirm their value. Quality assessment of the
candidate papers followed the guidelines outlined in <span style='color:#856DF0'>Kitchenham
et al. </span>(<span style='color:#856DF0'>2007</span>) study. Consequently, we
formulated the following questions to evaluate quality.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:21.85pt;text-indent:-10.85pt'><span style='line-height:112%'>1.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span>Are the aims
clearly stated?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:21.85pt;text-indent:-10.85pt'><span style='line-height:112%'>2.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span>Are data
collection methods adequately described?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:21.85pt;text-indent:-10.85pt'><span style='line-height:112%'>3.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span>Are all of the
study questions answered?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:21.85pt;text-indent:-10.85pt'><span style='line-height:112%'>4.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span>

<table cellpadding=0 cellspacing=0>
 <tr>
  <td width=66 height=0></td>
 </tr>
 <tr>
  <td></td>
  <td><img width=662 height=426
  src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image008.gif"></td>
 </tr>
</table>

<br clear=ALL>
Is the AI technique and methodology used in this studyfully defined?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:21.85pt;text-indent:-10.85pt'><span style='line-height:112%'>5.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span>How do these
results add to the literature?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:21.85pt;text-indent:-10.85pt'><span style='line-height:112%'>6.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span>Are the
limitations of this study were adequately addressed.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:5.7pt;
margin-left:21.85pt;text-indent:-10.85pt'><span style='line-height:112%'>7.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp; </span></span>How clear and
coherent are reports?</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:31.05pt;
margin-left:11.0pt'>Each QA inquiry was evaluated using a three-point rating
system. A response of “yes” received a score of 1, a “partial” response earned
0.5 points, and a “no” response was assigned a score of 0. If the study
effectively addressed the QA question, it received a full point, whereas a
partial response warranted 0.5 points. Any paper that failed to address the QA
question was assigned a score of 0. The quality of the research articles was
assessed using the QA questions to determine the overall quality score for each
study. An inclusion criterion was established, requiring a minimum overall
score of four for research inclusion. Studies with scores below four were
excluded.</p>

<h2 style='margin-left:33.0pt;text-indent:-22.75pt'>3.3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span>Summarizing stage</h2>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:23.65pt;
margin-left:11.0pt'>Data collection for this review was conducted between May
18, 2023, and May 24, 2023. <span style='color:#856DF0'>Figure 2 </span>shows
the final number of articles selected for this review. The search results based
on the keywords and search filters applied identified 3,706 articles.
Duplicates and retracted articles were removed prior to the abstract, title,
and keyword screening. In total, 2,424 articles were removed at this stage.
During the full-text screening stage, 850 articles were excluded, leaving 280
articles. These articles were</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>05</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:27.65pt;
margin-left:-.75pt;text-indent:0in'>subjected to quality assessment, and 42
articles were retained for the final analysis.</p>

<h1 style='margin-top:0in;margin-right:0in;margin-bottom:4.5pt;margin-left:
13.7pt;text-indent:-14.45pt'><span style='line-height:107%'>4<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Results
and discussion</h1>

<h2 style='margin-left:.5pt'>4.1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span>Distribution of article by publication year</h2>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'><span style='color:#856DF0'>Figure 3 </span>illustrates the
dissemination of articles by the year of publication. The first publication on
the utilization of AI in accessibility was published in 2018, whereas the most
substantial number of articles (13) were released in 2022. Conversely, only one
article was published in 2018.</p>

<h2 style='margin-left:33.0pt;text-indent:-22.75pt'>4.2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span><img width=662 height=667
src="Digital%20Accessibility%20in%20the%20Era%20of%20Artificial%20Intelligence%20-%20Bibliometric%20Analysis%20and%20Systematic%20Review_files/image009.gif"><br
clear=ALL>
Distribution of articles by database</h2>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:26.45pt;
margin-left:11.0pt'><span style='color:#856DF0'>Figure 4 </span>depicts the
distribution of the selected articles by the database source. A total of 41
articles were identified in Scopus, followed by one article each from
ScienceDirect and ACM Digital databases. No articles were selected from
IEEEXplore or Springer database, as they were either duplicates or had to be
excluded as they did not meet the inclusion criteria during the screening
process.</p>

<h2 style='margin-left:33.0pt;text-indent:-22.75pt'>4.3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span>Research classification framework</h2>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.75pt;
margin-left:11.0pt'>The findings of the review were the result of a
comprehensive analysis of articles related to AI and digital accessibility that</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>06</span></p>

</div>

<span style='font-size:9.0pt;line-height:112%;font-family:"Calibri",sans-serif;
color:#282828'><br clear=all style='page-break-before:always'>
</span>

<div class=WordSection4>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#7D7F7F'>TABLE
3 </span><span style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>Applications
that have been developed to enhance digital accessibility.</span></p>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 width=662
 style='width:496.2pt;margin-left:.3pt;border-collapse:collapse'>
 <tr style='height:16.6pt'>
  <td width=92 valign=top style='width:69.0pt;border-top:#A6B0A8;border-left:
  #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
  border-width:1.0pt;background:#8F9496;padding:5.15pt 7.85pt 0in 6.15pt;
  height:16.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Category</span></p>
  </td>
  <td width=432 valign=top style='width:324.15pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  background:#8F9496;padding:5.15pt 7.85pt 0in 6.15pt;height:16.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>Application</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  background:#8F9496;padding:5.15pt 7.85pt 0in 6.15pt;height:16.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>References</span></p>
  </td>
 </tr>
 <tr style='height:15.65pt'>
  <td width=92 rowspan=24 valign=top style='width:69.0pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:5.15pt 7.85pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Visual
  impairment</span></p>
  </td>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide an
  artificial vision for a perfect human vision</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Balakrishnan
  et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Supporting
  visually impaired people during their navigation</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Balakrishnan
  et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Virtual
  assistant</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Royal
  et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Real-Time
  Fire Warning System</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Abdusalomov
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Explores the
  shared privacy and ethical concerns of people with visual impairments</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Akter
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Assist to
  perceive the world using a tactile glove and a webcam</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Li
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Visualize
  environment with the help of handheld devices such as Mobile Phones</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Chaitra
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Assist
  visually impaired pedestrians in safely crossing the street</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Montanha
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Create a
  dataset for teachable object recognition with people who are blind or have
  low vision</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Theodorou
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Automate the
  generation of tactile educational materials for enhancing educational
  material development for visually impaired and blind students</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>See
  and Advincula, 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Enhance the
  accessibility of social media content for people with disabilities,
  particularly those with visual impairments</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Duarte
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:0in;
  margin-left:.05pt;text-indent:0in;line-height:107%'><span style='font-size:
  7.0pt;line-height:107%'>Mobile bank note recognition application that can
  help visually impaired people identify different bank note values</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Thomas
  and Meehan, 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide
  braille-readable captions for images to help visually impaired individuals
  better understand their surroundings and the images they encounter in the
  digital environment</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Wadhwa
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>System
  explicitly designed for visually impaired people for indoor and outdoor
  localization and navigation.</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lo
  Valvo et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide a
  multi-language interactive device for visually impaired persons to read and
  translate text from books, magazines, newspapers, and other printed materials</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Harum
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide a
  solution to the problem of current lighting systems not providing necessary
  lighting comfort for visually impaired and elderly people</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Karyono
  et al., 2020</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide
  walking path support for visually impaired university students</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Kose
  and Vasant, 2020</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Conduct
  face-to-face video communication freely and confidently</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Guo
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide an
  interactive learning experience for visually impaired children aged 6–14
  years</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Jayawardena
  et al., 2019</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide AI
  fully automated assistive technique for visually impaired people to perceive
  objects in surrounding and provide obstacle-aware navigation, where auditory
  inputs are given to users in real-time</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Joshi
  et al., 2020</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>AI-Vision
  smart glasses with 2 key functionalities: facial expression/age/gender
  recognition for meetings and color recognition for outfit sorting</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Alashkar
  et al., 2020</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Help blind
  athletes’ mobility and orientation, empowering them to run without a guide</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lucibello
  and Rotondi, 2019</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provides
  near-real-time information about user’s surroundings using a smartphone
  camera to help users navigate more effectively</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Saha
  et al., 2019</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide
  students with visual impairments a virtual assistant in the lab that can be
  controlled using natural language</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Watters
  et al., 2020</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=92 rowspan=10 valign=top style='width:69.0pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A6B0A8 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:5.15pt 7.85pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Speech
  and hearing impairment</span></p>
  </td>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Recognize
  the complex sign language</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Ullah
  et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Offers
  highly accurate speech recognition and voice reproduction capabilities</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Yang
  et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Automatic
  recognition of two-handed signs in Indian Sign Language (ISL) serving as
  teaching assistant</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Sreemathy
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Aid people
  who are deaf or hard-of-hearing in communicating with their smart home
  devices</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Rajasekhar
  and Panday, 2022</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Enhance
  information accessibility for Deaf and Hard of Hearing individuals by
  developing more effective American Sign Language (ASL) animations.</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Al-Khazraji
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide
  real-time video transcripts for people in Saudi Arabia who are deaf or have
  hearing loss</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Zaid
  alahmadi and Alsulami,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2020</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Conduct
  face-to-face video communication freely and confidently</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Guo
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Harness
  virtual reality (VR) technology to enhance speech comprehension for
  individuals who are deaf or hard of hearing (DHH) and apply it to live
  communication during theatrical performances</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Teófilo
  et al., 2018</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Aid students
  with autism spectrum disorder (ASD) in learning to code with the aid of an AI
  Companion (AIC)</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Hughes
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.2pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Conduct
  face-to-face video communication freely and confidently</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 7.85pt 0in 6.15pt;height:15.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Guo
  et al., 2021</span></p>
  </td>
 </tr>
</table>

<p class=MsoNormal align=right style='margin-top:0in;margin-right:0in;
margin-bottom:32.85pt;margin-left:0in;text-align:right;text-indent:0in;
line-height:107%'><i><span style='font-size:7.0pt;line-height:107%;font-family:
"Times New Roman",serif'>(Continued)</span></i></p>

<p class=MsoNormal align=center style='margin:0in;text-align:center;text-indent:
0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>07</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#7D7F7F'>TABLE
3 </span><span style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>(Continued)</span></p>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 width=662
 style='width:496.2pt;margin-left:.3pt;border-collapse:collapse'>
 <tr style='height:16.6pt'>
  <td width=92 valign=top style='width:69.0pt;border-top:#A6B0A8;border-left:
  #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
  border-width:1.0pt;background:#8F9496;padding:5.15pt 3.75pt 0in 6.15pt;
  height:16.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Category</span></p>
  </td>
  <td width=432 valign=top style='width:324.15pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  background:#8F9496;padding:5.15pt 3.75pt 0in 6.15pt;height:16.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>Application</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  background:#8F9496;padding:5.15pt 3.75pt 0in 6.15pt;height:16.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>References</span></p>
  </td>
 </tr>
 <tr style='height:15.65pt'>
  <td width=92 valign=top style='width:69.0pt;border-top:none;border-left:solid #A6B0A8 1.0pt;
  border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'>&nbsp;</p>
  </td>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Recognize
  the complex sign language</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Ullah
  et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:15.65pt'>
  <td width=92 rowspan=3 valign=top style='width:69.0pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:5.15pt 3.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Motor
  impairment</span></p>
  </td>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Increase the
  accessibility of digital games for players with motor impairments</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Cimolino
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide
  cooperative traffic signal assistance for non-motorized users and
  disabilities</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Yang
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Provide
  accessible bus rides for persons in wheelchairs</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lin
  et al., 2019</span></p>
  </td>
 </tr>
 <tr style='height:24.55pt'>
  <td width=92 valign=top style='width:69.0pt;border-top:none;border-left:solid #A6B0A8 1.0pt;
  border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:24.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Neurological
  impairment/disorder</span></p>
  </td>
  <td width=432 valign=top style='width:324.15pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:24.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Improve
  accessibility and inclusion for dyslexic students in the learning system</span></p>
  </td>
  <td width=137 valign=top style='width:103.05pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:5.15pt 3.75pt 0in 6.15pt;height:24.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:1.6pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Zingoni
  et al., 2021</span></p>
  </td>
 </tr>
</table>

</div>

<span style='font-size:9.0pt;line-height:112%;font-family:"Calibri",sans-serif;
color:#282828'><br clear=all style='page-break-before:auto'>
</span>

<div class=WordSection5>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:36.9pt;
margin-left:-.75pt;text-indent:0in'>were presented and evaluated. The
classification framework was applied by considering four dimensions:
accessibility guidelines, frameworks, standards, challenges, methodologies, and
applications. Additional information is provided in <span style='color:#856DF0'>Tables
3</span>–<span style='color:#856DF0'>6</span>.</p>

<h3 style='margin-left:27.8pt;text-indent:-28.55pt'><span style='line-height:
107%'>4.3.1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>(RQ
1) Dimension: disability types</h3>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.1.1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>AI for the visually impaired</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>The reviewed literature emphasizes the development of
various applications aimed at enhancing the mobility, safety, and quality of
life of the visually impaired. These applications include an array of
functionalities such as obstacle detection, navigation, educational support,
and social media accessibility.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>Several systems have been specifically designed for
obstacle detection and spatial information. For example, <span
style='color:#856DF0'>Balakrishnan et al. </span>(<span style='color:#856DF0'>2023</span>)
presented a novel synchronization protocol for vision sensors that provides
real-time obstacle detection and spatial detail to improve mobility and safety.
Building upon this, <span style='color:#856DF0'>Royal et al. </span>(<span
style='color:#856DF0'>2023</span>) went a step further by not only detecting
objects but also offering real-time object recognition and text reading within
images, thereby improving overall accessibility.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>In the domain of safety, <span style='color:#856DF0'>Abdusalomov
et al. </span>(<span style='color:#856DF0'>2022</span>) utilized AI-based fire
detection and classification methods to monitor and forecast fire-related
scenarios, thereby providing early warnings that are specifically tailored to
the needs of blind and visually impaired individuals. <span style='color:#856DF0'>Akter
et al. </span>(<span style='color:#856DF0'>2022</span>) examined shared ethical
and privacy considerations relevant to people with visual impairments, making a
significant contribution to the ethical development of assistive technologies.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>The AviPer system utilizes a visual-tactile multimodal
attention network that incorporates a self-developed flexible tactile glove and
webcam (<span style='color:#856DF0'>Li et al., 2022</span>). This novel
approach enables visually impaired individuals to perceive and interact with
their surroundings. Furthermore, <span style='color:#856DF0'>Chaitra et al. </span>(<span
style='color:#856DF0'>2022</span>) presented a viable and cost-effective
solution for visualizing environments using handheld devices, such as mobile
phones.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>In urban environments, <span style='color:#856DF0'>Montanha
et al. </span>(<span style='color:#856DF0'>2022</span>) employed context
awareness and AI methods to aid visually impaired pedestrians in safely
navigating roadways and generating real-time instructions based on traffic
conditions.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'><span style='color:#856DF0'>Duarte et al. </span>(<span
style='color:#856DF0'>2021</span>) worked to enhance the accessibility of
social media content, particularly benefiting people with visual impairments.
In addition, <span style='color:#856DF0'>Thomas and Meehan </span>(<span
style='color:#856DF0'>2021</span>) introduced a mobile banknote recognition
application and <span style='color:#856DF0'>Wadhwa et al. </span>(<span
style='color:#856DF0'>2021</span>) improved environmental understanding by
offering braillereadable captions for digital images.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:11.0pt'><span style='color:#856DF0'>Lo Valvo et al. </span>(<span
style='color:#856DF0'>2021</span>) concentrated on the development of indoor
and outdoor localization and navigation technologies for visually impaired
individuals. <span style='color:#856DF0'>Harum et al. </span>(<span
style='color:#856DF0'>2021</span>) presented a multi-language interactive
device that enables the reading and translation of text from various printed
materials. <span style='color:#856DF0'>Karyono et al. </span>(<span
style='color:#856DF0'>2020</span>) addressed the issue of lighting discomfort
experienced by the visually impaired and elderly, by introducing a specially
designed system.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:11.0pt'><span style='color:#856DF0'>Kose and Vasant </span>(<span
style='color:#856DF0'>2020</span>) offered effective walking-path support to
university students with visual impairments, enhancing their overall campus
experience. <span style='color:#856DF0'>Joshi et al. </span>(<span
style='color:#856DF0'>2020</span>) introduced an AIbased fully automated
assistive system with real-time perception, obstacle-aware navigation, and
auditory feedback. The AI-Vision smart glasses, outlined in <span
style='color:#856DF0'>Alashkar et al. </span>(<span style='color:#856DF0'>2020</span>),
utilize machine learning algorithms for facial expression/age/gender
recognition and color recognition, providing assistance in daily tasks. Furthermore,
<span style='color:#856DF0'>See and Advincula </span>(<span style='color:#856DF0'>2021</span>)
automated the production of tactile educational materials, such as tactile
flashcards, tactile maps, and tactile peg puzzles, which incorporate
interactive tactile graphics and braille captions, serving as a versatile tool
for teaching concepts such as shapes and geography to visually impaired and
blind students.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:12.95pt;
margin-left:11.0pt'><span style='color:#856DF0'>Lucibello and Rotondi </span>(<span
style='color:#856DF0'>2019</span>), <span style='color:#856DF0'>Saha et al. </span>(<span
style='color:#856DF0'>2019</span>), and <span style='color:#856DF0'>Watters et
al. </span>(<span style='color:#856DF0'>2020</span>) aimed to improve the lives
of both blind and visually impaired individuals. <span style='color:#856DF0'>Lucibello
and Rotondi </span>(<span style='color:#856DF0'>2019</span>) focused on
supporting blind athletes in the track and field, promoting independent
running, and enhancing spatial awareness through the learning of echolocation
skills. <span style='color:#856DF0'>Saha et al. </span>(<span style='color:
#856DF0'>2019</span>) has created a system that provides near-real-time
information about the surroundings through a smartphone camera, enhancing the
mobility skills of people with visual impairments. Finally, <span
style='color:#856DF0'>Watters et al. </span>(<span style='color:#856DF0'>2020</span>)
aimed to provide visually impaired students with a virtual assistant in the
laboratory that could be controlled through natural language, eliminating the
need for specific keywords or phrases.</p>

<h4 style='margin-left:42.9pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.1.2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>AI for speech and hearing impairment</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:23.7pt;
margin-left:11.0pt'>This section explores innovative technologies developed to
cater to people with speech and hearing impairments. These technologies have
been categorized into distinct applications that offer a range of benefits. For
instance, a graphene-based wearable artificial throat was developed to provide
highly accurate speech recognition and voice reproduction capabilities,
particularly for those who have undergone laryngectomy (<span style='color:
#856DF0'>Yang et al., 2023</span>).</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>08</span></p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#7D7F7F'>TABLE
4 </span><span style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>AI
methodologies utilized to enhance digital accessibility.</span></p>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 width=321
 style='width:240.95pt;margin-left:.3pt;border-collapse:collapse'>
 <tr style='height:16.25pt'>
  <td width=73 valign=top style='width:54.85pt;border-top:#A6B0A8;border-left:
  #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
  border-width:1.0pt;background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;
  height:16.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Category</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;height:16.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>AI techniques</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;height:16.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>References</span></p>
  </td>
 </tr>
 <tr style='height:15.65pt'>
  <td width=73 valign=top style='width:54.85pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Edge AI</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'>&nbsp;</p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.65pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Yang et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=73 rowspan=5 valign=top style='width:54.85pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Computer</span></p>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>vision</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Instance
  segmentation</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>See and Advincula, 2021</span></p>
  </td>
 </tr>
 <tr style='height:51.1pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.1pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Object
  detection</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.1pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:.1pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Joshi et
  al., 2020</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lo Valvo et al., 2021</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>See and Advincula, 2021</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Thomas and Meehan, 2021</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Chaitra et al., 2022</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Yang et al., 2022</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Balakrishnan et al., 2023</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Royal et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:33.15pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Image/object
  recognition</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Jayawardena
  et al., 2019</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lin et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2019</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Saha et al., 2019</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Duarte et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2021</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Abdusalomov et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Image
  classification</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Thomas and Meehan, 2021</span></p>
  </td>
 </tr>
 <tr style='height:33.15pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Optical
  character recognition/text recognition</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Duarte et al., 2021</span><span style='font-size:7.0pt;
  line-height:107%'>; </span><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Ingavelez-Guerra et al., 2022</span><span style='font-size:
  7.0pt;line-height:107%'>; </span><span style='font-size:7.0pt;line-height:
  107%;color:#856DF0'>Royal et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:42.55pt'>
  <td width=73 valign=top style='width:54.85pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Machine
  learning</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'>&nbsp;</p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:4.6pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lin et
  al., 2019</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lucibello and Rotondi,
  2019</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Alashkar et al., 2020</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Kosiedowski et al., 2020</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Zingoni et al., 2021</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Ullah et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:51.5pt'>
  <td width=73 rowspan=3 valign=top style='width:54.85pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 5.75pt 0in 6.15pt;height:51.5pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Deep
  learning</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.5pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'>&nbsp;</p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.5pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Lin
  et al., 2019</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Karyono et al., 2020</span><span
  style='font-size:7.0pt;line-height:107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Guo
  et al., 2021</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Zingoni et al., 2021</span><span
  style='font-size:7.0pt;line-height:107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Li
  et al., 2022</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Montanha et al., 2022</span><span
  style='font-size:7.0pt;line-height:107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Sreemathy
  et al., 2022</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Ullah et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2023</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Yang et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:78.0pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:78.0pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>CNN</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:78.0pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:5.25pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  113%'><span style='font-size:7.0pt;line-height:113%;color:#856DF0'>Jayawardena
  et al., 2019</span><span style='font-size:7.0pt;line-height:113%'>; </span><span
  style='font-size:7.0pt;line-height:113%;color:#856DF0'>Alashkar et al., 2020</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Joshi et al., 2020</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Lo Valvo et al., 2021</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Thomas and</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:4.75pt;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:113%'><span style='font-size:7.0pt;line-height:113%;color:#856DF0'>Meehan,
  2021</span><span style='font-size:7.0pt;line-height:113%'>; </span><span
  style='font-size:7.0pt;line-height:113%;color:#856DF0'>Wadhwa et al., 2021</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Abdusalomov et al., 2022</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Chaitra et al., 2022</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Ingavelez-Guerra et al., 2022</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Rajasekhar and Panday, 2022</span><span
  style='font-size:7.0pt;line-height:113%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Yang
  et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>RNN</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Lu et al., 2020</span><span style='font-size:7.0pt;line-height:
  107%'>; </span><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Wadhwa
  et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=73 rowspan=4 valign=top style='width:54.85pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A6B0A8 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>NLP</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'>&nbsp;</p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:3.85pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Saha et
  al., 2019</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Ingavelez-Guerra et
  al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:42.15pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Text-to-speech</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:.4pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  113%'><span style='font-size:7.0pt;line-height:113%;color:#856DF0'>Jayawardena
  et al., 2019</span><span style='font-size:7.0pt;line-height:113%'>; </span><span
  style='font-size:7.0pt;line-height:113%;color:#856DF0'>Alashkar et al., 2020</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Joshi et al., 2020</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Harum et al., 2021</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Abdusalomov et al., 2022</span><span
  style='font-size:7.0pt;line-height:113%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Royal
  et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Facial
  expression recognition</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Hughes et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:51.05pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.05pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Speech
  recognition</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.05pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Teófilo
  et al., 2018</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Kose and Vasant,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2020</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Zaid alahmadi and Alsulami,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2020</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Efanov et al., 2022</span><span
  style='font-size:7.0pt;line-height:107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:1.05pt;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Ingavelez-Guerra
  et al., 2022</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Royal et al., 2023</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Yang et al., 2023</span></p>
  </td>
 </tr>
</table>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt;text-indent:0in'>Additionally, a platform that recognizes
complex sign language was designed to offer an effective means of communication
for speechimpaired children (<span style='color:#856DF0'>Ullah et al., 2023</span>).
The automatic recognition of two-handed signs in Indian Sign Language also
serves as a teaching assistant, enhancing cognitive abilities and fostering
interest in learning for hearing and speech-impaired children (<span
style='color:#856DF0'>Sreemathy et al., 2022</span>). The real-time
interpretation and recognition of American Sign Language contributes to
seamless control of smart home components, addressing the specific needs of
people who are deaf or hard-of-hearing in their interactions with smart home
devices (<span style='color:#856DF0'>Rajasekhar and Panday, 2022</span>).</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:11.5pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#7D7F7F'>TABLE
5 </span><span style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>Digital
accessibility frameworks.</span></p>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 width=321
 style='width:240.95pt;margin-left:11.3pt;border-collapse:collapse'>
 <tr style='height:16.25pt'>
  <td width=69 valign=top style='width:52.0pt;border-top:#A6B0A8;border-left:
  #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
  border-width:1.0pt;background:#8F9496;padding:4.8pt 4.95pt 0in 6.15pt;
  height:16.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Category</span></p>
  </td>
  <td width=141 valign=top style='width:105.9pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  background:#8F9496;padding:4.8pt 4.95pt 0in 6.15pt;height:16.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Frameworks/standards</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  background:#8F9496;padding:4.8pt 4.95pt 0in 6.15pt;height:16.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>References</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=69 rowspan=2 valign=top style='width:52.0pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 4.95pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Design
  standards</span></p>
  </td>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Framework
  for value co-design and co-creation</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Vieira et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:33.15pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Universal
  Design for Learning</span></p>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>(UDL)
  principles</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Hughes et al., 2022</span><span style='font-size:7.0pt;
  line-height:107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Ingavelez-Guerra
  et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2022</span></p>
  </td>
 </tr>
 <tr style='height:42.55pt'>
  <td width=69 rowspan=13 valign=top style='width:52.0pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A6B0A8 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 4.95pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Accessibility
  standards</span></p>
  </td>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>accessibility
  compliance testing</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:1.85pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%'>(ACT) rules recommended
  by the World Wide Web Consortium (W3C)</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Montanha et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Web
  Content Accessibility</span></p>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Guidelines
  (WCAG) 2.1</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Acosta-Vargas et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2022</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>ISO/IEC
  25010:2011 Systems and software engineering</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>See and Advincula, 2021</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Universal
  design</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Cimolino et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Player
  balancing</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Cimolino et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Interface
  adaptation</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Cimolino et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Digital
  Accessible Information</span></p>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>System
  (DAISY) Standard</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Harum et al., 2021</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>CIE
  1,231,997</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Karyono et al., 2020</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>CIE
  196:2011</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Karyono et al., 2020</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>CIE
  227:2017</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Karyono et al., 2020</span></p>
  </td>
 </tr>
 <tr style='height:33.2pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:33.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Fermatean
  fuzzy information based decision-making framework</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:33.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Hezam et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:42.15pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:42.15pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:105%'><span style='font-size:7.0pt;line-height:105%'>Guidelines
  for designing mobile apps for people who are deaf or hard of hearing (</span><span
  style='font-size:7.0pt;line-height:105%;color:#856DF0'>Yeratziotis and</span></p>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Van Greunen, 2013</span><span style='font-size:7.0pt;
  line-height:107%'>)</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:42.15pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Zaid alahmadi and</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Alsulami,
  2020</span></p>
  </td>
 </tr>
 <tr style='height:42.1pt'>
  <td width=141 valign=top style='width:105.9pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:42.1pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Yue and Zin </span><span style='font-size:7.0pt;line-height:
  107%'>(</span><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2013</span><span
  style='font-size:7.0pt;line-height:107%'>) proposed a model based on Pugh’s
  product development process (PDP) model</span></p>
  </td>
  <td width=111 valign=top style='width:83.05pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 4.95pt 0in 6.15pt;height:42.1pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Zaid alahmadi and</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Alsulami,
  2020</span></p>
  </td>
 </tr>
</table>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:12.1pt;
margin-left:11.0pt'>AI Technology has also been utilized to enhance information
accessibility through more efficient American Sign Language animations (<span
style='color:#856DF0'>Al-Khazraji et al., 2021</span>). Real-time video
transcripts are provided to improve the accessibility of video content for
people with hearing impairments or deafness in Saudi Arabia (<span
style='color:#856DF0'>Zaid alahmadi and Alsulami, 2020</span>). Finally, the
utilization of virtual reality technology in live communication during
theatrical performances demonstrates its potential to enhance speech
comprehension for people who are deaf or hard of hearing (<span
style='color:#856DF0'>Teófilo et al., 2018</span>). These insights collectively
highlight the diverse applications of AI in addressing the communication and
accessibility needs of people with speech and hearing impairments, emphasizing
the potential for transformative effects on their daily lives and societal
inclusion.</p>

<h4 style='margin-left:42.9pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.1.3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>AI for autism spectrum disorder</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:23.7pt;
margin-left:11.0pt'><span style='color:#856DF0'>Hughes et al. </span>(<span
style='color:#856DF0'>2022</span>) concentrated on advancements in virtual AI
companion (AIC) and facilitating students with autism spectrum disorder (ASD)
in STEM learning environments while fostering their social and communication
skills.</p>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:12.0pt;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%'>09</span></p>

</div>

<span style='font-size:9.0pt;line-height:112%;font-family:"Calibri",sans-serif;
color:#282828'><br clear=all style='page-break-before:always'>
</span>

<div class=WordSection6>

<p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
margin-bottom:0in;margin-left:-.25pt;text-align:left;text-indent:-.5pt;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#7D7F7F'>TABLE
6 </span><span style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>AI
enabled digital accessibility challenges.</span></p>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 width=321
 style='width:240.95pt;margin-left:.3pt;border-collapse:collapse'>
 <tr style='height:16.25pt'>
  <td width=73 valign=top style='width:54.85pt;border-top:#A6B0A8;border-left:
  #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
  border-width:1.0pt;background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;
  height:16.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='color:white'>Category</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;height:16.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>Type</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:solid #A6B0A8 1.0pt;
  border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  background:#8F9496;padding:4.8pt 5.75pt 0in 6.15pt;height:16.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='color:white'>References</span></p>
  </td>
 </tr>
 <tr style='height:42.55pt'>
  <td width=73 rowspan=3 valign=top style='width:54.85pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:.75pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%'>Data challenges</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Lack of
  data/challenges in data collection process</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.55pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Lu et al., 2020</span><span style='font-size:7.0pt;line-height:
  107%'>; </span><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Park
  et al., 2021</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Yang et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Data
  management and security</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Vieira et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:33.15pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Data bias
  and discrimination</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Zaid
  alahmadi and Alsulami, 2020</span><span style='font-size:7.0pt;line-height:
  107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Guo
  et al., 2021</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Theodorou et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2021</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Vieira et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:33.6pt'>
  <td width=73 rowspan=4 valign=top style='width:54.85pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 5.75pt 0in 6.15pt;height:33.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Technical
  issues</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Complexity</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:113%'><span style='font-size:7.0pt;line-height:113%;
  color:#856DF0'>Lu et al., 2020</span><span style='font-size:7.0pt;line-height:
  113%'>; </span><span style='font-size:7.0pt;line-height:113%;color:#856DF0'>Cimolino
  et al., 2021</span><span style='font-size:7.0pt;line-height:113%'>; </span><span
  style='font-size:7.0pt;line-height:113%;color:#856DF0'>Theodorou et al., 2021</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Li et al., 2022</span><span
  style='font-size:7.0pt;line-height:113%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Vieira
  et al., 2022</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Ullah et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:33.2pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Lack of
  technical support/technical issues</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:33.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Teófilo
  et al., 2018</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Guo et al., 2021</span><span
  style='font-size:7.0pt;line-height:107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Vieira
  et al., 2022</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Hezam et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:15.25pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Fallibility
  of AI</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.25pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Akter et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:24.2pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Hardware</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>constraints</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Rajasekhar and Panday, 2022</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=73 rowspan=3 valign=top style='width:54.85pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Operational
  challenges</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Lack of</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>infrastructure</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Hezam et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:42.15pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Cost</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:42.15pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:.9pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Jayawardena
  et al., 2019</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Karyono et al., 2020</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Lo Valvo et al., 2021</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Li et al., 2022</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Vieira et al., 2022</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Hezam et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:51.1pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.1pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:105%'><span style='font-size:7.0pt;line-height:105%'>Lack of
  implementation of</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>accessibility
  regulations and standards</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:51.1pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:.85pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  113%'><span style='font-size:7.0pt;line-height:113%;color:#856DF0'>Karyono et
  al., 2020</span><span style='font-size:7.0pt;line-height:113%'>; </span><span
  style='font-size:7.0pt;line-height:113%;color:#856DF0'>Guo et al., 2021</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Lo Valvo et al., 2021</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Acosta-Vargas et al., 2022</span><span
  style='font-size:7.0pt;line-height:113%'>; </span><span style='font-size:
  7.0pt;line-height:113%;color:#856DF0'>Ingavelez-Guerra et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2022</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Hezam et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=73 valign=top style='width:54.85pt;border-top:none;border-left:
  solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:.9pt;
  margin-bottom:0in;margin-left:0in;text-align:left;text-indent:0in;line-height:
  107%'><span style='font-size:7.0pt;line-height:107%'>Knowledge and awareness</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Lack of
  awareness</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:.5pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Karyono
  et al., 2020</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Vieira et al.,</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>2022</span><span
  style='font-size:7.0pt;line-height:107%'>; </span><span style='font-size:
  7.0pt;line-height:107%;color:#856DF0'>Hezam et al., 2023</span></p>
  </td>
 </tr>
 <tr style='height:24.6pt'>
  <td width=73 rowspan=2 valign=top style='width:54.85pt;border-top:none;
  border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A6B0A8 1.0pt;border-right:
  solid #A2A2A2 1.0pt;padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Security
  and privacy</span></p>
  </td>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Privacy and
  surveillance</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:24.6pt'>
  <p class=MsoNormal align=center style='margin-top:0in;margin-right:.35pt;
  margin-bottom:.5pt;margin-left:0in;text-align:center;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Akter
  et al., 2022</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Hughes et al., 2022</span><span
  style='font-size:7.0pt;line-height:107%'>;</span></p>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:#856DF0'>Li
  et al., 2022</span><span style='font-size:7.0pt;line-height:107%'>; </span><span
  style='font-size:7.0pt;line-height:107%;color:#856DF0'>Vieira et al., 2022</span></p>
  </td>
 </tr>
 <tr style='height:15.2pt'>
  <td width=92 valign=top style='width:69.05pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.2pt'>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
  line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Security</span></p>
  </td>
  <td width=156 valign=top style='width:117.05pt;border-top:none;border-left:
  none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
  padding:4.8pt 5.75pt 0in 6.15pt;height:15.2pt'>
  <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
  0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%;
  color:#856DF0'>Vieira et al., 2022</span></p>
  </td>
 </tr>
</table>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.1.4<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>AI for neurological disorder</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.55pt;
margin-left:-.75pt'><span style='color:#856DF0'>Zingoni et al. </span>(<span
style='color:#856DF0'>2021</span>) aimed to enhance accessibility and inclusion
for dyslexic students by creating a supportive platform that utilizes best
practices for educators and institutions to predict the most suitable
methodologies and digital tools for students with the goal of addressing the
challenges they face in their academic journeys.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.1.5<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>AI for motor impaired</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.5pt;
margin-left:-.75pt'><span style='color:#856DF0'>Cimolino et al. </span>(<span
style='color:#856DF0'>2021</span>) aimed to tackle the issue of inaccessibility
in gaming for people with disabilities, particularly those with spinal cord
injuries, by proposing a novel method called “partial automation” that enables
an AI partner to manage inaccessible game inputs to improve overall
accessibility in gaming.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.1.6<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>AI for other disabilities</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:24.75pt;
margin-left:-.75pt'>This section encompasses an array of innovative
applications that cater to people with other disabilities. <span
style='color:#856DF0'>Campomanes-Alvarez and Rosario Campomanes-Alvarez </span>(<span
style='color:#856DF0'>2021</span>) focused on individuals with profound
intellectual and multiple disabilities, devising the INSENSION platform to
recognize facial expressions, thereby enabling interaction with digital
applications and enhancing their quality of life. Second, <span
style='color:#856DF0'>Ingavelez-Guerra et al. </span>(<span style='color:#856DF0'>2022</span>)
implemented a multilevel methodological approach to automatically adapt open
educational resources within e-learning environments, considering the diverse
needs and preferences of students with various disabilities, including hearing
impairments, physical disabilities, intellectual and developmental
disabilities, visual impairments, and mental health issues. Third, <span
style='color:#856DF0'>Guo et al. </span>(<span style='color:#856DF0'>2021</span>)
presented a virtual human social system that empowered individuals with facial
disabilities, deafmutes, and autism to engage in face-to-face video
communication. Additionally, <span style='color:#856DF0'>Hezam et al. </span>(<span
style='color:#856DF0'>2023</span>) utilized a hybrid multi-criteria
decision-making method to prioritize digital technologies for enhancing
transportation accessibility for people with disabilities, addressing barriers,
and selecting technologies through an uncertain decision-making framework.
Furthermore, <span style='color:#856DF0'>Lu et al. </span>(<span
style='color:#856DF0'>2020</span>) aimed to aid people with disabilities in
operating tractors, ensuring safe operation when consciousness and limb
movements are inconsistent, whereas <span style='color:#856DF0'>Lin et al. </span>(<span
style='color:#856DF0'>2019</span>) focused on providing wheelchair-accessible
bus rides for people with disabilities. The INSENSION Platform for Personalized
Assistance of Non-symbolic Interaction for individuals with profound
intellectual and multiple disabilities (PIMD), developed by <span
style='color:#856DF0'>Kosiedowski et al. </span>(<span style='color:#856DF0'>2020</span>),
supports independence by recognizing non-symbolic behaviors and collecting
contextual information through video, audio, and sensor data. <span
style='color:#856DF0'>Park et al. </span>(<span style='color:#856DF0'>2021</span>)
proposed an online infrastructure to enable large-scale remote data
contributions from disability communities to create inclusive AI systems. These
diverse applications underscore the importance of tailored technological
solutions in promoting independence, accessibility, and improved quality of
life for people with disabilities, emphasizing the need for an inclusive design
and comprehensive consideration of user needs in the development of assistive
technologies.</p>

<h3 style='margin-left:27.8pt;text-indent:-28.55pt'><span style='line-height:
107%'>4.3.2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>(RQ
2) Dimension: methodology</h3>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.95pt;
margin-left:-.75pt'>The accessibility of digital systems for people with
disabilities can be enhanced by employing various AI techniques, which can be
classified into several domains including Machine Learning (ML), Deep Learning
(DL), Natural Language Processing (NLP), Edge AI, and Computer Vision.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.2.1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Computer vision</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>Several studies have demonstrated diverse applications of
computer vision in enhancing accessibility. <span style='color:#856DF0'>Balakrishnan
et al. </span>(<span style='color:#856DF0'>2023</span>) utilized object
recognition for identifying and predicting object types, employing techniques
such as object localization and detection. <span style='color:#856DF0'>Jayawardena
et al. </span>(<span style='color:#856DF0'>2019</span>) used computer vision
for object recognition and hand gesture/movement recognition in an educational
context. In addition, <span style='color:#856DF0'>Lo Valvo et al. </span>(<span
style='color:#856DF0'>2021</span>) employed Convolutional Neural Networks
(CNNs) for recognizing objects or buildings. <span style='color:#856DF0'>Royal
et al. </span>(<span style='color:#856DF0'>2023</span>) developed a real-time
object recognition and text extraction from images using deep learning
algorithms in combination with the Pytesseract OCR Engine. <span
style='color:#856DF0'>Chaitra et al. </span>(<span style='color:#856DF0'>2022</span>)
employed a pre-trained Caffe Object Detection method to facilitate the
text-to-signal processing feature summarizing the objects detected in the form
of an audio catalog.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.5pt;
margin-left:-.75pt;text-indent:0in'><span style='color:#856DF0'>Abdusalomov et
al. </span>(<span style='color:#856DF0'>2022</span>) employed AI techniques
such as fire, object, and text recognition, along with object mapping. <span
style='color:#856DF0'>Duarte et al. </span>(<span style='color:#856DF0'>2021</span>)
employed various AI methodologies including image recognition, text recognition
in images, semantic similarity measures between text descriptions and image
concepts, and language identification. <span style='color:#856DF0'>Saha et al. </span>(<span
style='color:#856DF0'>2019</span>) utilized AI techniques, including object
recognition, within the Landmark AI computer vision system, which employed a
smartphone camera to offer realtime information and identify and describe
landmarks and signs in the user’s surroundings.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.2.2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Natural language processing (NLP)</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.45pt;
margin-left:-.75pt'>NLP plays a critical role in making digital systems more
accessible. <span style='color:#856DF0'>Ingavelez-Guerra et al. </span>(<span
style='color:#856DF0'>2022</span>) transformed digital educational resources
using NLP for automatic speech recognition (ASR) to extract textual information
from videos. In addition, <span style='color:#856DF0'>Wadhwa et al. </span>(<span
style='color:#856DF0'>2021</span>) utilized NLP to preprocess raw image and
caption data, incorporating a pretrained CNN for image feature encoding and an
LSTM-based RNN for generating natural language descriptions. Google’s
speech-to-text recognition, which falls under NLP, was integrated to transcribe
and process the spoken language into text for analysis (<span style='color:
#856DF0'>Zaid alahmadi and Alsulami, 2020</span>). Furthermore, <span
style='color:#856DF0'>Joshi et al. </span>(<span style='color:#856DF0'>2020</span>)
implemented various NLP techniques including YOLO-v3 object detection, an
optical character recognizer, and a textto-speech module for generating audio
prompts. <span style='color:#856DF0'>Teófilo et al. </span>(<span
style='color:#856DF0'>2018</span>) combined AI techniques, including a
speech-to-text algorithm for Portuguese, a sentence prediction algorithm for
selecting the correct speech based on initial text, and a word correction
algorithm to ensure the converted words are valid in the Portuguese language. <span
style='color:#856DF0'>Harum et al. </span>(<span style='color:#856DF0'>2021</span>)
leveraged third party apps such as Google Cloud services, including the Cloud
Vision API for image-to-text conversion, the Cloud Translation API for
translating the converted text, and Google Cloud Text-to-Speech for converting
the translated text into speech.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.2.3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Edge AI</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.45pt;
margin-left:-.75pt'>The system proposed by <span style='color:#856DF0'>Yang et
al. </span>(<span style='color:#856DF0'>2022</span>) showcased the utilization
of Edge AI in a cost-effective manner. The combination of Edge AI and computer
vision enabled the system to employ one-stage detectors and 2-D human pose
estimation for non-motorized users, emphasizing the importance of edge computing
in efficient real-time processing of data. Additionally, the SINAPSI device in <span
style='color:#856DF0'>Lucibello and Rotondi </span>(<span style='color:#856DF0'>2019</span>)
employed Edge AI, utilizing ultrasonic sensors and machine learning algorithms
for 3D environmental awareness, demonstrating its application in innovative
environmental awareness solutions.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.2.4<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Machine learning</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:10.2pt;
margin-left:-.75pt'>Various studies have employed machine learning techniques
to address accessibility challenges. For instance, <span style='color:#856DF0'>Ullah
et al. </span>(<span style='color:#856DF0'>2023</span>) utilized KNN, decision
trees, random forest, and neural networks to decipher sign languages,
underscoring the versatility of machine learning in linguistic contexts. A
range of machine learning techniques, including Naïve Bayes, K-Nearest
Neighbor, Stochastic Gradient Descent, Logistic Regression, Neural Networks,
and Random Forest, have been used to classify facial expressions and jaw
movements (<span style='color:#856DF0'>Campomanes-Alvarez and Rosario
Campomanes-Alvarez, 2021</span>). <span style='color:#856DF0'>Zingoni et al. </span>(<span
style='color:#856DF0'>2021</span>) primarily employed machine learning
techniques, starting with supervised ML algorithms, to predict appropriate
supporting materials for dyslexic students based on questionnaire and clinical
report data, with a potential transition to deep learning methods for more
complex data processing. The Speech Recognition Engine in <span
style='color:#856DF0'>Jayawardena et al. </span>(<span style='color:#856DF0'>2019</span>)
utilized ML to recognize a user’s voice commands, demonstrating the
adaptability of machine learning across diverse applications.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.2.5<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Deep learning</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>The utilization of deep-learning methodologies has been
prevalent in several studies, including <span style='color:#856DF0'>Royal et
al. </span>(<span style='color:#856DF0'>2023</span>), which facilitated
real-time object recognition and text extraction using deep-learning
algorithms. <span style='color:#856DF0'>Li et al. </span>(<span
style='color:#856DF0'>2022</span>) used a visual-tactile fusion classification
model, which is a multimodal deep learning model that combines visual and
tactile information to classify objects, and three attention mechanisms, namely
temporal, channel-wise, and spatial attention, which are used to improve the
accuracy of the classification model. <span style='color:#856DF0'>See and
Advincula </span>(<span style='color:#856DF0'>2021</span>) utilized a model
based on the Mask RCNN model trained using the common objects with context
(COCO) dataset with a backbone of ResNet-50.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'><span style='color:#856DF0'>Rajasekhar and Panday </span>(<span
style='color:#856DF0'>2022</span>) implemented a 1D CNN as the deep learning
model in an ASL gesture interpreter, while <span style='color:#856DF0'>Thomas
and Meehan </span>(<span style='color:#856DF0'>2021</span>) employed a CNN to
implement object detection in a banknote recognition system.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:10.1pt;
margin-left:-.75pt'><span style='color:#856DF0'>Zingoni et al. </span>(<span
style='color:#856DF0'>2021</span>) primarily employed machine learning
techniques, starting with supervised ML algorithms with a potential transition
to deep learning methods for more complex data processing. <span
style='color:#856DF0'>Kosiedowski et al. </span>(<span style='color:#856DF0'>2020</span>)
harnessed video and audio analysis, pattern recognition, and deep-learning
techniques to recognize various aspects of users with Profound and Multiple
Intellectual Disabilities. The integration of YOLOv3, a real-time image
recognition model, by <span style='color:#856DF0'>Lin et al. </span>(<span
style='color:#856DF0'>2019</span>) highlighted the effective use of deep
learning for image recognition and notification. <span style='color:#856DF0'>Yang
et al. </span>(<span style='color:#856DF0'>2023</span>) utilized
spectrogram-based feature extraction with pre-trained neural networks, k-fold
crossvalidation, and an ensemble model involving AlexNet, ReliefF, and an SVM
classifier to enhance speech recognition accuracy. <span style='color:#856DF0'>Abdusalomov
et al. </span>(<span style='color:#856DF0'>2022</span>) utilized the YOLOv5m
model for realtime monitoring and enhanced the detection accuracy of indoor
fire disasters. In their study, <span style='color:#856DF0'>Sreemathy et al. </span>(<span
style='color:#856DF0'>2022</span>) utilized four distinct deep learning models,
namely, AlexNet, GoogleNet, VGG-16, and VGG-19 and Histogram Oriented Gradient
(HOG) features for feature extraction for the automatic recognition of
two-handed signs of Indian Sign Language. <span style='color:#856DF0'>Montanha
et al. </span>(<span style='color:#856DF0'>2022</span>) employed a signal
trilateration technique complemented by deep learning (DL) for image
processing. <span style='color:#856DF0'>Montanha et al. </span>(<span
style='color:#856DF0'>2022</span>) also leveraged a pre-trained deep neural
network model from the open-source toolkit OpenVINO2 (Open Visual Inference and
Neural Network Optimization) by Intel. <span style='color:#856DF0'>CampomanesAlvarez
and Rosario Campomanes-Alvarez </span>(<span style='color:#856DF0'>2021</span>)
employed Long-Short Term Memory (LSTM) Neural Networks for jaw movement
classification. <span style='color:#856DF0'>Wadhwa et al. </span>(<span
style='color:#856DF0'>2021</span>) employed AI techniques involving
preprocessing of raw image and caption data, using a pretrained Convolutional
Neural Network (CNN) for encoding image features into high-dimensional vectors,
and subsequently utilizing a Long Short-Term Memory (LSTM) based Recurrent
Neural Network (RNN) for decoding and generating natural language descriptions.
<span style='color:#856DF0'>Lo Valvo et al. </span>(<span style='color:#856DF0'>2021</span>)
utilized Convolutional Neural Networks (CNNs) that have been trained to
recognize objects or buildings. <span style='color:#856DF0'>Guo et al. </span>(<span
style='color:#856DF0'>2021</span>) leveraged deep-learning technology for
facial restoration, incorporated affective computing for emotion recognition,
and employed these elements in the design of virtual avatars. <span
style='color:#856DF0'>Karyono et al. </span>(<span style='color:#856DF0'>2020</span>)
utilized artificial neural networks in their adaptive lighting system which
considers behavioral adaptation aspects for visually impaired people. <span
style='color:#856DF0'>Lu et al. </span>(<span style='color:#856DF0'>2020</span>)
employed a tractor driving control method that combined EEG-based input with a
recurrent neural network with transfer learning (RNN-TL) deep learning
algorithm.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.2.6<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>More AI methodologies</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'><span style='color:#856DF0'>Ingavelez-Guerra et al. </span>(<span
style='color:#856DF0'>2022</span>) utilized various AI techniques to adapt
digital educational resources for the diverse needs of learners. It employs
automatic speech recognition (ASR) to extract textual information from videos,
thereby making the text more readable. In addition, the system leverages
convolutional neural networks (CNNs) and recurrent neural networks (RNNs) for
image classification and description. Furthermore, it utilized long short-term
memory neural networks (LSTM NNs) from the Tesseract OCR library for text
recognition. Natural language processing (NLP) has also been applied to aid in
describing images using nearby text. <span style='color:#856DF0'>Li et al. </span>(<span
style='color:#856DF0'>2022</span>) introduced a visualtactile fusion
classification model, a multimodal deep learning approach that combined visual
and tactile information for improved object classification. <span
style='color:#856DF0'>Cimolino et al. </span>(<span style='color:#856DF0'>2021</span>)
applied AI techniques utilizing the Unity game engine along with the Behavior
Designer plugin. The system developed by <span style='color:#856DF0'>Kose and
Vasant </span>(<span style='color:#856DF0'>2020</span>) employs various AI
techniques, including optimization-based AI techniques, such as the Dijkstra
algorithm, ant colony optimization, intelligent water drop algorithm, and
speech recognition interface. <span style='color:#856DF0'>Watters et al. </span>(<span
style='color:#856DF0'>2020</span>) integrated an Alexa smart speaker and custom
Alexa Skill for natural language interaction, a Talking LabQuest with AI for
data collection and analysis, and a Raspberry Pi for coordination, effectively
combining AI techniques with components to create a virtual AI lab assistant
for enhanced laboratory assistance. In a study by <span style='color:#856DF0'>Lin
et al. </span>(<span style='color:#856DF0'>2019</span>), machine learning and
deep learning techniques, particularly neural networks, were harnessed for
image recognition using YOLOv3, a real-time image recognition model, for object
recognition and notification. In addition, chatbot technology was implemented
using the LINE platform, demonstrating the integration of AI methodologies in
both image recognition and chatbot development. <span style='color:#856DF0'>Alashkar
et al. </span>(<span style='color:#856DF0'>2020</span>) employed a modern
Convolutional Neural Network (CNN) named Mini Xception for facial features
recognition, utilized the K-Nearest Neighbors (K-NN) algorithm for color
recognition, and provided sound feedback using the IBM Watson Text to Speech
API. These studies demonstrated the potential of combining deep learning with
other techniques to develop more robust and adaptive systems that cater to
diverse user requirements.</p>

<h3 style='margin-left:27.8pt;text-indent:-28.55pt'><span style='line-height:
107%'>4.3.3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>(RQ
3) Dimension: challenges</h3>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.45pt;
margin-left:-.75pt'>A multitude of challenges confront efforts to enhance
accessibility for people with disabilities by introducing barriers that may
lead to exclusion and marginalization. Understanding and categorizing the
various factors that influence the adoption of AI can aid stakeholders in
devising specialized approaches to overcome the multifaceted challenges
associated with its implementation. These challenges span various aspects, each
of which requires careful consideration for successful implementation of accessible
technologies.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.3.1<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>General accessibility and usability challenges</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.45pt;
margin-left:-.75pt'>System complexity and lack of user friendliness can create
difficulties for people with various disabilities, hindering their ability to
use and benefit from technology. Implementation barriers, such as cost, lack of
technical support, and insufficient awareness and training among users and
caregivers, affect the overall accessibility and usability of AI systems (<span
style='color:#856DF0'>Lu et al., 2020</span>; <span style='color:#856DF0'>Cimolino
et al., 2021</span>; <span style='color:#856DF0'>Theodorou et al., 2021</span>).</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.3.2<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Data challenges</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:11.45pt;
margin-left:-.75pt'>The incorporation of AI into digital accessibility systems
has resulted in several data challenges. These challenges encompass matters
pertaining to the inadequacy and questionable quality of data, along with
apprehensions regarding data privacy, surveillance, administration, and the
potential for bias and discrimination in the utilization of data within AI
systems. The limited availability of training data, with people with disability
comprising only 0.5–3% of the total user population, presents a significant
challenge in achieving high levels of accuracy in speech recognition technology
(<span style='color:#856DF0'>Yang et al., 2022</span>). <span style='color:
#856DF0'>Li et al. </span>(<span style='color:#856DF0'>2022</span>) faced
challenges in accurate tactile data acquisition for wearable devices, handling
heterogeneous data from tactile and visual sensors. In their investigation, <span
style='color:#856DF0'>Zaid alahmadi and Alsulami </span>(<span
style='color:#856DF0'>2020</span>) encountered biases in the data, as the
evaluation results of the prototype may have been influenced by the
participation of only female participants, which overlooked the gender
diversity present in Saudi Arabian universities. Additionally, <span
style='color:#856DF0'>Lu et al. </span>(<span style='color:#856DF0'>2020</span>)
encountered limitations in obtaining a comprehensive dataset because of
constraints such as site-specific conditions, environmental variables, and
tractor operating factors. Furthermore, maintaining consistency in virtual
datasets is problematic, requiring ongoing algorithm adjustments (<span
style='color:#856DF0'>Lu et al., 2020</span>). <span style='color:#856DF0'>Acosta-Vargas
et al. </span>(<span style='color:#856DF0'>2022</span>) emphasized the
importance of inclusive data collection processes, acknowledging the varying
challenges faced by participants of different types and prominence of
disabilities. This includes physical disabilities affecting phone usage,
blindness posing challenges in photography tasks, considerations for cultural
aspects and sign language fluency for deaf participants. These challenges
highlight the need for innovative solutions and strategies to address the issue
of data scarcity for specific user groups.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.3.3<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Security and privacy challenges</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.25pt;
margin-left:-.75pt'>Considering the privacy and security challenges associated
with integrating assistive technologies, several issues have been noted in
various studies. The accurate acquisition of tactile data for wearable devices
raises privacy and security concerns, particularly related to webcam usage (<span
style='color:#856DF0'>Li et al., 2022</span>). Similarly, the development of
digitally accessible games introduced ethical dilemmas, encompassing issues of
player autonomy, privacy, and potential unintended consequences tied to partial
automation. Privacy and security concerns were also integral to the challenges
faced in designing an indoor navigation system (<span style='color:#856DF0'>Lo
Valvo et al., 2021</span>) and developing the avatar-to-person system (<span
style='color:#856DF0'>Guo et al., 2021</span>), emphasizing the necessity for
technical expertise in AI and 3D modeling. The study conducted by <span
style='color:#856DF0'>Zaid alahmadi and Alsulami </span>(<span
style='color:#856DF0'>2020</span>) faced challenges linked to the need to
navigate privacy concerns, especially given the impact of including only female
participants. Involving people with disabilities in data collection processes
underscores the significance of inclusive practices, recognizing diverse
accessibility challenges and implicitly emphasizing the importance of
safeguarding privacy (<span style='color:#856DF0'>AcostaVargas et al., 2022</span>).
These challenges collectively highlight the multifaceted nature of integrating
assistive technologies and the imperative to address privacy and security
across various domains.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.3.4<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Challenges of visually impaired</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.35pt;
margin-left:-.75pt'><span style='color:#856DF0'>Karyono et al. </span>(<span
style='color:#856DF0'>2020</span>) drew attention to the deficiency of a
dependable predictive lighting model for visually impaired and elderly
individuals, the scarcity of implementation of lighting standards, and
potential barriers such as system cost and insufficient awareness. Similarly, <span
style='color:#856DF0'>Jayawardena et al. </span>(<span style='color:#856DF0'>2019</span>)
emphasized the challenges in enhancing the lives of visually impaired children,
including the dearth of research studies, limited resources and funding, and
the requirement for user-friendly, affordable systems in developing countries.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.3.5<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Challenges of hearing impaired</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.4pt;
margin-left:-.75pt'>The challenges faced by <span style='color:#856DF0'>Teófilo
et al. </span>(<span style='color:#856DF0'>2018</span>) include technical setup
issues affecting user experience, accuracy of captioning for users with hearing
impairments, and usability factors such as head and eye strain, brightness, and
device weight.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.3.6<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Challenges faced by those with motor disabilities</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.4pt;
margin-left:-.75pt'><span style='color:#856DF0'>Li et al. </span>(<span
style='color:#856DF0'>2022</span>) presented several challenges in the
acquisition of accurate tactile data for wearable devices, including the
handling of heterogeneous data and concerns related to privacy and security,
which can impact users with varying motor abilities. Additionally, <span
style='color:#856DF0'>Cimolino et al. </span>(<span style='color:#856DF0'>2021</span>)
highlighted challenges in the development of digitally accessible games,
particularly in interpreting the intentions of players with diverse motor
abilities and designing interfaces for partial automation.</p>

<h4 style='margin-left:-.25pt'><span style='line-height:107%'>4.3.3.7<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Challenges faced by those with cognitive disabilities</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:9.4pt;
margin-left:-.75pt'><span style='color:#856DF0'>Park et al. </span>(<span
style='color:#856DF0'>2021</span>) involved people with disabilities and
highlighted the challenges faced by those with cognitive disabilities, such as
difficulties with reading and typing tasks, including people with attention
deficit hyperactivity disorder (ADHD) and dyslexia.</p>

<h4 style='margin-left:31.15pt;text-indent:-31.9pt'><span style='line-height:
107%'>4.3.3.8<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;
</span></span>Other challenges</h4>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:22.6pt;
margin-left:-.75pt'>Other challenges include the lack of resources and funding
for the research and development of systems that enhance accessibility (<span
style='color:#856DF0'>Jayawardena et al., 2019</span>). <span style='color:
#856DF0'>Lo Valvo et al. </span>(<span style='color:#856DF0'>2021</span>) faced
challenges related to physical infrastructure adaptation, 3D object
registration, and accessibility design. <span style='color:#856DF0'>Guo et al. </span>(<span
style='color:#856DF0'>2021</span>) identified challenges related to
psychological barriers, accessibility issues, the need for technical expertise
in relevant areas, and the importance of user acceptance and adoption
influenced by factors such as ease of use and perceived usefulness.</p>

<h3 style='margin-left:27.8pt;text-indent:-28.55pt'><span style='line-height:
107%'>4.3.4<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>(RQ
4) Dimension: frameworks</h3>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>Various frameworks and accessibility standards have been
employed in AI-based research endeavors aimed at enhancing digital
accessibility for people with disabilities. One notable framework is the
“Framework for value co-design and co-creation” (<span style='color:#856DF0'>Vieira
et al., 2022</span>), which centers on the impact of Virtual Assistants (VAs)
on the wellbeing of people with disabilities. This framework emphasizes the
co-creation of value through interactions between people with disabilities and
VA technology within their home environments.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>Additionally, addressing the adaptability and accessibility
of Open Educational Resources (OER), the need for new metadata aligned with
Universal Design for Learning guidelines is highlighted (<span
style='color:#856DF0'>Ingavelez-Guerra et al., 2022</span>). <span
style='color:#856DF0'>Cimolino et al. </span>(<span style='color:#856DF0'>2021</span>)
explored the improvement in game accessibility by utilizing multiple
frameworks, including universal design, player balancing, and interface
adaptation. Within this context, universal design focuses on the creation of
products and environments that cater to a broad spectrum of individuals
irrespective of their abilities.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>In the domain of e-commerce website accessibility, <span
style='color:#856DF0'>AcostaVargas et al. </span>(<span style='color:#856DF0'>2022</span>)
predominantly relied on the Web Content Accessibility Guidelines (WCAG) 2.1,
employing a modified approach to the Website Accessibility Conformance
Evaluation Methodology (WCAG-EM) 1.0, for automated evaluations using the Web
Accessibility Evaluation Tool (WAVE) to identify potential WCAG 2.1-related
accessibility concerns. Furthermore, <span style='color:#856DF0'>See and
Advincula </span>(<span style='color:#856DF0'>2021</span>) evaluated system
usability through the ISO/IEC 25010:2011 SQuaRE quality models, which encompass
factors such as appropriateness, recognizability, learnability, operability,
user error protection, user interface aesthetics, and accessibility.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>The Digital Accessible Information System (DAISY) standard
allows for utmost flexibility in integrating text and audio, accommodating
various combinations ranging from pure audio, text-only, full text, to full
audio integration.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'><span style='color:#856DF0'>Karyono et al. </span>(<span
style='color:#856DF0'>2020</span>) employed various accessibility standards,
including CIE 1,231:1997 for addressing lighting needs of partially sighted
individuals, CIE 196:2011 for enhancing accessibility in lighting, and CIE
227:2017 for lighting considerations in buildings for older individuals and
those with visual impairments.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>In their study, <span style='color:#856DF0'>Hezam et al. </span>(<span
style='color:#856DF0'>2023</span>) harnessed a decisionmaking framework
grounded in Fermatean fuzzy information, incorporating AI methodologies from
the field of expert systems, to comprehensively evaluate the suitability of
digital technologies within the realm of sustainable transportation for people
with disabilities.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'><span style='color:#856DF0'>Yeratziotis and Van Greunen </span>(<span
style='color:#856DF0'>2013</span>) outlined guidelines for deaf and hard of
hearing-friendly mobile app design, drawing from sources like telecom
accessibility guidelines and industry practices (e.g., Apple, Samsung, and
Google) which were used to guide the system developed in <span
style='color:#856DF0'>Zaid alahmadi and Alsulami </span>(<span
style='color:#856DF0'>2020</span>).</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:13.95pt;text-indent:0in'><span style='color:#856DF0'>Table 7 </span>shows
the results of the classification framework.</p>

<table class=TableGrid border=0 cellspacing=0 cellpadding=0 align=left
 width=662 style='width:496.5pt;border-collapse:collapse;margin-left:-2.25pt;
 margin-right:-2.25pt'>
 <tr style='height:7.4pt'>
  <td width=343 valign=top style='width:256.9pt;padding:.5pt 0in 0in 0in;
  height:7.4pt'>
  <p class=MsoNormal style='margin:0in;text-indent:0in;line-height:107%'><span
  style='font-size:7.0pt;line-height:107%;color:#7D7F7F'>TABLE 7 </span><span
  style='font-size:7.0pt;line-height:107%;color:#6E6E6E'>Mapping the
  classification framework across the different disabilities.</span></p>
  <table class=TableGrid border=0 cellspacing=0 cellpadding=0 width=662
   style='width:496.2pt;margin-left:.3pt;border-collapse:collapse'>
   <tr style='height:34.55pt'>
    <td width=111 valign=top style='width:83.2pt;border-top:#A6B0A8;border-left:
    #A6B0A8;border-bottom:#A2A2A2;border-right:#A2A2A2;border-style:solid;
    border-width:1.0pt;background:#8F9496;padding:5.2pt 3.1pt 0in 6.15pt;
    height:34.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:solid #A6B0A8 1.0pt;
    border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    background:#8F9496;padding:5.2pt 3.1pt 0in 6.15pt;height:34.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:1.6pt;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='color:white'>Visual impairment</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:solid #A6B0A8 1.0pt;
    border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    background:#8F9496;padding:5.2pt 3.1pt 0in 6.15pt;height:34.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='color:white'>Speech and hearing impairment</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:solid #A6B0A8 1.0pt;
    border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    background:#8F9496;padding:5.2pt 3.1pt 0in 6.15pt;height:34.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='color:white'>Autism spectrum disorder (ASD)</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:solid #A6B0A8 1.0pt;
    border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    background:#8F9496;padding:5.2pt 3.1pt 0in 6.15pt;height:34.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='color:white'>Neurological disorders</span></p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:solid #A6B0A8 1.0pt;
    border-left:none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    background:#8F9496;padding:5.2pt 3.1pt 0in 6.15pt;height:34.55pt'>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='color:white'>Motor impairment</span></p>
    </td>
   </tr>
   <tr style='height:15.55pt'>
    <td width=111 rowspan=2 valign=top style='width:83.2pt;border-top:none;
    border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;
    border-right:solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;height:
    15.55pt'>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>AI
    methodologies</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Edge AI</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
   </tr>
   <tr style='height:44.25pt'>
    <td width=111 valign=top style='width:83.2pt;border:none;border-bottom:
    solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;height:44.25pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=333 colspan=3 valign=top style='width:249.65pt;border:none;
    border-bottom:solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;
    height:44.25pt'>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:.4pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Computer
    vision</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:.4pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Machine
    learning</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:.35pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Deep
    learning</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:0in;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>NLP</span></p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:44.25pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
   </tr>
   <tr style='height:35.65pt'>
    <td width=111 rowspan=3 valign=top style='width:83.2pt;border-top:none;
    border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;
    border-right:solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;height:
    35.65pt'>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>AI</span></p>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>accessibility/standard/</span></p>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>framework</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border:none;border-bottom:
    solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;height:35.65pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=333 colspan=3 valign=top style='width:249.65pt;border:none;
    border-bottom:solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;
    height:35.65pt'>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:1.3pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Framework
    for value co-design and co-creation</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:.35pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Web
    Content Accessibility Guidelines (WCAG) 2.1</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:0in;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Universal
    Design</span></p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:35.65pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
   </tr>
   <tr style='height:51.3pt'>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:51.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:51.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Guidelines
    for designing mobile apps for people who are deaf or hard of hearing (</span><span
    style='font-size:7.0pt;line-height:107%;color:#856DF0'>Yeratziotis and Van
    Greunen, 2013</span><span style='font-size:7.0pt;line-height:107%'>)</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:51.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:51.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:51.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
   </tr>
   <tr style='height:87.3pt'>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:87.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:2.45pt;
    margin-bottom:0in;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Digital Accessible</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Information
    System</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.6pt;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>(DAISY)
    Standard</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:2.45pt;
    margin-bottom:0in;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:105%'><span style='font-size:7.0pt;line-height:105%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:105%'>Low Vision—Lighting needs for the
    partially sighted: CIE</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>1,231,997;
    CIE</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>196:2011;</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>CIE
    227:2017</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:87.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:87.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:87.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:87.3pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
   </tr>
   <tr style='height:44.25pt'>
    <td width=111 rowspan=2 valign=top style='width:83.2pt;border-top:none;
    border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A2A2A2 1.0pt;
    border-right:solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;height:
    44.25pt'>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Challenges</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border:none;border-bottom:
    solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;height:44.25pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=333 colspan=3 valign=top style='width:249.65pt;border:none;
    border-bottom:solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;
    height:44.25pt'>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:.35pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Data
    challenges</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:.4pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Technical
    issues</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:.4pt;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Operational
    challenges</span></p>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.05pt;
    margin-bottom:0in;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Knowledge
    and awareness</span></p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:44.25pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
   </tr>
   <tr style='height:15.55pt'>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Security
    and privacy</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Security
    and privacy</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.55pt'>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Security
    and privacy</span></p>
    </td>
   </tr>
   <tr style='height:132.1pt'>
    <td width=111 rowspan=2 valign=top style='width:83.2pt;border-top:none;
    border-left:solid #A6B0A8 1.0pt;border-bottom:solid #A6B0A8 1.0pt;
    border-right:solid #A2A2A2 1.0pt;padding:5.2pt 3.1pt 0in 6.15pt;height:
    132.1pt'>
    <p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
    0in;line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Applications</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:132.1pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.85pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Artificial vision</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.8pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Navigation</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.85pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Virtual Assistant</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.9pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Fire Safety</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.75pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Road Safety</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.8pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:106%'><span style='font-size:7.0pt;line-height:106%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:106%'>Educational Material Generation</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.75pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Social Media accessibility</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.7pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Bank Note Recognition</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.75pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Lighting system</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.7pt;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Walking path support</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.05pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Image captioning</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:132.1pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.7pt;margin-left:7.0pt;text-align:left;text-indent:-6.95pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Speech recognition</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.7pt;margin-left:7.0pt;text-align:left;text-indent:-6.95pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Voice reproduction</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.75pt;margin-left:7.0pt;text-align:left;text-indent:-6.95pt;
    line-height:106%'><span style='font-size:7.0pt;line-height:106%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:106%'>Communicating with smart devices</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.8pt;margin-left:7.0pt;text-align:left;text-indent:-6.95pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Video transcription</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:-6.95pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Harness VR</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:105%'><span style='font-size:7.0pt;line-height:105%'>technology
    for communication</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>during</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>theatrical
    performance</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:132.1pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Learning
    to code</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:132.1pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:.05pt;text-align:left;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Accessibility
    in learning</span></p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A2A2A2 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:132.1pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.75pt;margin-left:7.0pt;text-align:left;text-indent:-7.0pt;
    line-height:106%'><span style='font-size:7.0pt;line-height:106%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:106%'>Enhance digital games
    accessibility</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:.9pt;margin-left:7.0pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Accessible bus rides</span></p>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:0in;margin-left:7.0pt;text-align:left;text-indent:-7.0pt;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>•<span
    style='font:7.0pt "Times New Roman"'>&nbsp; </span></span><span
    style='font-size:7.0pt;line-height:107%'>Traffic signal assistance</span></p>
    </td>
   </tr>
   <tr style='height:15.5pt'>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.5pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=222 colspan=2 valign=top style='width:166.45pt;border-top:none;
    border-left:none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.5pt'>
    <p class=MsoNormal align=center style='margin-top:0in;margin-right:3.0pt;
    margin-bottom:0in;margin-left:0in;text-align:center;text-indent:0in;
    line-height:107%'><span style='font-size:7.0pt;line-height:107%'>Sign
    language recognition</span></p>
    </td>
    <td width=111 valign=top style='width:83.2pt;border-top:none;border-left:
    none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A2A2A2 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.5pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
    <td width=107 valign=top style='width:80.15pt;border-top:none;border-left:
    none;border-bottom:solid #A6B0A8 1.0pt;border-right:solid #A6B0A8 1.0pt;
    padding:5.2pt 3.1pt 0in 6.15pt;height:15.5pt'>
    <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
    margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
    line-height:107%'>&nbsp;</p>
    </td>
   </tr>
  </table>
  <p class=MsoNormal align=left style='margin-top:0in;margin-right:0in;
  margin-bottom:8.0pt;margin-left:0in;text-align:left;text-indent:0in;
  line-height:107%'></p>
  </td>
 </tr>
</table>

<h2 style='margin-left:.5pt'>4.4<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span>Research implications, limitations, and future directions</h2>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>Most research in the field of AI-driven digital
accessibility has primarily focused on addressing the needs of people with
visual impairment. This emphasis on AI solutions related to visual impairment
is evident from the multitude of innovations and systems designed to enhance
the lives of the visually impaired. These include a wide range of applications,
from real-time obstacle detection and object recognition to tactile educational
materials, and even AI-driven smart glasses. The impact of AI on digital accessibility
for the visually impaired has been profound, leading to improved mobility,
safety, and educational opportunities (<span style='color:#856DF0'>Lo Valvo et
al., 2021</span>; <span style='color:#856DF0'>See and Advincula, 2021</span>; <span
style='color:#856DF0'>Abdusalomov et al., 2022</span>). However, this
concentration of visual impairments has highlighted a significant gap in the
research landscape. There is a paucity of comprehensive AI systems tailored to
address the unique challenges faced by people with other disabilities such as
speech and hearing impairments, autism spectrum disorder (ASD), neurological
disorders, and motor impairments. While there are some noteworthy AI solutions
for these other disability types (<span style='color:#856DF0'>Zingoni et al.,
2021</span>; <span style='color:#856DF0'>Ullah et al., 2023</span>), the sheer
volume of research and innovation predominantly dedicated to visual impairment
underscores the need for a more equitable distribution of research efforts. It
is crucial to expand the scope of AI-driven digital accessibility to bridge
this gap and provide people with various disabilities with the same level of
support, independence, and accessibility that the visually impaired enjoy. This
will require concerted effort to foster innovation and research in AI systems
tailored to the specific needs of these communities. Our research highlights
the urgent need for a fundamental shift in the design and development of
systems catering to people with disabilities.</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>To address these shortcomings, the research agenda must
prioritize a 2-fold approach. First, researchers must realign their efforts
toward a more comprehensive examination of disabilities, ensuring that the
unique challenges faced by people with diverse impairments are adequately
considered. Second, it is imperative to augment data-collection efforts
involving people with disabilities to capture a broader range of experiences
and requirements. This inclusive approach not only enhances the inclusivity of
technological solutions but also provides a more robust and informed foundation
for future research and development in the field. A more focused effort is
necessary to comprehend how the information requirements of people with
disabilities can vary across different contexts, cultures, and audiences and
how their needs are context-dependent (<span style='color:#856DF0'>Akter et
al., 2022</span>). Future research should explore this aspect to enhance the
AI-driven accessibility. <span style='color:#856DF0'>Park et al. </span>(<span
style='color:#856DF0'>2021</span>) suggested that motivating people with
disabilities for AI data collection should involve fair monetary compensation,
nonmonetary incentives, and transparent communication regarding data use and
privacy. To ensure accessibility, the data collection process should be
streamlined and consider the diverse range of abilities within disability
categories, avoid punitive measures, and acknowledge potential performance
anxiety among people with disabilities. Future research should prioritize
algorithmic accountability, transparency, and explainability in the development
of assistive technologies (<span style='color:#856DF0'>Akter et al., 2022</span>).
This approach ensures that users can better understand and trust the
functioning of AIdriven systems, thereby contributing to their overall
effectiveness and acceptance. Maintaining the confidentiality and privacy of
the collected data is crucial, especially when the data are publicly available
to promote large-scale machine learning advancements (<span style='color:#856DF0'>Li
et al., 2022</span>). It is essential to extend the reach of the infrastructure
to individuals beyond WEIRD societies, who may use different platforms, devices
with lower specifications, or have limited access to broadband, and to support
cultural adaptations in the data collection process (<span style='color:#856DF0'>Li
et al., 2022</span>).</p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:22.6pt;
margin-left:-.75pt'>Although every effort has been made to ensure the
comprehensiveness of the present research, it is possible that some significant
studies may have been overlooked because of the vast number of results
retrieved from one of the databases.</p>

<h1 style='margin-left:13.7pt;text-indent:-14.45pt'><span style='line-height:
107%'>5<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp; </span></span>Conclusion</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:18.45pt;
margin-left:-.75pt'>The significance of access to the Internet and digital
content has intensified in recent times; however, not all individuals,
particularly those with disabilities, have equitable access to this technology.
By employing a thorough review and evaluation using a classification framework,
this research specifically focuses on the impact of AI on digital accessibility
in the context of disability. The most prevalent AI methodologies utilized are
edge AI, NLP, Computer Vision, machine learning, and deep learning. The most
common challenges encountered were related to data, technical difficulties,
security and privacy concerns, and operational difficulties. The findings
reveal a prevalent focus on AI-driven digital accessibility for people with
visual impairments, indicating a substantial gap in addressing other
disabilities. This research underscores the imperative need to realign efforts
toward a more comprehensive examination of disabilities, urging researchers to
broaden their scope and enhance data collection efforts involving people with
various disabilities. The shortcomings of existing systems regarding adherence
to accessibility standards highlight the pressing need for a fundamental shift
in the design of solutions that prioritize the needs of people with
disabilities. The study underscores the critical role of accessible AI in
preventing exclusion and discrimination and emphasizes the urgency for a
comprehensive approach to digital accessibility that accommodates diverse
disability needs. As we move forward into the digital age, where Internet
access is increasingly integral to education, entertainment, and communication,
organizations are encouraged to prioritize and invest in digital accessibility.
By adhering to established guidelines and standards, organizations can bridge
the digital divide and ensure a fair and enjoyable online experience for all
users regardless of their abilities. This not only promotes equal opportunities
for individuals with disabilities, but also enhances overall usability and satisfaction
for all users. Ultimately, this research calls for a concerted effort to make
digital accessibility a cornerstone of our digital landscape, fostering an
inclusive environment that benefits the entire user spectrum.</p>

<h1 style='margin-left:-.25pt;text-indent:0in'>Data availability statement</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:18.5pt;
margin-left:-.75pt'>The raw data supporting the conclusions of this article
will be made available by the authors, without undue reservation.</p>

<h1 style='margin-left:-.25pt;text-indent:0in'>Author contributions</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:18.45pt;
margin-left:-.75pt'>KC: Data curation, Investigation, Methodology, Resources,
Software, Visualization, Writing – original draft, Writing – review &amp;
editing. AO: Conceptualization, Methodology, Project administration,
Supervision, Validation, Writing – original draft, Writing – review &amp;
editing.</p>

<h1 style='margin-left:-.25pt;text-indent:0in'>Funding</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:18.5pt;
margin-left:-.75pt'>The author(s) declare that no financial support was
received for the research, authorship, and/or publication of this article.</p>

<h1 style='margin-left:-.25pt;text-indent:0in'>Conflict of interest</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:18.5pt;
margin-left:-.75pt'>The authors declare that the research was conducted in the
absence of any commercial or financial relationships that could be construed as
a potential conflict of interest.</p>

<h1 style='margin-left:-.25pt;text-indent:0in'>Publisher’s note</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.2pt;
margin-left:-.75pt'>All claims expressed in this article are solely those of
the authors and do not necessarily represent those of their affiliated
organizations, or those of the publisher, the editors and the reviewers. Any
product that may be evaluated in this article, or claim that may be made by its
manufacturer, is not guaranteed or endorsed by the publisher.</p>

</div>

<span style='font-size:9.0pt;line-height:112%;font-family:"Calibri",sans-serif;
color:#282828'><br clear=all style='page-break-before:auto'>
</span>

<div class=WordSection7>

<h1 style='margin-left:-.25pt;text-indent:0in'>References</h1>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.3pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Abduljabbar, R., Dia, H., Liyanage, S., and
Bagloee, S. A. (2019). Applications of artificial intelligence in transport: an
overview. </span><i><span style='font-size:7.0pt;line-height:97%;font-family:
"Times New Roman",serif;color:black'>Sustainability </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>11:189.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:0in;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>doi: </span><a
href="https://doi.org/10.3390/su11010189"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3390/su11010189</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Abdusalomov, A. B., Mukhiddinov, M.,
Kutlimuratov, A., and Whangbo, T. K. (2022). Improved real-time fire warning
system based on advanced technologies for visually impaired people. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Sensors </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>22:197305. doi: </span><a href="https://doi.org/10.3390/s22197305"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.3390/s22197305</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:5.6pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Abiodun, O. I., Jantan, A., Omolara, A. E.,
Dada, K. V., Umar, A. M., Linus, O. U., et al. (2019). Comprehensive review of
artificial neural network applications </span><a
href="https://doi.org/10.1109/ACCESS.2019.2945545"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>to pattern recognition.</span></a><span
style='font-size:7.0pt;line-height:97%;color:black'> </span><a
href="https://doi.org/10.1109/ACCESS.2019.2945545"><i><span style='font-size:
7.0pt;line-height:97%;font-family:"Times New Roman",serif;color:black;
text-decoration:none'>IEEE Access</span></i></a><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'> </span></i><a
href="https://doi.org/10.1109/ACCESS.2019.2945545"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>7, 158820–158846. doi:
10.1109/ACCESS.2019.29 </span></a><a
href="https://doi.org/10.1109/ACCESS.2019.2945545"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>45545</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Acosta-Vargas, P., Salvador-Acosta, B.,
Salvador-Ullauri, L., and Jadán-Guerrero, J. (2022). Accessibility challenges
of e-commerce websites. </span><i><span style='font-size:7.0pt;line-height:
97%;font-family:"Times New Roman",serif;color:black'>PeerJ Comput. Sci. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>8:891. doi: </span><a
href="https://doi.org/10.7717/peerj-cs.891"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.7717/peerj-cs.891</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Akter, T., Ahmed, T., Kapadia, A., and
Swaminathan, M. (2022). Shared privacy concerns of the visually impaired and
sighted bystanders with camera</span><a href="https://doi.org/10.1145/3506857"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>based
assistive technologies.</span></a><span style='font-size:7.0pt;line-height:
97%;color:black'> </span><a href="https://doi.org/10.1145/3506857"><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black;text-decoration:none'>ACM Trans. Access. Comput.</span></i></a><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'> </span></i><a href="https://doi.org/10.1145/3506857"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>15:3506857.
doi: 10.1145/35 </span></a><a href="https://doi.org/10.1145/3506857"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>06857</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Alashkar, R., Elsabbahy, M., Sabha, A.,
Abdelghany, M., Tlili, B., and Mounsef, J. (2020). “AI-vision towards an
improved social inclusion,” in </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>IEEE/ITU Int.
Conf. Artif. Intell. Good, AI4G (Institute of Electrical and Electronics
Engineers Inc.) </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>(Geneva), 204–209.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Ali, O., Abdelbaki, W., Shrestha, A.,
Elbasi, E., Alryalat, M. A. A., and Dwivedi, Y. K. (2023). A systematic
literature review of artificial intelligence in the healthcare sector:
benefits, challenges, methodologies, and functionalities. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>J. Innov. Knowl. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>8:100333. doi: </span><a
href="https://doi.org/10.1016/j.jik.2023.100333"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1016/j.jik.2023.100333</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Ali, O., Ally, M., Dwivedi, Y., and others
(2020). The state of play of blockchain technology in the financial services
sector: a systematic literature review. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Int. J. Inf.
Manag. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>54:102199.
doi: </span><a href="https://doi.org/10.1016/j.ijinfomgt.2020.102199"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.ijinfomgt.2020.102199</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Ali, O., Jaradat, A., Kulakli, A., and
Abuhalimeh, A. (2021). A comparative study: blockchain technology utilization
benefits, challenges and functionalities. </span><i><span style='font-size:
7.0pt;line-height:97%;font-family:"Times New Roman",serif;color:black'>IEEE
Access </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>9,
12730–12749. doi: </span><a href="https://doi.org/10.1109/ACCESS.2021.3050241"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1109/ACCESS.2021.3050241</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Ali, O., Shrestha, A., Soar, J., and Wamba,
S. F. (2018). Cloud computing-enabled healthcare opportunities, issues, and
applications: a systematic review. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Int. J. Inf.
Manag. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>43,
146–158. doi: </span><a href="https://doi.org/10.1016/j.ijinfomgt.2018.07.009"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.ijinfomgt.2018.07.009</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Al-Khazraji, S., Dingman, B., Lee, S., and
Huenerfauth, M. (2021). “At a different pace: evaluating whether users prefer
timing parameters in American sign language animations to differ from human
signers’ timing,” in </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>ASSETS—Int. ACM SIGACCESS
Conf. Comput. Access. (Association for Computing Machinery, Inc</span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:5.05pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Alonzo, O., Shin, H. V., and Li, D. (2022).
“Beyond subtitles: captioning and visualizing non-speech sounds to improve
accessibility of user-generated videos,” in </span><i><span style='font-size:
7.0pt;line-height:97%;font-family:"Times New Roman",serif;color:black'>Proceedings
of the 24th International ACM SIGACCESS Conference on Computers and
Accessibility </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>(New York, NY), 1–12.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Balakrishnan, A., Ramana, K., Ashok, G.,
Viriyasitavat, W., Ahmad, S., and Gadekallu, T. R. (2023). Sonar
glass—artificial vision: comprehensive design aspects of a synchronization
protocol for vision based sensors. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Meas. J. Int.
Meas. Confed. </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>211:2636. doi: </span><a
href="https://doi.org/10.1016/j.measurement.2023.112636"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.measurement.2023.112636</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Bi, W. L., Hosny, A., Schabath, M. B.,
Giger, M. L., Birkbak, N. J., Mehrtash, A., et al. (2019). Artificial
intelligence in cancer imaging: clinical challenges and applications. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Cancer J. Clin. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>69, 127–157. doi: </span><a
href="https://doi.org/10.3322/caac.21552"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3322/caac.21552</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:5.1pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Bigham, J. P., Kaminsky, R. S., Ladner, R.
E., Danielsson, O. M., and Hempton, G. L. (2006). “WebInSight: making web
images accessible,” in </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>Proceedings of the 8th
International ACM SIGACCESS Conference on Computers and Accessibility </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>(New York, NY), 181–188.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:5.05pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Bong, W. K., and Chen, W. (2021). Increasing
faculty’s competence in digital accessibility for inclusive education: a
systematic literature review. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Int. J. Incl.
Educ. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>2021,
1–17. doi: </span><a href="https://doi.org/10.1080/13603116.2021.1937344"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1080/13603116.2021.1937344</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Bragg, D., Koller, O., Bellard, M., Berke,
L., Boudreault, P., Braffort, A., et al. (2019). “Sign language recognition,
generation, and translation: an interdisciplinary perspective,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>The 21st International ACM SIGACCESS Conference on Computers and
Accessibility </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>(Pittsburgh, PA). Available online at: </span><a
href="https://hal.science/hal-02394580"><span style='font-size:7.0pt;
line-height:97%;color:#856DF0;text-decoration:none'>https://hal.science/hal-02394580
</span></a><span style='font-size:7.0pt;line-height:97%;color:black'>(accessed
November 19, 2023).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Campomanes-Alvarez, C., and Rosario
Campomanes-Alvarez, B. (2021). “Automatic facial expression recognition for the
interaction of individuals with multiple disabilities,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Int. Conf. Appl. Artif. Intell., ICAPAI (Institute of Electrical
and Electronics Engineers Inc.) </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>(Halden).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Chadli, F. E., Gretete, D., and Moumen, A.
(2021). Digital accessibility: a systematic literature review. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>SHS Web. Conf. </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>119:e06005. doi: </span><a
href="https://doi.org/10.1051/shsconf/202111906005"><span style='font-size:
7.0pt;line-height:97%;color:black;text-decoration:none'>10.1051/shsconf/202111906005
</span></a><span style='font-size:7.0pt;line-height:97%;color:black'>Chaitra,
C., Vethanayagi, R., Manoj Kumar, M. V., Prashanth, B. S., Snehah, H. R.,
Thomas, L., et al. (2022). “Image/video summarization in text/speech for
visually impaired people,” in </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>MysuruCon—IEEE
Mysore Sub Sect. Int. Conf. (Institute of Electrical and Electronics Engineers
Inc.) </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>(Mysuru).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Chen, X., Wu, C.-S., Murakhovs’ ka, L.,
Laban, P., Niu, T., Liu, W., et al. (2023). Marvista: exploring the design of a
human-AI collaborative news reading tool. </span><i><span style='font-size:
7.0pt;line-height:97%;font-family:"Times New Roman",serif;color:black'>ACM
Trans. Comput.-Hum. Interact. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>30, 1–27. doi: </span><a
href="https://doi.org/10.1145/3609331"><span style='font-size:7.0pt;line-height:
97%;color:black;text-decoration:none'>10.1145/3609331</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Cimolino, G., Askari, S., and Graham, T. C.
N. (2021). The role of partial automation in increasing the accessibility of
digital games. </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>Proc. ACM Hum. Comput.
Interact. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>5:3474693.
doi: </span><a href="https://doi.org/10.1145/3474693"><span style='font-size:
7.0pt;line-height:97%;color:black;text-decoration:none'>10.1145/3474693</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Dobransky, K., and Hargittai, E. (2016).
Unrealized potential: exploring the digital disability divide. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Poetics </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>58, 18–28. doi: </span><a
href="https://doi.org/10.1016/j.poetic.2016.08.003"><span style='font-size:
7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.poetic.2016.08.003</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Duarte, C., Pereira, L. S., Santos, A.,
Vicente, J., Rodrigues, A., Guerreiro, J., et al. (2021). “Nipping
inaccessibility in the bud: opportunities and challenges of accessible media
content authoring,” in </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>ACM Int. Conf. Proc. Ser.
(Association for Computing Machinery)</span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>, 3–9.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Efanov, D., Aleksandrov, P., and
Karapetyants, N. (2022). “The BiLSTM-based synthesized speech recognition,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Procedia Comput. Sci.</span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>, eds. F. F. Ramos Corchado and A. V. Samsonovich
(Elsevier B.V.), 415–421.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Feng, C.-H., Hsieh, J.-Y., Hung, Y.-H.,
Chen, C.-J., and Chen, C.-H. (2020). “Research on the visually impaired
individuals shopping with artificial intelligence image recognition
assistance,” in </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>Lect. Notes Comput. Sci. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>eds. M. Antona and C.
Stephanidis (Berlin: Springer), 518–531.</span></p>

<p class=MsoNormal align=center style='margin-top:0in;margin-right:0in;
margin-bottom:2.75pt;margin-left:1.45pt;text-align:center;text-indent:0in;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:black'>Fu,
K.-S. (2019). </span><i><span style='font-size:7.0pt;line-height:107%;
font-family:"Times New Roman",serif;color:black'>Applications of Pattern
Recognition</span></i><span style='font-size:7.0pt;line-height:107%;color:black'>.
Boca Raton, FL: CRC Press.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Golder, S., Loke, Y. K., and Zorzela, L.
(2014). Comparison of search strategies in systematic reviews of adverse
effects to other systematic reviews. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Health Inf.
Libr. J. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>31,
92–105. doi: </span><a href="https://doi.org/10.1111/hir.12041"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1111/hir.12041</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Guo, Z., Wang, Z., and Jin, X. (2021).
“Avatar To Person” (ATP) virtual human social ability enhanced system for
disabled people. </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>Wirel. Commun. Mob. Comput. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>2021:5098992. doi: </span><a
href="https://doi.org/10.1155/2021/5098992"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1155/2021/5098992</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Hapsari, G. I., Mutiara, G. A., and Kusumah,
D. T. (2017). “Smart cane location guide for blind using GPS,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>2017 5th International Conference on Information and Communication
Technology (ICoIC7) </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>(Melaka), 1–6.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Harum, N., Izzati, M. S. K. N., Emran, N.
A., Abdullah, N., Zakaria, N. A., Hamid, E., et al. (2021). A development of
multi-language interactive device using artificial intelligence technology for
visual impairment person. </span><i><span style='font-size:7.0pt;line-height:
97%;font-family:"Times New Roman",serif;color:black'>Int. J. Interact. Mob.
Technol. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>15,
79–92. doi: </span><a href="https://doi.org/10.3991/ijim.v15i19.24139"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.3991/ijim.v15i19.24139</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Hassani, H., Silva, E. S., Unger, S.,
TajMazinani, M., and Mac Feely, S. (2020). Artificial intelligence (AI) or
intelligence augmentation (ia): what is the future? </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>AI </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>1, 143–155. doi: </span><a href="https://doi.org/10.3390/ai1020008"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.3390/ai1020008</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Hezam, I. M., Mishra, A. R., Rani, P., and
Alshamrani, A. (2023). Assessing the barriers of digitally sustainable
transportation system for persons with disabilities using Fermatean fuzzy
double normalization-based multiple aggregation method. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Appl. Soft Comput. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>133:109910. doi: </span><a
href="https://doi.org/10.1016/j.asoc.2022.109910"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1016/j.asoc.2022.109910</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Hughes, C. E., Dieker, L. A., Glavey, E. M.,
Hines, R. A., Wilkins, I., Ingraham, K., et al. (2022). RAISE: robotics &amp;
AI to improve STEM and social skills for elementary school students. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Front. Virtual Real. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>3:968312. doi: </span><a
href="https://doi.org/10.3389/frvir.2022.968312"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3389/frvir.2022.968312</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Ingavelez-Guerra, P., Robles-Bykbaev, V. E.,
Perez-Munoz, A., Hilera-Gonzalez, J., and Oton-Tortosa, S. (2022). Automatic
adaptation of open educational resources: an approach from a multilevel
methodology based on students’ preferences, educational special needs,
artificial intelligence and accessibility metadata. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>IEEE Access </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>10, 9703–9716. doi: </span><a
href="https://doi.org/10.1109/ACCESS.2021.3139537"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1109/ACCESS.2021.3139537</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Initiative (WAI), W. W. A. (2022). </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Introduction to Web Accessibility</span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>. Web Access. Initiat. WAI.
Available online at: </span><a
href="https://www.w3.org/WAI/fundamentals/accessibility-intro/"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>https://www.w3.org/WAI/fundamentals/
</span></a><a href="https://www.w3.org/WAI/fundamentals/accessibility-intro/"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>accessibility-intro/</span></a><span
style='font-size:7.0pt;line-height:97%;color:#856DF0'> </span><span
style='font-size:7.0pt;line-height:97%;color:black'>(accessed April 12, 2023).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Jayawardena, C., Balasuriya, B. K.,
Lokuhettiarachchi, N. P., and Ranasinghe, A. R. M. D. N. (2019). “Intelligent
platform for visually impaired children for learning indoor and outdoor
objects,” in </span><i><span style='font-size:7.0pt;line-height:97%;font-family:
"Times New Roman",serif;color:black'>IEEE Reg 10 Annu Int Conf Proc TENCON
(Institute of Electrical and Electronics Engineers Inc.)</span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>, 2572–2577.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Joshi, R. C., Yadav, S., Dutta, M. K., and
Travieso-Gonzalez, C. M. (2020). Efficient multi-object detection and smart
navigation using artificial intelligence for visually impaired people. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Entropy </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>22:e22090941. doi: </span><a
href="https://doi.org/10.3390/e22090941"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3390/e22090941</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Karyono, K., Abdullah, B., Cotgrave, A., and
Bras, A. (2020). A novel adaptive lighting system which considers behavioral
adaptation aspects for visually impaired people. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Buildings </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>10:90168. doi: </span><a
href="https://doi.org/10.3390/buildings10090168"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3390/buildings10090168</span></a></p>

<p class=MsoNormal align=left style='margin:0in;text-align:left;text-indent:
8.95pt;line-height:93%'><span style='font-size:7.0pt;line-height:93%;
color:black'>Kitchenham, B., Charters, S., and others (2007). </span><i><span
style='font-size:7.0pt;line-height:93%;font-family:"Times New Roman",serif;
color:black'>Guidelines for Performing Systematic Literature Reviews in
Software Engineering</span></i><span style='font-size:7.0pt;line-height:93%;
color:black'>.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Kose, U., and Vasant, P. (2020). Better
campus life for visually impaired University students: intelligent social
walking system with beacon and assistive technologies. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Wirel. Netw. </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>26, 4789–4803. doi: </span><a
href="https://doi.org/10.1007/s11276-018-1868-z"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1007/s11276-018-1868-z</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Kosiedowski, M., Radziuk, A., Szymaniak, P.,
Kapsa, W., Rajtar, T., Stroinski, M., et al. (2020). “On applying ambient
intelligence to assist people with profound intellectual and multiple
disabilities,” in </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>Adv. Intell. Sys. Comput. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>eds. Y. Bi, R. Bhatia, and
S. Kapoor (Berlin: Springer Verlag), 895–914.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Le Glaz, A., Haralambous, Y., Kim-Dufor,
D.-H., Lenca, P., Billot, R., Ryan, T. C., et al. (2021). Machine learning and
natural language processing in mental health: systematic review. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>J. Med. Internet Res. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>23:e15708. doi: </span><a
href="https://doi.org/10.2196/15708"><span style='font-size:7.0pt;line-height:
97%;color:black;text-decoration:none'>10.2196/15708</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:.3pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Leaman, J., and La, H. M. (2017). A
comprehensive review of smart wheelchairs: past, present, and future. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>IEEE Trans. Hum.-Mach. Syst. </span></i><span style='font-size:
7.0pt;line-height:97%;color:black'>47, 486–499.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:0in;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>doi: </span><a
href="https://doi.org/10.1109/THMS.2017.2706727"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1109/THMS.2017.2706727</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Li, X., Huang, M., Xu, Y., Cao, Y., Lu, Y.,
Wang, P., et al. (2022). AviPer: assisting visually impaired people to perceive
the world with visual-tactile multimodal attention network. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>CCF Trans. Pervasive Comput. Interact. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>4, 219–239. doi: </span><a
href="https://doi.org/10.1007/s42486-022-00108-3"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1007/s42486-022-00108-3</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Lin, P.-J., Hung, S., Lam, S. F. S., and
Chen, B. C. (2019). “Object recognition with machine learning: case study of
demand-responsive service,” in </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Proc.—IEEE
Int. Conf. Internet Things Intell. Syst., IoTaIS (Institute of Electrical and
Electronics Engineers Inc.) </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>(Bali), 129–134.</span></p>

<p class=MsoNormal align=right style='margin-top:0in;margin-right:1.4pt;
margin-bottom:3.5pt;margin-left:0in;text-align:right;text-indent:0in;
line-height:107%'><span style='font-size:7.0pt;line-height:107%;color:black'>Liu,
J., Sun, J., and Wang, S. (2006). Pattern recognition: an overview. </span><i><span
style='font-size:7.0pt;line-height:107%;font-family:"Times New Roman",serif;
color:black'>IJCSNS </span></i><span style='font-size:7.0pt;line-height:107%;
color:black'>6:57.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Liu, L., Ouyang, W., Wang, X., Fieguth, P.,
Chen, J., Liu, X., et al. (2020). Deep learning for generic object detection: a
survey. </span><i><span style='font-size:7.0pt;line-height:97%;font-family:
"Times New Roman",serif;color:black'>Int. J. Comput. Vis. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>128, 261–318. doi: </span><a
href="https://doi.org/10.1007/s11263-019-01247-4"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1007/s11263-019-01247-4</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Lo Valvo, A., Croce, D., Garlisi, D.,
Giuliano, F., Giarré, L., and Tinnirello, I. (2021). A navigation and augmented
reality system for visually impaired people. </span><i><span style='font-size:
7.0pt;line-height:97%;font-family:"Times New Roman",serif;color:black'>Sensors </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>21:93061. doi: </span><a
href="https://doi.org/10.3390/s21093061"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3390/s21093061</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Lu, W., Wei, Y., Yuan, J., Deng, Y., and
Song, A. (2020). Tractor assistant driving control method based on eeg combined
with rnn-Tl deep learning algorithm. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>IEEE Access </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>8, 163269–163279. doi: </span><a
href="https://doi.org/10.1109/ACCESS.2020.3021051"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1109/ACCESS.2020.3021051</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Lucibello, S., and Rotondi, C. (2019). The
biological encoding of design and the premises for a new generation of ‘living’
products: the example of sinapsi. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Temes Disseny </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>2019, 116–139. doi: </span><a
href="https://doi.org/10.46467/TdD35.2019.116-139"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.46467/TdD35.2019.116-139</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>McLean, G., Osei-Frimpong, K., and Barhorst,
J. (2021). Alexa, do voice assistants influence consumer brand engagement?</span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>—</span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>examining the role of AI powered voice assistants in influencing
consumer brand engagement. </span><i><span style='font-size:7.0pt;line-height:
97%;font-family:"Times New Roman",serif;color:black'>J. Bus. Res. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>124, 312–328. doi: </span><a
href="https://doi.org/10.1016/j.jbusres.2020.11.045"><span style='font-size:
7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.jbusres.2020.11.045</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Montanha, A., Oprescu, A. M., and
Romero-Ternero, M. (2022). A context-aware artificial intelligence-based system
to support street crossings for pedestrians with visual impairments. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Appl. Artif. Intell. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>36:2062818. doi: </span><a
href="https://doi.org/10.1080/08839514.2022.2062818"><span style='font-size:
7.0pt;line-height:97%;color:black;text-decoration:none'>10.1080/08839514.2022.2062818</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Ngai, E. W., and Wat, F. (2002). A
literature review and classification of electronic commerce research. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Inf. Manage. </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>39, 415–429. doi: </span><a
href="https://doi.org/10.1016/S0378-7206(01)00107-0"><span style='font-size:
7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/S0378-7206(01)00107-0</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Paiva, D. M. B., Freire, A. P., and de
Mattos Fortes, R. P. (2021). Accessibility and software engineering processes:
a systematic literature review. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>J. Syst.
Softw. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>171:110819.
doi: </span><a href="https://doi.org/10.1016/j.jss.2020.110819"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.jss.2020.110819</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Park, J. S., Bragg, D., Kamar, E., and
Morris, M. R. (2021). “Designing an online infrastructure for collecting AI
data from people with disabilities,” in </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>FAccT—Proc.
ACM Conf. Fairness, Account., Transpar. (Association for Computing Machinery,
Inc)</span></i><span style='font-size:7.0pt;line-height:97%;color:black'>,
52–63.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:5.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Paul, J., Lim, W. M., O’Cass, A., Hao, A.
W., and Bresciani, S. (2021). Scientific procedures and rationales for
systematic literature reviews (SPAR-4-SLR). </span><i><span style='font-size:
7.0pt;line-height:97%;font-family:"Times New Roman",serif;color:black'>Int. J.
Consum. Stud. </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>45, O1–O16. doi: </span><a
href="https://doi.org/10.1111/ijcs.12695"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1111/ijcs.12695</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Pimenov, D. Y., Bustillo, A., Wojciechowski,
S., Sharma, V. S., Gupta, M. K., and Kuntoglu, M. (2023). Artificial
intelligence systems for tool condition monitoring in machining: analysis and
critical review. </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>J. Intell. Manuf. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>34, 2079–2121. doi: </span><a
href="https://doi.org/10.1007/s10845-022-01923-2"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1007/s10845-022-01923-2</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Prado, B., Gobbo Junior, J. A., and Bezerra,
B. S. (2023). Emerging themes for digital accessibility in education. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Sustainability </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>15:11392. doi: </span><a
href="https://doi.org/10.3390/su151411392"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3390/su151411392</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Rajasekhar, N., and Panday, S. (2022).
“SiBo-the Sign Bot, connected world for disabled,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>WINTECHCON—IEEE Women Technol. Conf. (Institute of Electrical and
Electronics Engineers Inc.) </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>(Bangalore).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Royal, A. B., Sandeep, B. G., Das, B. M.,
Bharath Raj Nayaka, A. M., and Joshi, S. (2023). “VisionX—a virtual assistant
for the visually impaired using deep learning models,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Lect. Notes Electr. Eng.</span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>, eds. N. R. Shetty, N. H. Prasad, and L. M.
Patnaik (Berlin: Springer Science and Business Media Deutschland GmbH),
891–901. doi: </span><a href="https://doi.org/10.1007/978-981-19-5482-5_75"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1007/978-981-19-5482-5_75</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Saha, M., Fiannaca, A. J., Kneisel, M.,
Cutrell, E., and Morris, M. R. (2019). “Closing the gap: designing for the
last-few-meters wayfinding problem for people with visual impairments,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>ASSETS—Int. ACM SIGACCESS Conf. Comput. Access. (Association for
Computing Machinery, Inc)</span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>, 222–235.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:8.95pt;text-indent:0in;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Schank, R. C. (1991). Where’s the AI? </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>AI Mag. </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>12, 38–38.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Schwendicke, F., Samek, W., and Krois, J.
(2020). Artificial intelligence in dentistry: chances and challenges. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>J. Dent. Res. </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>99, 769–774. doi: </span><a
href="https://doi.org/10.1177/0022034520915714"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1177/0022034520915714</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>See, A. R., and Advincula, W. D. (2021).
Creating tactile educational materials for the visually impaired and blind
students using ai cloud computing. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Appl. Sci.
Switz. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>11:167552.
doi: </span><a href="https://doi.org/10.3390/app11167552"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.3390/app11167552</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Sharma, T., Legarda, R., and Sharma, S.
(2020). “Assessing trends of digital divide within digital services in New York
City,” in </span><i><span style='font-size:7.0pt;line-height:97%;font-family:
"Times New Roman",serif;color:black'>Human Interaction and Emerging
Technologies Advances in Intelligent Systems and Computing</span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>, eds. T. Ahram, R. Taiar,
S. Colson, and A. Choplin (Cham: Springer International Publishing), 682–687.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Shezi, M., and Ade-Ibijola, A. (2020). Deaf
chat: a speech-to-text communication aid for hearing deficiency. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Adv. Sci. Technol. Eng. Syst. </span></i><span style='font-size:
7.0pt;line-height:97%;color:black'>5, 826–833. doi: </span><a
href="https://doi.org/10.25046/aj0505100"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.25046/aj0505100</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Sreemathy, R., Turuk, M., Kulkarni, I., and
Khurana, S. (2022). Sign language recognition using artificial intelligence. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Educ. Inf. Technol. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>22:11391. doi: </span><a
href="https://doi.org/10.1007/s10639-022-11391-z"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.1007/s10639-022-11391-z</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Subashini, P., and Krishnaveni, M. (2021).
“Artificial intelligence-based assistive technology,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Artificial Intelligence Theory, Models, and Applications </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>(Boca Raton, FL: Auerbach
Publications), 217–240.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Teófilo, M., Lourenço, A., Postal, J., and
Lucena, V. F. (2018). “Exploring virtual reality to enable deaf or hard of
hearing accessibility in live theaters: a case study,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Lect. Notes Comput. Sci. </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>eds. M. Antona and C. Stephanidis (Berlin:
Springer Verlag), 132–148.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Theodorou, L., Massiceti, D., Zintgraf, L.,
Stumpf, S., Morrison, C., Cutrell, E., et al. (2021). “Disability-first dataset
creation: lessons from constructing a dataset for teachable object recognition
with blind and low vision data collectors,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>ASSETS—Int. ACM SIGACCESS Conf. Comput. Access. (Association for
Computing Machinery, Inc</span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Thomas, M., and Meehan, K. (2021). “Banknote
object detection for the visually impaired using a CNN,” in </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>2021 32nd Irish Signals and Systems Conference (ISSC) </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>(Athlone: IEEE), 1–6.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Ullah, F., AbuAli, N. A., Ullah, A., Ullah,
R., Siddiqui, U. A., and Siddiqui, A. A. (2023). Fusion-based body-worn IoT
sensor platform for gesture recognition of autism spectrum disorder children. </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Sensors </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>23:1672. doi: </span><a href="https://doi.org/10.3390/s23031672"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.3390/s23031672</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Vieira, A. D., Leite, H., and Volochtchuk,
A. V. L. (2022). The impact of voice assistant home devices on people with
disabilities: a longitudinal study. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Technol.
Forecast. Soc. Change </span></i><span style='font-size:7.0pt;line-height:97%;
color:black'>184:121961. doi: </span><a
href="https://doi.org/10.1016/j.techfore.2022.121961"><span style='font-size:
7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.techfore.2022.121961</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Wadhwa, V., Gupta, B., and Gupta, S. (2021).
“AI based automated image caption tool implementation for visually impaired,”
in </span><i><span style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>ICIERA—Int. Conf. Ind. Electron. Res. Appl., Proc. (Institute of
Electrical and Electronics Engineers Inc.) </span></i><span style='font-size:
7.0pt;line-height:97%;color:black'>(New Delhi).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Watson, R. T. (2015). Beyond being
systematic in literature reviews in IS. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>J. Inf.
Technol. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>30,
185–187. doi: </span><a href="https://doi.org/10.1057/jit.2015.12"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1057/jit.2015.12</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Watters, J., Liu, C., Hill, A., and Jiang,
F. (2020). “An artificial intelligence tool for accessible science education,”
in </span><i><span style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>IMCIC - Int. Multi-Conf. Complex., Informatics Cybern., Proc.</span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>, eds. R. M. A. Baracho, N.
C. Callaos, S. K. Lunsford, B. Sanchez, and M. Savoie (International Institute
of Informatics and Systemics, IIIS), 147–150. Available online at: </span><a
href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085951599&amp;partnerID=40&amp;md5=8ff1be6533d855bc4f3338a78ba516db"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>https://www.scopus.com/inward/record.uri?eid=2-s2.
</span></a><a
href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085951599&amp;partnerID=40&amp;md5=8ff1be6533d855bc4f3338a78ba516db"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>0-85085951599&amp;partnerID=40&amp;md5=8ff1be6533d855bc4f3338a78ba516db</span></a><span
style='font-size:7.0pt;line-height:97%;color:#856DF0'> </span><span
style='font-size:7.0pt;line-height:97%;color:black'>(accessed May 18, 2023).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>World Health Organization (2022). </span><i><span
style='font-size:7.0pt;line-height:97%;font-family:"Times New Roman",serif;
color:black'>Global Report on Health Equity for Persons With Disabilities</span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>. Geneva: World Health
Organization.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Yang, H. F., Ling, Y., Kopca, C., Ricord,
S., and Wang, Y. (2022). Cooperative traffic signal assistance system for
non-motorized users and disabilities empowered by computer vision and edge
artificial intelligence. </span><i><span style='font-size:7.0pt;line-height:
97%;font-family:"Times New Roman",serif;color:black'>Transp. Res. C Emerg.
Technol. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>145:103896.
doi: </span><a href="https://doi.org/10.1016/j.trc.2022.103896"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1016/j.trc.2022.103896</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Yang, Q., Jin, W., Zhang, Q., Wei, Y., Guo,
Z., Li, X., et al. (2023). Mixed-modality speech recognition and interaction
using a wearable artificial throat. </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>Nat. Mach.
Intell. </span></i><span style='font-size:7.0pt;line-height:97%;color:black'>5,
169–180. doi: </span><a href="https://doi.org/10.1038/s42256-023-00616-6"><span
style='font-size:7.0pt;line-height:97%;color:black;text-decoration:none'>10.1038/s42256-023-00616-6</span></a></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:1.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Yeratziotis, G., and Van Greunen, D. (2013).
“Making ICT accessible for the deaf,” in </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>2013
IST-Africa Conference and Exhibition </span></i><span style='font-size:7.0pt;
line-height:97%;color:black'>(IEEE), 1–9. Available online at: </span><a
href="https://ieeexplore.ieee.org/abstract/document/6701722/"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>https://
</span></a><a href="https://ieeexplore.ieee.org/abstract/document/6701722/"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>ieeexplore.ieee.org/abstract/document/6701722/</span></a><span
style='font-size:7.0pt;line-height:97%;color:#856DF0'> </span><span
style='font-size:7.0pt;line-height:97%;color:black'>(accessed November 15,
2023).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Yue, W. S., and Zin, N. A. M. (2013). Voice
recognition and visualization mobile apps game for training and teaching
hearing handicaps children. </span><i><span style='font-size:7.0pt;line-height:
97%;font-family:"Times New Roman",serif;color:black'>Proce. Technol. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>11, 479–486.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Zaid alahmadi, S., and Alsulami, R. A.
(2020). ““Asmeany”: an andriod application for deaf and hearing-impaired
people,” in </span><i><span style='font-size:7.0pt;line-height:97%;font-family:
"Times New Roman",serif;color:black'>Proc. Int. Conf. Ind. Eng. Oper. Manage. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>(IEOM Society), 434–435.
Available online at: </span><a
href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088992536&amp;partnerID=40&amp;md5=caf9751c4881d56383dddfc8abb3d60b"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>https://www.
</span></a><a
href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088992536&amp;partnerID=40&amp;md5=caf9751c4881d56383dddfc8abb3d60b"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>scopus.com/inward/record.uri?eid=2-s2.0-85088992536&amp;partnerID=40&amp;md5=
</span></a><a
href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088992536&amp;partnerID=40&amp;md5=caf9751c4881d56383dddfc8abb3d60b"><span
style='font-size:7.0pt;line-height:97%;color:#856DF0;text-decoration:none'>caf9751c4881d56383dddfc8abb3d60b</span></a><span
style='font-size:7.0pt;line-height:97%;color:#856DF0'> </span><span
style='font-size:7.0pt;line-height:97%;color:black'>(accessed May 18, 2023).</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:1.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Zhou, X., Cheng, S., Zhu, M., Guo, C., Zhou,
S., Xu, P., et al. (2018). “A state of the art survey of data mining-based
fraud detection and credit scoring,” in </span><i><span style='font-size:7.0pt;
line-height:97%;font-family:"Times New Roman",serif;color:black'>MATEC Web of
Conferences (EDP Sciences) </span></i><span style='font-size:7.0pt;line-height:
97%;color:black'>(Beijing), e03002.</span></p>

<p class=MsoNormal style='margin-top:0in;margin-right:0in;margin-bottom:3.55pt;
margin-left:-.75pt;text-indent:8.45pt;line-height:97%'><span style='font-size:
7.0pt;line-height:97%;color:black'>Zingoni, A., Taborri, J., Panetti, V.,
Bonechi, S., Aparicio-Martínez, P., Pinzi, S., et al. (2021). Investigating
issues and needs of dyslexic students at university: proof of concept of an
artificial intelligence and virtual reality-based supporting platform and
preliminary results. </span><i><span style='font-size:7.0pt;line-height:97%;
font-family:"Times New Roman",serif;color:black'>Appl. Sci. Switz. </span></i><span
style='font-size:7.0pt;line-height:97%;color:black'>11:104624. doi: </span><a
href="https://doi.org/10.3390/app11104624"><span style='font-size:7.0pt;
line-height:97%;color:black;text-decoration:none'>10.3390/app11104624</span></a></p>

</div>

</body>

</html>
